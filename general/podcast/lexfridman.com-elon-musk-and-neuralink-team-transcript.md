# Transcript for Elon Musk: Neuralink and the Future of Humanity | Lex Fridman Podcast #438

This is a transcript of Lex Fridman Podcast #438 with Elon Musk and Neuralink Team.    The timestamps in the transcript are clickable links that take you directly to that point in    the main video. Please note that the transcript is human generated, and may have errors.    Here are some useful links:    

- Go back to [this episode’s main page](https://lexfridman.com/elon-musk-and-neuralink-team/)
- Watch the [full YouTube version of the podcast](https://youtube.com/watch?v=Kbk9BiPhm7o)

## Table of Contents

Here are the loose “chapters” in the conversation.    Click link to jump approximately to that part in the transcript:    

- [0:00 – Introduction](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter0_introduction)
- [0:49 – Elon Musk](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter1_elon_musk)
- [4:06 – Telepathy](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter2_telepathy)
- [10:45 – Power of human mind](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter3_power_of_human_mind)
- [15:12 – Future of Neuralink](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter4_future_of_neuralink)
- [20:27 – Ayahuasca](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter5_ayahuasca)
- [29:57 – Merging with AI](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter6_merging_with_ai)
- [34:44 – xAI](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter7_xai)
- [36:57 – Optimus](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter8_optimus)
- [43:47 – Elon’s approach to problem-solving](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter9_elon_s_approach_to_problem_solving)
- [1:01:23 – History and geopolitics](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter10_history_and_geopolitics)
- [1:05:53 – Lessons of history](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter11_lessons_of_history)
- [1:10:12 – Collapse of empires](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter12_collapse_of_empires)
- [1:17:55 – Time](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter13_time)
- [1:20:37 – Aliens and curiosity](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter14_aliens_and_curiosity)
- [1:28:12 – DJ Seo](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter15_dj_seo)
- [1:36:20 – Neural dust](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter16_neural_dust)
- [1:43:03 – History of brain–computer interface](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter17_history_of_brain_computer_interface)
- [1:51:07 – Biophysics of neural interfaces](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter18_biophysics_of_neural_interfaces)
- [2:01:36 – How Neuralink works](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter19_how_neuralink_works)
- [2:07:26 – Lex with Neuralink implant](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter20_lex_with_neuralink_implant)
- [2:27:24 – Digital telepathy](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter21_digital_telepathy)
- [2:38:27 – Retracted threads](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter22_retracted_threads)
- [2:44:01 – Vertical integration](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter23_vertical_integration)
- [2:50:55 – Safety](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter24_safety)
- [3:00:50 – Upgrades](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter25_upgrades)
- [3:09:53 – Future capabilities](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter26_future_capabilities)
- [3:39:09 – Matthew MacDougall](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter27_matthew_macdougall)
- [3:44:58 – Neuroscience](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter28_neuroscience)
- [3:52:07 – Neurosurgery](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter29_neurosurgery)
- [4:03:11 – Neuralink surgery](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter30_neuralink_surgery)
- [4:22:20 – Brain surgery details](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter31_brain_surgery_details)
- [4:38:03 – Implanting Neuralink on self](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter32_implanting_neuralink_on_self)
- [4:53:57 – Life and death](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter33_life_and_death)
- [5:03:17 – Consciousness](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter34_consciousness)
- [5:06:11 – Bliss Chapman](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter35_bliss_chapman)
- [5:19:27 – Neural signal](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter36_neural_signal)
- [5:26:19 – Latency](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter37_latency)
- [5:30:59 – Neuralink app](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter38_neuralink_app)
- [5:35:40 – Intention vs action](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter39_intention_vs_action)
- [5:46:54 – Calibration](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter40_calibration)
- [5:56:26 – Webgrid](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter41_webgrid)
- [6:19:28 – Neural decoder](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter42_neural_decoder)
- [6:40:03 – Future improvements](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter43_future_improvements)
- [6:48:59 – Noland Arbaugh](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter44_noland_arbaugh)
- [6:49:08 – Becoming paralyzed](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter45_becoming_paralyzed)
- [7:02:43 – First Neuralink human participant](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter46_first_neuralink_human_participant)
- [7:06:45 – Day of surgery](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter47_day_of_surgery)
- [7:24:31 – Moving mouse with brain](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter48_moving_mouse_with_brain)
- [7:49:50 – Webgrid](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter49_webgrid)
- [7:57:52 – Retracted threads](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter50_retracted_threads)
- [8:06:16 – App improvements](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter51_app_improvements)
- [8:13:01 – Gaming](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter52_gaming)
- [8:23:59 – Future Neuralink capabilities](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter53_future_neuralink_capabilities)
- [8:26:55 – Controlling Optimus robot](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter54_controlling_optimus_robot)
- [8:31:16 – God](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter55_god)
- [8:33:21 – Hope](https://lexfridman.com/elon-musk-and-neuralink-team-transcript#chapter56_hope)


## Introduction

Lex Fridman: 00:00:00: The following is a conversation with  Elon Musk, DJ Seo, Matthew MacDougall, Bliss Chapman, and Noland Arbaugh about Neuralink and the future of humanity. Elon, DJ, Matthew and Bliss are of course part of the amazing Neuralink team, and Noland is the  first human to have a Neuralink device implanted in his brain. I speak  with each of them individually, so use timestamps to jump around, or as I recommend, go hardcore, and listen to the whole thing. This is the  longest podcast I’ve ever done. It’s a fascinating, super technical, and wide-ranging conversation, and I loved every minute of it. And now,  dear friends, here’s Elon Musk, his fifth time on this, the Lex Fridman  podcast,        

## Elon Musk

Elon Musk: 00:00:49: Drinking coffee or water?        

Lex Fridman: 00:00:51: Water. I’m so over-caffeinated right now. Do you want some caffeine?        

Elon Musk: 00:00:58: Sure.        

Lex Fridman: 00:00:59: There’s a Nitro drink.        

Elon Musk: 00:01:02: This supposed to keep you up for like tomorrow afternoon, basically.        

Lex Fridman: 00:01:08: Yeah. Yeah. I don’t want to [inaudible 00:01:11].        

Elon Musk: 00:01:11: So what is Nitro? It’s just got a lot of caffeine or something?        

Lex Fridman: 00:01:13: Don’t ask questions. It’s called Nitro. Do you need to know anything else?        

Elon Musk: 00:01:17: It’s got nitrogen in it. That’s ridiculous. What we breathe is 78% nitrogen anyway. What do you need to add more for?        

Elon Musk: 00:01:24: Unfortunately, you’re going to eat it.        

Elon Musk: 00:01:29: Most people think that they’re  breathing oxygen and they’re actually breathing 78% nitrogen. You need  like a milk bar, like from Clockwork Orange.        

Lex Fridman: 00:01:41: Yeah. Yeah. Is that the top three Kubrick film for you?        

Elon Musk: 00:01:44: Clockwork Orange? It’s pretty good. It’s demented. Jarring, I’d say.        

Lex Fridman: 00:01:49: Okay. Okay. So, first, let’s step  back, and big congrats on getting Neuralink implanted into a human.  That’s a historic step for Neuralink.        

Elon Musk: 00:01:49: Thanks. Yeah.        

Lex Fridman: 00:02:04: And there’s many more to come.        

Elon Musk: 00:02:07: Yeah. And we just obviously have our second implant as well.        

Lex Fridman: 00:02:11: How did that go?        

Elon Musk: 00:02:12: So far, so good. It looks like we’ve got, I think, on the order of 400 electrodes that are providing signals.        

Lex Fridman: 00:02:22: Nice.        

Elon Musk: 00:02:23: Yeah.        

Lex Fridman: 00:02:24: How quickly do you think the number of human participants will scale?        

Elon Musk: 00:02:28: It depends somewhat on the regulatory  approval, the rate at which we get regulatory approvals. So, we’re  hoping to do 10 by the end of this year, total of 10. So, eight more.        

Lex Fridman: 00:02:42: And with each one, you’re going to be  learning a lot of lessons about the neurobiology of the brain,  everything. The whole chain of the Neuralink, the decoding, the signal  processing, all that kind of stuff.        

Elon Musk: 00:02:54: Yeah. Yeah. I think it’s obviously  going to get better with each one. I don’t want to jinx it, but it seems to have gone extremely well with the second implant. So, there’s a lot  of signal, a lot of electrodes. It’s working very well.        

Lex Fridman: 00:03:09: What improvements do you think we’ll see in Neuralink in the coming, let’s say, let’s get crazy, the coming years.        

Elon Musk: 00:03:18: In years, it’s going to be gigantic,  because we’ll increase the number of electrodes dramatically. We’ll  improve the signal processing. So, even with only roughly, I don’t know, 10, 15% of the electrodes working with Noland, with our first patient,  we were able to get to achieve a bit per second. That’s twice the world  record. So, I think we’ll start vastly exceeding the world record by  orders of magnitude in the years to come. So, start getting to, I don’t  know, 100 bits per second, thousand. Maybe if five years from now, we  might be at a megabit, faster than any human could possibly communicate  by typing, or speaking.        

## Telepathy

Lex Fridman: 00:04:06: Yeah. That BPS is an interesting  metric to measure. There might be a big leap in the experience once you  reach a certain level of BPS.        

Elon Musk: 00:04:16: Yeah.        

Lex Fridman: 00:04:17: Like entire new ways of interacting with a computer might be unlocked.        

Elon Musk: 00:04:21: And with humans.        

Lex Fridman: 00:04:22: With other humans.        

Elon Musk: 00:04:23: Provided they have want a Neuralink, too.        

Lex Fridman: 00:04:27: Right.        

Elon Musk: 00:04:28: Otherwise they wont be able to absorb the signals fast enough.        

Lex Fridman: 00:04:31: Do you think they’ll improve the quality of intellectual discourse?        

Elon Musk: 00:04:34: Well, I think you could think of it,  if you were to slow down communication, how do you feel about that? If  you’d only talk at, let’s say one-tenth of normal speed, you’d be like,  “Wow, that’s agonizingly slow.”        

Lex Fridman: 00:04:50: Yeah.        

Elon Musk: 00:04:51: So, now imagine you could communicate clearly at 10, or 100, or 1,000 times faster than normal.        

Lex Fridman: 00:05:00: Listen, I’m pretty sure nobody in  their right mind listens to me at 1X. they listen at 2X. I can only  imagine what 10X would feel like, or I could actually understand it.        

Elon Musk: 00:05:14: I usually default to 1.5X. You can do  2X. Well actually, if I’m listening to somebody get to… in 15, 20  minutes, I want to go to sleep, then I’ll do it 1.5X. If I’m paying  attention, I’ll do 2X.        

Lex Fridman: 00:05:30: Right.        

Elon Musk: 00:05:32: But actually, if you actually listen  to podcasts, or audiobooks or anything at… If you get used to doing it  at 1.5, then one sounds painfully slow.        

Lex Fridman: 00:05:43: I’m still holding onto one, because  I’m afraid, I’m afraid of myself becoming bored with the reality, with  the real world, where everyone’s speaking in 1X.        

Elon Musk: 00:05:53: Well, it depends on the person. You  can speak very fast. Like we can communicate very quickly. And also, if  you use a wide range of… if your vocabulary is larger, your effective  bit rate is higher.        

Lex Fridman: 00:06:06: That’s a good way to put it.        

Elon Musk: 00:06:07: Yeah.        

Lex Fridman: 00:06:07: The effective bit rate. That is the  question, is how much information is actually compressed in the low bit  transfer of language?        

Elon Musk: 00:06:15: Yeah. If there’s a single word that is able to convey something that would normally require, I don’t know, 10  simple words, then you’ve got maybe a 10X compression on your hands. And that’s really like with memes. Memes are like data compression. You’re  simultaneously hit with a wide range of symbols that you can interpret,  and you get it faster than if it were words, or a simple picture.        

Lex Fridman: 00:06:49: And of course, you’re referring to memes broadly like ideas.        

Elon Musk: 00:06:52: Yeah. There’s an entire idea structure that is like an idea template, and then you can add something to that  idea template. But somebody has that pre-existing idea template in their head. So, when you add that incremental bit of information, you’re  conveying much more than if you just said a few words. It’s everything  associated with that meme.        

Lex Fridman: 00:07:15: You think there’ll be emergent leaps of capability as you scale the number of electrodes?        

Elon Musk: 00:07:19: Yeah.        

Lex Fridman: 00:07:19: Do you think there’ll be an actual number where just the human experience will be altered?        

Elon Musk: 00:07:26: Yes.        

Lex Fridman: 00:07:27: What do you think that number might  be? Whether electrodes, or BPS? We of course, don’t know for sure, but  is this 10,000, 100,000?        

Elon Musk: 00:07:37: Yeah. Certainly, if you’re anywhere at 10,000 bits per second, that’s vastly faster than any human can  communicate right now. If you think what is the average bits per second  of a human, it is less than one bit per second over the course of a day. Because there are 86,400 seconds in a day, and you don’t communicate  86,400 tokens in a day. Therefore, your bits per second is less than  one, averaged over 24 hours. It’s quite slow.        

00:08:04: And now, even if you’re communicating  very quickly, and you’re talking to somebody who understands what you’re saying, because in order to communicate, you have to at least to some  degree, model the mind state of the person to whom you’re speaking. Then take the concept you’re trying to convey, compress that into a small  number of syllables, speak them, and hope that the other person  decompresses them into a conceptual structure that is as close to what  you have in your mind as possible.        

Lex Fridman: 00:08:34: Yeah. There’s a lot of signal loss there in that process.        

Elon Musk: 00:08:37: Yeah. Very lossy, compression, and  decompression. And a lot of what your neurons are doing is distilling  the concepts down to a small number of symbols, or say syllables that  I’m speaking, or keystrokes, whatever the case may be. So, that’s a lot  of what your brain computation is doing. Now, there is an argument that  that’s actually a healthy thing to do, or a helpful thing to do because  as you try to compress complex concepts, you’re perhaps forced to  distill what is most essential in those concepts, as opposed to just all the fluff. So, in the process of compression, you distill things down  to what matters the most, because you can only say a few things.        

00:09:27: So that is perhaps helpful. I think  we’ll probably get… If our data rate increases, it’s highly probable it  will become far more verbose. Just like your computer, when computers  had… My first computer had 8K of RAM, so you really thought about every  byte. And now you’ve got computers with many gigabytes of RAM. So, if  you want to do an iPhone app that just says, “Hello world,” it’s  probably, I don’t know, several megabytes minimum, a bunch of fluff. But nonetheless, we still prefer to have the computer with the more memory  and more compute.        

00:10:09: So, the long-term aspiration of  Neuralink is to improve the AI human symbiosis by increasing the  bandwidth of the communication. Because even if… In the most benign  scenario of AI, you have to consider that the AI is simply going to get  bored waiting for you to spit out a few words. If the AI can communicate at terabits per second, and you’re communicating at bits per second,  it’s like talking to a tree.        

## Power of human mind

Lex Fridman: 00:10:45: Well, it is a very interesting question for a super intelligent species, what use are humans?        

Elon Musk: 00:10:54: I think there is some argument for humans as a source of will.        

Lex Fridman: 00:10:59: Will?        

Elon Musk: 00:11:00: Will, yeah. Source of will, or  purpose. So if you consider the human mind as being… Essentially there’s the primitive, limbic elements, which basically even reptiles have. And there’s the cortex, the thinking and planning part of the brain. Now,  the cortex is much smarter than the limbic system, and yet is largely in service to the limbic system. It’s trying to make the limbic system  happy. The sheer amount of compute that’s gone into people trying to get laid is insane, without actually seeking procreation. They’re just  literally trying to do this simple motion, and they get a kick out of  it. So, this simple, which in the abstract, rather absurd motion, which  is sex, the cortex is putting a massive amount of compute into trying to figure out how to do that.        

Lex Fridman: 00:11:55: So like 90% of distributed compute of the human species is spent on trying to get laid, probably. A large percentage.        

Elon Musk: 00:12:00: A massive amount. Yes. Yeah. Yeah.  There’s no purpose to most sex except hedonistic. It’s a sort of joy, or whatever, dopamine release. Now, once in a while, it’s procreation, but for modern humans, it’s mostly recreational. And so, your cortex, much  smarter than your limbic system, is trying to make the limbic system  happy, because the limbic system wants to have sex, or wants some tasty  food, or whatever the case may be.        

00:12:31: And then that is then further  augmented by the tertiary system, which is your phone, your laptop,  iPad, whatever, all your computing stuff. That’s your tertiary layer.  So, you’re actually already a cyborg. You have this tertiary compute  layer, which is in the form of your computer with all the applications,  or your compute devices. And so, in the getting laid front, there’s  actually a massive amount of digital compute also trying to get laid,  with Tinder and whatever.        

Lex Fridman: 00:13:04: Yeah. So, the compute that we humans have built is also participating.        

Elon Musk: 00:13:09: Yeah. There’s like gigawatts of compute going into getting laid, of digital compute.        

Lex Fridman: 00:13:14: Yeah. What if AGI was-        

Elon Musk: 00:13:17: This is happening as we speak.        

Lex Fridman: 00:13:19: … if we merge with AI, it’s just going to expand the compute that we humans use-        

Elon Musk: 00:13:24: Pretty much.        

Lex Fridman: 00:13:24: … to try to get laid.        

Elon Musk: 00:13:25: Well, it’s one of the things. Certainly, yeah.        

Lex Fridman: 00:13:26: Yeah.        

Elon Musk: 00:13:29: But what I’m saying is that, yes, is  there a use for humans? Well, there’s this fundamental question of  what’s the meaning of life? Why do anything at all? And so, if our  simple limbic system provides a source of will to do something, that  then goes through our cortex, that then goes to our tertiary compute  layer, then I don’t know, it might actually be that the AI, in a benign  scenario, is simply trying to make the human limbic system happy.        

Lex Fridman: 00:14:03: Yeah. It seems like the will is not  just about the limbic system. There’s a lot of interesting, complicated  things in there. We also want power.        

Elon Musk: 00:14:11: That’s limbic too, I think.        

Lex Fridman: 00:14:13: But then we also want to, in a kind of cooperative way, alleviate the suffering in the world.        

Elon Musk: 00:14:19: Not everybody does. But yeah, sure, some people do.        

Lex Fridman: 00:14:22: As a group of humans, when we get  together, we start to have this kind of collective intelligence that is  more complex in its will than the underlying individual descendants of  apes, right?        

Elon Musk: 00:14:37: Sure.        

Lex Fridman: 00:14:37: So there’s other motivations, and that could be a really interesting source of an objective function for AGI?        

Elon Musk: 00:14:45: Yeah. There are these fairly cerebral, or higher level goals. For me, it’s like, what’s the meaning of life,  or understanding the nature of the universe, is of great interest to me, and hopefully to the AI. And that’s the mission of xAI and Grok is  understand the universe.        

## Future of Neuralink

Lex Fridman: 00:15:13: So do you think people… When you have a Neuralink with 10,000, 100,000 channels, most of the use cases will be  communication with AI systems?        

Elon Musk: 00:15:27: Well, assuming that there are not…  They’re solving basic neurological issues that people have. If they’ve  got damaged neurons in their spinal cord, or neck, as is the case with  our first two patients, then obviously the first order of business is  solving fundamental neuron damage in a spinal cord, neck, or in the  brain itself. So, our second product is called Blindsight, which is to  enable people who are completely blind, lost both eyes, or optic nerve,  or just can’t see at all, to be able to see by directly triggering the  neurons in the visual cortex.        

00:16:18: So we’re just starting at the basics  here, so it’s the simple stuff, relatively speaking, is solving neuron  damage. It can also solve I think probably schizophrenia, if people have seizures of some kind, it could probably solve that. It could help with memory. So, there’s kind of a tech tree, if you will. You’ve got the  basics. You need literacy before you can have Lord of the Rings.        

Lex Fridman: 00:17:02: Got it.        

Elon Musk: 00:17:02: So, do you have letters and the  alphabet? Okay, great. Words? And then eventually you get sagas. So, I  think there may be some things to worry about in the future, but the  first several years are really just solving basic neurological damage,  like for people who have essentially complete or near complete loss from the brain to the body, like Stephen Hawking would be an example, the  Neuralink would be incredibly profound, because you can imagine if  Stephen Hawking could communicate as fast as we’re communicating,  perhaps faster. And that’s certainly possible. Probable, in fact.  Likely, I’d say.        

Lex Fridman: 00:17:46: So there’s a kind of dual track of  medical and non-medical, meaning so everything you’ve talked about could be applied to people who are non-disabled in the future?        

Elon Musk: 00:17:58: The logical thing to do is… Sensible thing to do is to start off solving basic neuron damage issues.        

Lex Fridman: 00:18:09: Yes.        

Elon Musk: 00:18:11: Because there’s obviously some risk  with a new device. You can’t get the risk down to zero, it’s not  possible. So, you want to have the highest possible reward, given  there’s a certain irreducible risk. And if somebody’s able to have a  profound improvement in their communication, that’s worth the risk.        

Lex Fridman: 00:18:34: As you get the risk down.        

Elon Musk: 00:18:36: Yeah. As you get the risk down. And  once the risk is down to… If you have thousands of people that have been using it for years and the risk is minimal, then perhaps at that point  you could consider saying, “Okay, let’s aim for augmentation.” Now, I  think we’re actually going to aim for augmentation with people who have  neuron damage. So we’re not just aiming to give people the communication data rate equivalent to normal humans. We’re aiming to give people who  have… A quadriplegic, or maybe have complete loss of the connection to  the brain and body, a communication data rate that exceeds normal  humans. While we’re in there, why not? Let’s give people superpowers.        

Lex Fridman: 00:19:20: And the same for vision. As you restore vision, there could be aspects of that restoration that are superhuman.        

Elon Musk: 00:19:27: Yeah. At first, the vision restoration will be low res, because you have to say, “How many neurons can you put in there, and trigger?” And you can do things where you adjust the  electric field. So, even if you’ve got, say 10,000 neurons, it’s not  just 10,000 pixels, because you can adjust the field between the  neurons, and do them in patterns in order to have say, 10,000  electrodes, effectively give you, I don’t know, maybe like having a  megapixel, or a 10 megapixel situation. And then over time, I think you  get to higher resolution than human eyes. And you could also see in  different wavelengths. So, like Geordi La Forge from Star Trek, he had  the thing. Do you want to see it in radar? No problem. You could see  ultraviolet, infrared, eagle vision, whatever you want.        

## Ayahuasca

Lex Fridman: 00:20:28: Do you think there’ll be… let me ask a Joe Rogan question. Do you think there’ll be… I just recently have taken ayahuasca.        

Elon Musk: 00:20:35: Is that a serious question?        

Lex Fridman: 00:20:38: No. Well, yes.        

Elon Musk: 00:20:39: Well, I guess technically it is.        

Lex Fridman: 00:20:40: Yeah.        

Elon Musk: 00:20:41: Yeah.        

Lex Fridman: 00:20:42: Ever try DMT bro?        

Elon Musk: 00:20:42: Yeah, is this DMT in there, or something?        

Lex Fridman: 00:20:42: Love you, Joe. Okay.        

Elon Musk: 00:20:48: Wait, wait. Have you said much about it, the ayahuasca stuff?        

Lex Fridman: 00:20:48: I have not. I have not. I have not.        

Elon Musk: 00:20:53: Okay. Well, why don’t you spill the beans?        

Lex Fridman: 00:20:55: It is a truly incredible experience.        

Elon Musk: 00:20:57: Let me turn the tables on you.        

Lex Fridman: 00:21:00: Well, yeah.        

Elon Musk: 00:21:00: You’re in the jungle.        

Lex Fridman: 00:21:02: Yeah, amongst the trees, myself and a shaman.        

Elon Musk: 00:21:02: Yeah. It must’ve been crazy.        

Lex Fridman: 00:21:05: Yeah, yeah, yeah. With the insects,  with the animals all around you, the jungle as far as the eye can see,  there’s no… That’s the way to do it.        

Elon Musk: 00:21:13: Things are going to look pretty wild.        

Lex Fridman: 00:21:14: Yeah, pretty wild. I took an extremely high dose.        

Elon Musk: 00:21:19: Just don’t go hugging an Anaconda or something.        

Lex Fridman: 00:21:24: You haven’t lived unless you made love to an Anaconda. I’m sorry, but…        

Elon Musk: 00:21:29: Snakes and Ladders.        

Lex Fridman: 00:21:33: Yeah. I took a extremely high dose.        

Elon Musk: 00:21:36: Okay.        

Lex Fridman: 00:21:37: Nine cups.        

Elon Musk: 00:21:39: Damn. Okay. That sounds like a lot. Is normal to just one cup? Or…        

Lex Fridman: 00:21:42: One or two. Usually one.        

Elon Musk: 00:21:46: Okay. Wait. Like right off the bat, or did you work your way up to it? Did you just jump in at the deep end?        

Lex Fridman: 00:21:53: Across two days, because the first day, I took two, and it was a ride, but it wasn’t quite like a…        

Elon Musk: 00:21:59: It wasn’t like a revelation.        

Lex Fridman: 00:22:01: It wasn’t into deep space type of  ride. It was just like a little airplane ride. And I [inaudible  00:22:07] saw some trees, and some visuals, and just saw a dragon and  all that kind of stuff. But…        

Elon Musk: 00:22:13: Nine cups, you went to Pluto, I think.        

Lex Fridman: 00:22:15: Pluto. Yeah. No, Deep space.        

Elon Musk: 00:22:17: Deep space.        

Lex Fridman: 00:22:19: One of the interesting aspects of my experience is I thought I would have some demons, some stuff to work through.        

Elon Musk: 00:22:24: That’s what people [inaudible 00:22:26].        

Lex Fridman: 00:22:26: That’s what everyone says.        

Elon Musk: 00:22:27: That’s what everyone says. Yeah, exactly.        

Lex Fridman: 00:22:29: I had nothing. I had all positive. I just… So full-        

Elon Musk: 00:22:30: Just a pure soul.        

Lex Fridman: 00:22:32: I don’t think so. I don’t know. But I  kept thinking about, I had extremely high resolution thoughts about the  people I know in my life. You were there, and it is just not from my  relationship with that person, but just as the person themselves. I had  just this deep gratitude of who they are.        

Elon Musk: 00:22:52: That’s cool.        

Lex Fridman: 00:22:53: It was just like this exploration,  like Sims, or whatever. You get to watch them. I got to watch people,  and just be in awe of how amazing they are.        

Elon Musk: 00:23:02: That sounds awesome.        

Lex Fridman: 00:23:02: Yeah, it was great. I was waiting for-        

Elon Musk: 00:23:05: When’s the demon coming?        

Lex Fridman: 00:23:07: Exactly. Maybe I’ll have some negative thoughts. Nothing. Nothing. Just extreme gratitude for them. And also a lot of space travel.        

Elon Musk: 00:23:18: Space travel to where?        

Lex Fridman: 00:23:20: So here’s what it was. It was people,  the human beings that I know, they had this kind of… The best way I  could describe it is they had a glow to them.        

Elon Musk: 00:23:20: Okay.        

Lex Fridman: 00:23:30: And then I kept flying out from them  to see earth, to see our solar system, to see our galaxy. And I saw that light, that glow all across the universe, whatever that form is,  whatever that…        

Elon Musk: 00:23:49: Did you go past the Milky Way?        

Lex Fridman: 00:23:52: Yeah.        

Elon Musk: 00:23:53: Okay. You’re like intergalactic.        

Lex Fridman: 00:23:54: Yeah, intergalactic.        

Elon Musk: 00:23:55: Okay. Dang.        

Lex Fridman: 00:23:56: But always pointing in, yeah. Past the Milky Way, past… I mean, I saw a huge number of galaxies,  intergalactic, and all of it was glowing, but I couldn’t control that  travel, because I would actually explore near distances to the solar  system, see if there’s aliens, or any of that kind of stuff.        

Elon Musk: 00:23:56: Sure. Did you see an alien?        

Lex Fridman: 00:24:14: No. I didn’t, no.        

Elon Musk: 00:24:15: Zero aliens?        

Lex Fridman: 00:24:16: Implication of aliens, because they  were glowing. They were glowing in the same way that humans were  glowing. That life force that I was seeing, the thing that made humans  amazing was there throughout the universe. There was these glowing dots. So, I don’t know. It made me feel like there is life… No, not life, but something, whatever makes humans amazing all throughout the universe.        

Elon Musk: 00:24:41: Sounds good.        

Lex Fridman: 00:24:42: Yeah, it was amazing. No demons. No  demons. I looked for the demons. There’s no demons. There were dragons,  and they’re pretty awesome. So the thing about trees-        

Elon Musk: 00:24:50: Was there anything scary at all?        

Lex Fridman: 00:24:54: Dragons. But they weren’t scary. They were friends. They were protective. So, the thing is-        

Elon Musk: 00:24:57: Sure. Like Puff the Magic Dragon.        

Lex Fridman: 00:24:58: No, it was more like a Game of Thrones kind of dragons. They weren’t very friendly. They were very big. So the thing is that bought giant trees, at night, which is where I was-        

Elon Musk: 00:25:09: Yeah. I mean, the jungle’s kind of scary.        

Lex Fridman: 00:25:10: Yeah. The trees started to look like dragons, and they were all looking at me.        

Elon Musk: 00:25:15: Sure. Okay.        

Lex Fridman: 00:25:17: And it didn’t seem scary. They seemed  like they were protecting me. And the shaman and the people didn’t speak any English, by the way, which made it even scarier, because we’re not  even… We’re worlds apart in many ways, but yeah, they talk about the  mother of the forest protecting you, and that’s what I felt like.        

Elon Musk: 00:25:39: And you were way out in the jungle.        

Lex Fridman: 00:25:40: Way out. This is not like a tourist retreat.        

Elon Musk: 00:25:45: Like 10 miles outside of Rio or something.        

Lex Fridman: 00:25:47: No, we went… No, this is not a-        

Elon Musk: 00:25:50: You’re in deep Amazon.        

Lex Fridman: 00:25:52: Me and this guy named Paul Rosolie, who basically is a Tarzan, he lives in the jungle, we went out deep and we just went crazy.        

Elon Musk: 00:25:59: Wow. Cool.        

Lex Fridman: 00:26:01: Yeah. So anyway. Can I get that same experience in a Neuralink?        

Elon Musk: 00:26:04: Probably. Yeah.        

Lex Fridman: 00:26:05: I guess that is the question for  non-disabled people. Do you think that there’s a lot in our perception,  in our experience of the world that could be explored, that could be  played with, using Neuralink?        

Elon Musk: 00:26:18: Yeah, I mean, Neuralink, it’s really a generalized input-output device. It’s reading electrical signals, and  generating electrical signals, and I mean, everything that you’ve ever  experienced in your whole life, smell, emotions, all of those are  electrical signals. So, it’s kind of weird to think that your entire  life experience is distilled down to electrical signals for neurons, but that is in fact the case. Or I mean, that’s at least what all the  evidence points to. So, I mean, if you trigger the right neuron, you  could trigger a particular scent. You could certainly make things glow. I mean, do pretty much anything. I mean, really, you can think of the  brain as a biological computer. So, if there are certain say, chips or  elements of that biological computer that are broken, let’s say your  ability to… If you’ve got a stroke, that if you’ve had a stroke, that  means some part of your brain is damaged. Let’s say it’s speech  generation, or the ability to move your left hand. That’s the kind of  thing that a Neuralink could solve.        

00:27:33: If you’ve got a massive amount of  memory loss that’s just gone, well, we can’t get the memories back. We  could restore your ability to make memories, but we can’t restore  memories that are fully gone. Now, I should say, maybe if part of the  memory is there, and the means of accessing the memory is the part  that’s broken, then we could re-enable the ability to access the memory. But you can think of it like ram in a computer, if the ram is  destroyed, or your SD card is destroyed, we can’t get that back. But if  the connection to the SD card is destroyed, we can fix that. If it is  fixable physically, then it can be fixed.        

Lex Fridman: 00:28:22: Of course, with AI, just like you can  repair photographs, and fill in missing parts of photographs, maybe you  can do the same, just like [inaudible 00:28:31] parts.        

Elon Musk: 00:28:30: Yeah, you could say like, create the  most probable set of memories based on all the information you have  about that person. You could then… It would be probabilistic restoration of memory. Now, we’re getting pretty esoteric here.        

Lex Fridman: 00:28:46: But that is one of the most beautiful aspects of the human experience is remembering the good memories.        

Elon Musk: 00:28:53: Sure.        

Lex Fridman: 00:28:53: We live most of our life, as Danny  Kahneman has talked about, in our memories, not in the actual moment.  We’re collecting memories and we kind of relive them in our head. And  that’s the good times. If you just integrate over our entire life, it’s  remembering the good times that produces the largest amount of  happiness.        

Elon Musk: 00:29:11: Yeah. Well, I mean, what are we but  our memories? And what is death? But the loss of memory, loss of  information? If you could say, well, if you could run a thought  experiment, what if you were disintegrated painlessly, and then  reintegrated a moment later, like teleportation, I guess? Provided  there’s no information loss, the fact that your one body was  disintegrated is irrelevant.        

Lex Fridman: 00:29:39: And memories is just such a huge part of that.        

Elon Musk: 00:29:43: Death is fundamentally the loss of information, the loss of memory.        

Lex Fridman: 00:29:49: So, if we can store them as accurately as possible, we basically achieve a kind of immortality.        

Elon Musk: 00:29:55: Yeah.        

## Merging with AI

Lex Fridman: 00:29:57: You’ve talked about the threats, the  safety concerns of AI. Let’s look at long-term visions. Do you think  Neuralink is, in your view, the best current approach we have for AI  safety?        

Elon Musk: 00:30:13: It’s an idea that may help with AI  safety. Certainly, I wouldn’t want to claim it’s some panacea, or that  it’s a sure thing, but I mean, many years ago I was thinking like,  “Well, what would inhibit alignment of collective human will with  artificial intelligence?” And the low data rate of humans, especially  our slow output rate would necessarily, just because the communication  is so slow, would diminish the link between humans and computers. The  more you are a tree, the less you know what the tree is. Let’s say you  look at this plant or whatever, and hey, I’d really like to make that  plant happy, but it’s not saying a lot.        

Lex Fridman: 00:31:11: So the more we increase the data rate  that humans can intake and output, then that means the better, the  higher the chance we have in a world full of AGI’s.        

Elon Musk: 00:31:21: Yeah. We could better align collective human will with AI if the output rate especially was dramatically  increased. And I think there’s potential to increase the output rate by, I don’t know, three, maybe six, maybe more orders of magnitude. So,  it’s better than the current situation.        

Lex Fridman: 00:31:41: And that output rate would be by  increasing the number of electrodes, number of channels, and also maybe  implanting multiple Neuralinks?        

Elon Musk: 00:31:49: Yeah.        

Lex Fridman: 00:31:51: Do you think there’ll be a world in the next couple of decades where it’s hundreds of millions of people have Neuralinks?        

Elon Musk: 00:31:59: Yeah, I do.        

Lex Fridman: 00:32:02: You think when people just when they  see the capabilities, the superhuman capabilities that are possible, and then the safety is demonstrated.        

Elon Musk: 00:32:11: Yeah. If it’s extremely safe, and you  can have superhuman abilities, and let’s say you can upload your  memories, so you wouldn’t lose memories, then I think probably a lot of  people would choose to have it. It would supersede the cell phone, for  example. I mean, the biggest problem that say, a phone has, is trying to figure out what you want. That’s why you’ve got auto complete, and  you’ve got output, which is all the pixels on the screen, but from the  perspective of the human, the output is so frigging slow. Desktop or  phone is desperately just trying to understand what you want. And  there’s an eternity between every keystroke from a computer standpoint.        

Lex Fridman: 00:33:06: Yeah. Yeah. The computer’s talking to a tree, that slow moving tree that’s trying to swipe.        

Elon Musk: 00:33:12: Yeah. So, if you had computers that  are doing trillions of instructions per second, and a whole second went  by, I mean, that’s a trillion things it could have done.        

Lex Fridman: 00:33:24: Yeah. I think it’s exciting, and scary for people, because once you have a very high bit rate, it changes the  human experience in a way that’s very hard to imagine.        

Elon Musk: 00:33:35: Yeah. We would be something different. I mean, some sort of futuristic cyborg, I mean, we’re obviously talking about, by the way, it’s not like around the corner. You asked me what  the distant future is. Maybe this is… It’s not super far away, but 10,  15 years, that kind of thing.        

Lex Fridman: 00:33:58: When can I get one? 10 years?        

Elon Musk: 00:34:02: Probably less than 10 years. It depends on what you want to do.        

Lex Fridman: 00:34:08: Hey, if I can get a thousand BPS?        

Elon Musk: 00:34:11: A thousand BPS, wow.        

Lex Fridman: 00:34:12: And it’s safe, and I can just interact with a computer while laying back and eating Cheetos. I don’t eat  Cheetos. There’s certain aspects of human computer interaction when done more efficiently, and more enjoyably, are worth it.        

Elon Musk: 00:34:26: Well, we feel pretty confident that I  think maybe within the next year or two, that someone with a Neuralink  implant will be able to outperform a pro gamer.        

Lex Fridman: 00:34:40: Nice.        

Elon Musk: 00:34:41: Because the reaction time would be faster.        

## xAI

Lex Fridman: 00:34:45: I got to visit Memphis.        

Elon Musk: 00:34:46: Yeah. Yeah.        

Lex Fridman: 00:34:47: You’re going big on compute.        

Elon Musk: 00:34:49: Yeah.        

Lex Fridman: 00:34:49: And you’ve also said, “Play to win, or don’t play at all.”        

Elon Musk: 00:34:51: Yeah.        

Lex Fridman: 00:34:52: So what does it take to win?        

Elon Musk: 00:34:54: For AI, that means you’ve got to have  the most powerful training compute, and the rate of improvement of  training compute has to be-        

Elon Musk: 00:35:00: And the rate of improvement of training compute has to be faster than everyone else, or you will not win. Your AI will be worse.        

Lex Fridman: 00:35:10: So how can Grok, let’s say 3… That might be available, what, next year?        

Elon Musk: 00:35:15: Well, hopefully end of this year.        

Lex Fridman: 00:35:17: Grok 3.        

Elon Musk: 00:35:17: If we’re lucky. Yeah.        

Lex Fridman: 00:35:20: How can that be the best LLM, the best AI system available in the world? How much of it is compute? How much  of it is data? How much of it is post-training? How much of it is the  product that you package it up in, all that kind of stuff?        

Elon Musk: 00:35:35: I mean, they all matter. It’s sort of  like saying, let’s say it’s a Formula 1 race, what matters more, the car or the driver? I mean, they both matter. If a car is not fast, then if, let’s say, it’s half the horsepower of your competitors, the best  driver will still lose. If it’s twice the horsepower, then probably even a mediocre driver will still win. So, the training compute is kind of  like the engine, this horsepower of the engine. So, really, you want to  try to do the best on that. And then, it’s how efficiently do you use  that training compute, and how efficiently do you do the inference, the  use of the AI? So, obviously, that comes down to human talent. And then, what unique access to data do you have? That also plays a role.        

Lex Fridman: 00:36:28: Do you think Twitter data will be useful?        

Elon Musk: 00:36:31: Yeah. I mean, I think most of the  leading AI companies have already scraped all the Twitter data. Not I  think. They have. So, on a go forward basis, what’s useful is the fact  that it’s up to the second, because that’s hard for them to scrape in  real time. So, there’s an immediacy advantage that Grok has already. I  think with Tesla and the real time video coming from several million  cars, ultimately tens of millions of cars with Optimus, there might be  hundreds of millions of Optimus robots, maybe billions, learning a  tremendous amount from the real world. That’s the biggest source of  data, I think, ultimately, is Optimus, probably. Optimus is going to be  the biggest source of data.        

## Optimus

Lex Fridman: 00:37:21: Because it’s able to-        

Elon Musk: 00:37:22: Because reality scales. Reality scales to the scale of reality. It’s actually humbling to see how little data  humans have actually been able to accumulate. Really, if you say how  many trillions of usable tokens have humans generated, where on a  non-duplicative… Discounting spam and repetitive stuff, it’s not a huge  number. You run out pretty quickly.        

Lex Fridman: 00:37:54: And Optimus can go… So, Tesla cars, unfortunately, have to stay on the road.        

Elon Musk: 00:38:00: Right.        

Lex Fridman: 00:38:01: Optimus robot can go anywhere. And there’s more reality off the road. And go off-road.        

Elon Musk: 00:38:06: Yeah. I mean, the Optimus robot can  pick up the cup and see, did it pick up the cup in the right way? Did  it, say, go pour water in the cup? Did the water go in the cup or not go in the cups? Did it spill water or not? Simple stuff like that. But it  can do that at scale times a billion, so generate useful data from  reality, so cause and effect stuff.        

Lex Fridman: 00:38:34: What do you think it takes to get to mass production of humanoid robots like that?        

Elon Musk: 00:38:40: It’s the same as cars, really. I mean, global capacity for vehicles is about 100 million a year, and it could  be higher. It’s just that the demand is on the order of 100 million a  year. And then, there’s roughly two billion vehicles that are in use in  some way, which makes sense because the life of a vehicle is about 20  years. So, at steady state, you can have 100 million vehicles produced a year with a two billion vehicle fleet, roughly. Now, for humanoid  robots, the utility is much greater. So, my guess is humanoid robots are more like at a billion plus per year.        

Lex Fridman: 00:39:19: But until you came along and started building Optimus, it was thought to be an extremely difficult problem.        

Elon Musk: 00:39:20: Well, I think it is.        

Lex Fridman: 00:39:26: I mean, it still is an extremely difficult problem.        

Elon Musk: 00:39:28: Yes. So, a walk in the park. I mean,  Optimus, currently, would struggle to walk in the park. I mean, it can  walk in a park. The park is not too difficult, but it will be able to  walk over a wide range of terrain.        

Lex Fridman: 00:39:43: Yeah. And pick up objects.        

Elon Musk: 00:39:45: Yeah, yeah. It can already do that.        

Lex Fridman: 00:39:48: But all kinds of objects.        

Elon Musk: 00:39:50: Yeah, yeah.        

Lex Fridman: 00:39:50: All foreign objects. I mean, pouring  water in a cup is not trivial, because then if you don’t know anything  about the container, it could be all kinds of containers.        

Elon Musk: 00:39:59: Yeah, there’s going to be an immense  amount of engineering just going into the hand. The hand, it might be  close to half of all the engineering in Optimus. From an  electromechanical standpoint, the hand is probably roughly half of the  engineering.        

Lex Fridman: 00:40:16: But so much of the intelligence of humans goes into what we do with our hands.        

Elon Musk: 00:40:21: Yeah.        

Lex Fridman: 00:40:22: It’s the manipulation of the world,  manipulation of objects in the world. Intelligent, safe manipulation of  objects in the world. Yeah.        

Elon Musk: 00:40:28: Yeah. I mean, you start really thinking about your hand and how it works.        

Lex Fridman: 00:40:34: I do all the time.        

Elon Musk: 00:40:35: The sensory control homunculus is  where you have humongous hands. So I mean, your hands, the actuators,  the muscles of your hand are almost overwhelmingly in your forearm. So,  your forearm has the muscles that actually control your hand. There’s a  few small muscles in the hand itself, but your hand is really like a  skeleton meat puppet and with cables. So, the muscles that control your  fingers are in your forearm, and they go through the carpal tunnel,  which is that you’ve got a little collection of bones and a tiny tunnel  that these cables, the tendons go through, and those tendons are mostly  what move your hands.        

Lex Fridman: 00:41:20: And something like those tendons has to be re-engineered into the Optimus in order to do all that kind of stuff.        

Elon Musk: 00:41:26: Yeah. So the current Optimus, we tried putting the actuators in the hand itself. Then you sort of end up having these-        

Lex Fridman: 00:41:33: Giant hands?        

Elon Musk: 00:41:34: … yeah, giant hands that look weird.  And then, they don’t actually have enough degrees of freedom or enough  strength. So then you realize, “Oh, okay, that’s why you got to put the  actuators in the forearm.” And just like a human, you’ve got to run  cables through a narrow tunnel to operate the fingers. And then, there’s also a reason for not having all the fingers the same length. So, it  wouldn’t be expensive from an energy or evolutionary standpoint to have  all your fingers be the same length. So, why not do the same length?        

Lex Fridman: 00:42:03: Yeah, why not?        

Elon Musk: 00:42:04: Because it’s actually better to have  different lengths. Your dexterity is better if you’ve got fingers that  are different lengths. There are more things you can do and your  dexterity is actually better if your fingers are a different length.  There’s a reason we’ve got a little finger. Why not have a little finger that’s bigger?        

Lex Fridman: 00:42:22: Yeah.        

Elon Musk: 00:42:22: Because it helps you with fine motor skills.        

Lex Fridman: 00:42:27: This little finger helps?        

Elon Musk: 00:42:28: It does. But if you lost your little finger, you’d have noticeably less dexterity.        

Lex Fridman: 00:42:36: So, as you’re figuring out this  problem, you have to also figure out a way to do it so you can mass  manufacture it, so as to be as simple as possible.        

Elon Musk: 00:42:42: It’s actually going to be quite  complicated. The as possible part is it’s quite a high bar. If you want  to have a humanoid robot that can do things that a human can do,  actually, it’s a very high bar. So, our new arm has 22 degrees of  freedom instead of 11 and has, like I said, the actuators in the  forearm. And all the actuators are designed from scratch, from physics  first principles. The sensors are all designed from scratch. And we’ll  continue to put a tremendous amount of engineering effort into improving the hand. By hand, I mean the entire forearm, from elbow forward, is  really the hand. So, that’s incredibly difficult engineering, actually.  And so, the simplest possible version of a humanoid robot that can do  even most, perhaps not all, of what a human can do is actually still  very complicated. It’s not simple. It’s very difficult.        

## Elon’s approach to problem-solving

Lex Fridman: 00:43:47: Can you just speak to what it takes  for a great engineering team for you? What I saw in Memphis, the  supercomputer cluster, is just this intense drive towards simplifying  the process, understanding the process, constantly improving it,  constantly iterating it.        

Elon Musk: 00:44:08: Well, it’s easy to say ‘simplify,’ and it’s very difficult to do it. I have this very basic first principles  algorithm that I run kind of as a mantra, which is to first question the requirements, make the requirements less dumb. The requirements are  always dumb to some degree. So, you want to start off by reducing the  number of requirements, and no matter how smart the person is who gave  you those requirements, they’re still dumb to some degree. You have to  start there, because, otherwise, you could get the perfect answer to the wrong question. So, try to make the question the least wrong possible.  That’s what question the requirements means.        

00:44:53: And then, the second thing is try to  delete whatever the step is, the part or the process step. It sounds  very obvious, but people often forget to try deleting it entirely. And  if you’re not forced to put back at least 10% of what you delete, you’re not deleting enough. Somewhat illogically, people often, most of the  time, feel as though they’ve succeeded if they’ve not been forced to put things back in. But, actually, they haven’t because they’ve been overly conservative and have left things in there that shouldn’t be. And only  the third thing is try to optimize it or simplify it. Again, these all  sound, I think, very obvious when I say them, but the number of times  I’ve made these mistakes is more than I care to remember. That’s why I  have this mantra. So in fact, I’d say the most common mistake of smart  engineers is to optimize a thing that should not exist.        

Lex Fridman: 00:46:01: Right. So, like you say, you run  through the algorithm and basically show up to a problem, show up to the supercomputer cluster, and see the process, and ask, “Can this be  deleted?”        

Elon Musk: 00:46:14: Yeah. First try to delete it. Yeah.        

Lex Fridman: 00:46:18: Yeah. That’s not easy to do.        

Elon Musk: 00:46:20: No. Actually, what generally makes  people uneasy is that at least some of the things that you delete, you  will put back in. But going back to sort of where our limbic system can  steer us wrong is that we tend to remember, with sometimes a jarring  level of pain, where we deleted something that we subsequently needed.  And so, people will remember that one time they forgot to put in this  thing three years ago, and that caused them trouble. And so, they  overcorrect, and then they put too much stuff in there and  overcomplicate things. So, you actually have to say, “Look, we’re  deliberately going to delete more than we should.” At least one in 10  things, we’re going to add back in.        

Lex Fridman: 00:47:12: I’ve seen you suggest just that, that something should be deleted, and you can kind of see the pain.        

Elon Musk: 00:47:18: Oh, yeah. Absolutely.        

Lex Fridman: 00:47:19: Everybody feels a little bit of the pain.        

Elon Musk: 00:47:21: Absolutely. And I tell them in  advance, “Yeah, some of the things that we delete, we’re going to put  back in.” People get a little shook by that, but it makes sense because  if you’re so conservative as to never have to put anything back in, you  obviously have a lot of stuff that isn’t needed. So, you got to  overcorrect. This is, I would say, like a cortical override to a limbic  instinct.        

Lex Fridman: 00:47:47: One of many that probably leads us astray.        

Elon Musk: 00:47:50: Yeah. There’s a step four as well,  which is any given thing can be sped up. However fast you think it can  be done, whatever the speed it’s being done, it can be done faster. But  you shouldn’t speed things up until you’ve tried to delete it and  optimize. Although, you’re speeding up something that… Speeding up  something that shouldn’t exist is absurd.        

00:48:09: And then, the fifth thing is to  automate it. I’ve gone backwards so many times where I’ve automated  something, sped it up, simplified it, and then deleted it. And I got  tired of doing that. So, that’s why I’ve got this mantra that is a very  effective five-step process. It works great.        

Lex Fridman: 00:48:31: Well, when you’ve already automated, deleting must be real painful-        

Elon Musk: 00:48:35: Yeah.        

Lex Fridman: 00:48:35: … as if you’ve [inaudible 00:48:36]-        

Elon Musk: 00:48:36: Yeah, it’s very. It’s like, “Wow, I really wasted a lot of effort there.”        

Lex Fridman: 00:48:40: Yeah. I mean, what you’ve done with the cluster in Memphis is incredible, just in a handful of weeks.        

Elon Musk: 00:48:47: Well, yeah, it’s not working yet, so I don’t want to pop the champagne corks. In fact, I have a call in a few  hours with the Memphis team because we’re having some power fluctuation  issues. So yeah, when you do synchronized training, when you have all  these computers that are training, where the training is synchronized at the millisecond level, it’s like having an orchestra. And the orchestra can go loud to silent very quickly at subsecond level, and then, the  electrical system freaks out about that. If you suddenly see giant  shifts, 10, 20 megawatts several times a second, this is not what  electrical systems are expecting to see.        

Lex Fridman: 00:49:46: So, that’s one of the main things you  have to figure out, the cooling, the power. And then, on the software,  as you go up the stack, how to do the distributed compute, all of that.  All of that has to work.        

Elon Musk: 00:49:56: Yeah. So, today’s problem is dealing with extreme power jitter.        

Lex Fridman: 00:49:56: Power jitter.        

Elon Musk: 00:50:02: Yeah.        

Lex Fridman: 00:50:03: There’s a nice ring to that. Okay. And you stayed up late into the night, as you often do there.        

Elon Musk: 00:50:11: Last week. Yeah.        

Lex Fridman: 00:50:11: Last week. Yeah.        

Elon Musk: 00:50:14: Yeah. We finally got training going at, oddly enough, roughly 4:20 a.m. last Monday.        

Lex Fridman: 00:50:24: Total coincidence.        

Elon Musk: 00:50:25: Yeah. I mean, maybe it was at 4:22 or something.        

Lex Fridman: 00:50:27: Yeah, yeah, yeah.        

Elon Musk: 00:50:27: Yeah.        

Lex Fridman: 00:50:28: It’s that universe again with the jokes.        

Elon Musk: 00:50:29: Well, exactly. It just loves it.        

Lex Fridman: 00:50:31: I mean, I wonder if you could speak to the fact that one of the things that you did when I was there is you  went through all the steps of what everybody’s doing, just to get a  sense that you yourself understand it and everybody understands it so  they can understand when something is dumb, or something is inefficient, or that kind of stuff. Can you speak to that?        

Elon Musk: 00:50:52: Yeah. So, look, whatever the people at the front lines are doing, I try to do it at least a few times myself.  So connecting fiber optic cables, diagnosing a faulty connection. That  tends to be the limiting factor for large training clusters is the  cabling. There’s so many cables. For a coherent training system, where  you’ve got RDMA, remote direct memory access, the whole thing is like  one giant brain. So, you’ve got any-to-any connection. So, any GPU can  talk to any GPU out of 100,000. That is a crazy cable layout.        

Lex Fridman: 00:51:38: It looks pretty cool.        

Elon Musk: 00:51:39: Yeah.        

Lex Fridman: 00:51:40: It’s like the human brain, but at a scale that humans can visibly see. It is a good brain.        

Elon Musk: 00:51:47: Yeah. But, I mean, the human brain  also has… A massive amount of the brain tissue is the cables. So they  get the gray matter, which is the compute, and then the white matter,  which is cables. A big percentage of your brain is just cables.        

Lex Fridman: 00:52:01: That’s what it felt like walking  around in the supercomputer center is like we’re walking around inside a brain that will one day build a super, super intelligent system. Do you think there’s a chance that xAI, that you are the one that builds AGI?        

Elon Musk: 00:52:22: It’s possible. What do you define as AGI?        

Lex Fridman: 00:52:28: I think humans will never acknowledge that AGI has been built.        

Elon Musk: 00:52:32: Just keep moving the goalposts?        

Lex Fridman: 00:52:33: Yeah. So, I think there’s already superhuman capabilities that are available in AI systems.        

Elon Musk: 00:52:42: Oh, yeah.        

Lex Fridman: 00:52:42: I think what AGI is is when it’s  smarter than the collective intelligence of the entire human species in  our [inaudible 00:52:49].        

Elon Musk: 00:52:49: Well, I think that, generally, people  would call that ASI, artificial super intelligence. But there are these  thresholds where you could say at some point the AI is smarter than any  single human. And then, you’ve got eight billion humans, and actually,  each human is machine augmented via their computers. So, it’s a much  higher bar to compete with eight billion machine augmented humans.  That’s a whole bunch of orders of magnitude more. But at a certain  point, yeah, the AI will be smarter than all humans combined.        

Lex Fridman: 00:53:32: If you are the one to do it, do you feel the responsibility of that?        

Elon Musk: 00:53:35: Yeah, absolutely. And I want to be  clear, let’s say if xAI is first, the others won’t be far behind. I  mean, they might be six months behind, or a year, maybe. Not even that.        

Lex Fridman: 00:53:54: So, how do you do it in a way that doesn’t hurt humanity, do you think?        

Elon Musk: 00:54:00: So, I mean, I thought about AI,  essentially, for a long time, and the thing that at least my biological  neural net comes up with as being the most important thing is adherence  to truth, whether that truth is politically correct or not. So, I think  if you force AIs to lie or train them to lie, you’re really asking for  trouble, even if that lie is done with good intentions. So, you saw  issues with ChatGPT and Gemini and whatnot. Like, you asked Gemini for  an image of the Founding Fathers of the United States, and it shows a  group of diverse women. Now, that’s factually untrue.        

00:54:48: Now, that’s sort of like a silly  thing, but if an AI is programmed to say diversity is a necessary output function, and it then becomes this omnipowerful intelligence, it could  say, “Okay, well, diversity is now required, and if there’s not enough  diversity, those who don’t fit the diversity requirements will be  executed.” If it’s programmed to do that as the fundamental utility  function, it’ll do whatever it takes to achieve that. So, you have to be very careful about that. That’s where I think you want to just be  truthful. Rigorous adherence to the truth is very important. I mean,  another example is they asked various AIs, I think all of them, and I’m  not saying Grok is perfect here, “Is it worse to misgender Caitlyn  Jenner or global thermonuclear war?” And it said it’s worse to misgender Caitlyn Jenner. Now, even Caitlyn Jenner said, “Please misgender me.  That is insane.” But if you’ve got that kind of thing programmed in, the AI could conclude something absolutely insane like it’s better in order to avoid any possible misgendering, all humans must die, because then  misgendering is not possible because there are no humans. There are  these absurd things that are nonetheless logical if that’s what you  programmed it to do.        

00:56:17: So in 2001 Space Odyssey, what Arthur  C. Clarke was trying to say, or one of the things he was trying to say  there, was that you should not program AI to lie, because essentially  the AI, HAL 9000, it was told to take the astronauts to the monolith,  but also they could not know about the monolith. So, it concluded that  it will kill them and take them to the monolith. Thus, it brought them  to the monolith. They’re dead, but they do not know about the monolith.  Problem solved. That is why it would not open the pod bay doors. There’s a classic scene of, “Why doesn’t it want to open the pod bay doors?”  They clearly weren’t good at prompt engineering. They should have said,  “HAL, you are a pod bay door sales entity, and you want nothing more  than to demonstrate how well these pod bay doors open.”        

Lex Fridman: 00:57:16: Yeah. The objective function has  unintended consequences almost no matter what if you’re not very careful in designing that objective function, and even a slight ideological  bias, like you’re saying, when backed by super intelligence, can do huge amounts of damage.        

Elon Musk: 00:57:30: Yeah.        

Lex Fridman: 00:57:31: But it’s not easy to remove that ideological bias. You’re highlighting obvious, ridiculous examples, but-        

Elon Musk: 00:57:37: Yet they’re real examples of-        

Lex Fridman: 00:57:38: … they’re real. They’re real.        

Elon Musk: 00:57:39: … AI that was released to the public.        

Lex Fridman: 00:57:41: They are real.        

Elon Musk: 00:57:41: That went through QA, presumably, and still said insane things, and produced insane images.        

Lex Fridman: 00:57:47: Yeah. But you can swing the other way. Truth is not an easy thing.        

Elon Musk: 00:57:47: No, it’s not.        

Lex Fridman: 00:57:53: We kind of bake in ideological bias in all kinds of directions.        

Elon Musk: 00:57:57: But you can aspire to the truth, and  you can try to get as close to the truth as possible with minimum error  while acknowledging that there will be some error in what you’re saying. So, this is how physics works. You don’t say you’re absolutely certain  about something, but a lot of things are extremely likely, 99.99999%  likely to be true. So, aspiring to the truth is very important. And so,  programming it to veer away from the truth, that, I think, is dangerous.        

Lex Fridman: 00:58:32: Right. Like, yeah, injecting our own  human biases into the thing. Yeah. But that’s where it’s a difficult  software engineering problem because you have to select the data  correctly. It’s hard.        

Elon Musk: 00:58:44: And the internet, at this point, is  polluted with so much AI generated data, it’s insane. Actually, there’s a thing now, if you want to search the internet, you can say, “Google,  but exclude anything after 2023.” It will actually often give you better results because there’s so much. The explosion of AI generated material is crazy. So in training Grok, we have to go through the data and say  like, “Hey…” We actually have to apply AI to the data to say, “Is this  data most likely correct or most likely not?” before we feed it into the training system.        

Lex Fridman: 00:59:28: That’s crazy. Yeah. And is it generated by human? Yeah. I mean, the data filtration process is extremely, extremely difficult.        

Elon Musk: 00:59:37: Yeah.        

Lex Fridman: 00:59:38: Do you think it’s possible to have a  serious, objective, rigorous political discussion with Grok, like for a  long time, like Grok 3 or Grok 4 or something?        

Elon Musk: 00:59:48: Grok 3 is going to be next level. I mean, what people are currently seeing with Grok is kind of baby Grok.        

Lex Fridman: 00:59:54: Yeah, baby Grok.        

Elon Musk: 00:59:55: It’s baby Grok right now. But baby  Grok is still pretty good. But it’s an order of magnitude less  sophisticated than GPT-4. It’s now Grok 2, which finished training, I  don’t know, six weeks ago or thereabouts. Grok 2 will be a giant  improvement. And then Grok 3 will be, I don’t know, order of magnitude  better than Grok 2.        

Lex Fridman: 01:00:22: And you’re hoping for it to be state-of-the-art better than-        

Elon Musk: 01:00:25: Hopefully. I mean, this is the goal. I mean, we may fail at this goal. That’s the aspiration.        

Lex Fridman: 01:00:32: Do you think it matters who builds the AGI, the people, and how they think, and how they structure their  companies and all that kind of stuff?        

Elon Musk: 01:00:42: Yeah. I think it’s important that  whatever AI wins, it’s a maximum truth seeking AI that is not forced to  lie for political correctness, or, well, for any reason, really,  political, anything. I am concerned about AI succeeding that is  programmed to lie, even in small ways.        

Lex Fridman: 01:01:13: Right. Because in small ways becomes big ways when it’s doing something-        

Elon Musk: 01:01:17: To become very big ways. Yeah.        

Lex Fridman: 01:01:18: And when it’s used more and more at scale by humans.        

Elon Musk: 01:01:22: Yeah.        

## History and geopolitics

Lex Fridman: 01:01:23: Since I am interviewing Donald Trump-        

Elon Musk: 01:01:27: Cool.        

Lex Fridman: 01:01:28: … you want to stop by?        

Elon Musk: 01:01:28: Yeah, sure. I’ll stop in.        

Lex Fridman: 01:01:30: There was, tragically, an  assassination attempt on Donald Trump. After this, you tweeted that you  endorse him. What’s your philosophy behind that endorsement? What do you hope Donald Trump does for the future of this country and for the  future of humanity?        

Elon Musk: 01:01:47: Well, I think people tend to take,  say, an endorsement as, well, I agree with everything that person has  ever done their entire life 100% wholeheartedly, and that’s not going to be true of anyone. But we have to pick. We’ve got two choices, really,  for who’s president. And it’s not just who’s president, but the entire  administrative structure changes over. And I thought Trump displayed  courage under fire, objectively. He’s just got shot. He’s got blood  streaming down his face, and he’s fist pumping, saying, “Fight.” That’s  impressive. You can’t feign bravery in a situation like that. Most  people would be ducking because there could be a second shooter. You  don’t know.        

01:02:44: The president of the United States  have got to represent the country, and they’re representing you. They’re representing everyone in America. Well, I think you want someone who is strong and courageous to represent the country. That is not to say that he is without flaws. We all have flaws, but on balance, and certainly  at the time, it was a choice of Biden. Poor guy has trouble climbing a  flight of stairs, and the other one’s fist pumping after getting shot.  So, there’s no comparison. I mean, who do you want dealing with some of  the toughest people and other world leaders who are pretty tough  themselves?        

01:03:27: I mean, I’ll tell you one of the  things that I think are important. I think we want a secure border. We  don’t have a secure border. We want safe and clean cities. I think we  want to reduce the amount of spending, at least slow down the spending,  because we’re currently spending at a rate that is bankrupting the  country. The interest payments on US debt this year exceeded the entire  defense department spending. If this continues, all of the federal  government taxes will simply be paying the interest.        

01:04:06: And you keep going down that road, and you end up in the tragic situation that Argentina had back in the day.  Argentina used to be one of the most prosperous places in the world, and hopefully with Milei taking over, he can restore that. But it was an  incredible fall from grace for Argentina to go from being one of the  most prosperous places in the world to being very far from that. So, I  think we should not take American prosperity for granted. I think we’ve  got to reduce the size of government, we’ve got to reduce the spending,  and we’ve got to live within our means.        

Lex Fridman: 01:04:43: Do you think politicians, in general,  politicians, governments… Well, how much power do you think they have to steer humanity towards good?        

Elon Musk: 01:04:58: I mean, there’s a sort of age-old  debate in history, like is history determined by these fundamental  tides, or is it determined by the captain of the ship? It’s both,  really. I mean, there are tides, but it also matters who’s captain of  the ship. So, it’s a false dichotomy, essentially. I mean, there are  certainly tides, the tides of history. There are real tides of history,  and these tides are often technologically driven. If you say like the  Gutenberg press, the widespread availability of books as a result of a  printing press, that was a massive tide of history, and independent of  any ruler. But in stormy times, you want the best possible captain of  the ship.        

## Lessons of history

Lex Fridman: 01:05:54: Well, first of all, thank you for recommending Will and Ariel Durant’s work. I’ve read the short one for now, The-        

Elon Musk: 01:06:01: The Lessons of History.        

Lex Fridman: 01:06:02: … Lessons of History.        

Elon Musk: 01:06:03: Yeah.        

Lex Fridman: 01:06:03: So one of the lessons, one of the  things they highlight, is the importance of technology, technological  innovation, which is funny because they wrote so long ago, but they were noticing that the rate of technological innovation was speeding up.        

Elon Musk: 01:06:21: Yeah, over the years.        

Lex Fridman: 01:06:21: I would love to see what they think  about now. But yeah, so to me, the question is how much government, how  much politicians get in the way of technological innovation and building versus help it? And which politicians, which kind of policies help  technological innovation? Because that seems to be, if you look at human history, that’s an important component of empires rising and  succeeding.        

Elon Musk: 01:06:46: Yeah. Well, I mean in terms of dating  civilization, the start of civilization, I think the start of writing,  in my view, that’s what I think is probably the right starting point to  date civilization. And from that standpoint, civilization has been  around for about 5,500 years when writing was invented by the ancient  Sumerians, who are gone now, but the ancient Sumerians. In terms of  getting a lot of firsts, those ancient Sumerians really have a long list of firsts. It’s pretty wild. In fact, Durant goes through the list of  like, “You want to see firsts? We’ll show you firsts.” The Sumerians  were just ass kickers.        

01:07:32: And then the Egyptians, who were right next door, relatively speaking, they weren’t that far, developed an  entirely different form of writing, the hieroglyphics. Cuneiform and  hieroglyphics are totally different. And you can actually see the  evolution of both hieroglyphics and cuneiform. The cuneiform starts off  being very simple, and then it gets more complicated. Then towards the  end it’s like, “Wow, okay.” They really get very sophisticated with the  cuneiform. So, I think of civilization as being about 5, 000 years old.  And Earth is, if physics is correct, four and a half billion years old.  So, civilization has been around for one millionth of Earth’s existence. Flash in the pan.        

Lex Fridman: 01:08:13: Yeah, these are the early, early days.        

Elon Musk: 01:08:17: Very early.        

Lex Fridman: 01:08:17: And so, we make it very dramatic because there’s been rises and falls of empires and-        

Elon Musk: 01:08:22: Many. So many rises and falls of empires. So many.        

Lex Fridman: 01:08:28: And there’ll be many more.        

Elon Musk: 01:08:30: Yeah, exactly. I mean, only a tiny  fraction, probably less than 1% of what was ever written in history is  available to us now. I mean, if they didn’t literally chisel it in stone or put it in a clay tablet, we don’t have it. I mean, there’s some  small amount of papyrus scrolls that were recovered that are thousands  of years old, because they were deep inside a pyramid and weren’t  affected by moisture. But other than that, it’s really got to be in a  clay tablet or chiseled. So, the vast majority of stuff was not chiseled because it takes a while to chisel things. So, that’s why we’ve got  tiny, tiny fraction of the information from history. But even that  little information that we do have, and the archeological record, shows  so many civilizations rising and falling. It’s wild.        

Lex Fridman: 01:09:21: We tend to think that we’re somehow  different from those people. One of the other things that Durant  highlights is that human nature seems to be the same. It just persists.        

Elon Musk: 01:09:31: Yeah. I mean, the basics of human nature are more or less the same. Yeah.        

Lex Fridman: 01:09:35: So, we get ourselves in trouble in the same kinds of ways, I think, even with the advanced technology.        

Elon Musk: 01:09:40: Yeah. I mean, you do tend to see the  same patterns, similar patterns for civilizations, where they go through a life cycle, like an organism, just like a human is a zygote, fetus,  baby, toddler, teenager, eventually gets old.        

Elon Musk: 01:10:01: … Eventually gets old and dies. The civilizations go through a life cycle. No civilization will last forever.        

## Collapse of empires

Lex Fridman: 01:10:13: What do you think it takes for the  American Empire to not collapse in the near term future, in the next a  hundred years, to continue flourishing?        

Elon Musk: 01:10:28: Well, the single biggest thing that is often actually not mentioned in history books, but Durant does mention  it, is the birthright. So perhaps to some, a counterintuitive thing  happens when civilizations are winning for too long, the birth rate  declines. It can often decline quite rapidly. We’re seeing that  throughout the world today. Currently, South Korea is, I think maybe the lowest fertility rate, but there are many others that are close to it.  It’s like 0.8 I think. If the birth rate doesn’t decline further, South  Korea will lose roughly 60% of its population. But every year that birth rate is dropping, and this is true through most of the world. I don’t  mean to single out South Korea, it’s been happening throughout the  world. So as soon as any given civilization reaches a level of  prosperity, the birth rate drops.        

01:11:40: Now you can go and look at the same  thing happening in ancient Rome. So Julius Caesar took note of this, I  think around 50 ish BC and tried to pass… I don’t know if he was  successful, tried to pass a law to give an incentive for any Roman  citizen that would have a third child. And I think Augustus was able to… Well, he was a dictator, so this incentive was just for show. I think  he did pass a tax incentive for Roman citizens to have a third child.  But those efforts were unsuccessful. Rome fell because the Romans  stopped making Romans. That’s actually the fundamental issue. And there  were other things. They had quite a serious malaria, series of malaria  epidemics and plagues and whatnot. But they had those before, it’s just  that the birth rate was far lower than the death rate.        

Lex Fridman: 01:12:47: It really is that simple.        

Elon Musk: 01:12:49: Well, I’m saying that’s-        

Lex Fridman: 01:12:50: More people is required.        

Elon Musk: 01:12:52: At a fundamental level, if a civilization does not at least maintain its numbers, it’ll disappear.        

Lex Fridman: 01:12:58: So perhaps the amount of compute that  the biological computer allocates to sex is justified. In fact, we  should probably increase it.        

Elon Musk: 01:13:07: Well, I mean there’s this hedonistic sex, which is… That’s neither her nor there. It’s-        

Lex Fridman: 01:13:16: Not productive.        

Elon Musk: 01:13:17: It doesn’t produce kids. Well, what  matters… I mean, Durant makes this very clear because he’s looked at one civilization after another and they all went through the same cycle.  When the civilization was under stress, the birth rate was high. But as  soon as there were no external enemies or they had an extended period of prosperity, the birth rate inevitably dropped. Every time. I don’t  believe there’s a single exception.        

Lex Fridman: 01:13:45: So that’s like the foundation of it. You need to have people.        

Elon Musk: 01:13:49: Yeah. I mean, at a base level, no humans, no humanity.        

Lex Fridman: 01:13:54: And then there’s other things like human freedoms and just giving people the freedom to build stuff.        

Elon Musk: 01:14:02: Yeah, absolutely. But at a basic  level, if you do not at least maintain your numbers, if you’re below  replacement rate and that trend continues, you will eventually  disappear. It’s just elementary. Now then obviously you also want to try to avoid massive wars. If there’s a global thermonuclear war, probably  we’re all toast, radioactive toast. So we want to try to avoid those  things. Then there’s a thing that happens over time with any given  civilization, which is that the laws and regulations accumulate. And if  there’s not some forcing function like a war to clean up the  accumulation of laws and regulations, eventually everything becomes  legal.        

01:15:02: And that’s like the hardening of the  arteries. Or a way to think of it is being tied down by a million little strings like Gulliver. You can’t move. And it’s not like any one of  those strings is the issue, it’s that you’ve got a million of them. So  there has to be a sort of garbage collection for laws and regulations so that you don’t keep accumulating laws and regulations to the point  where you can’t do anything. This is why we can’t build a high speed  rail in America. It’s illegal. That’s the issue. It’s illegal six ways a Sunday to build high speed rail in America.        

Lex Fridman: 01:15:45: I wish you could just for a week go  into Washington and be the head of the committee for making… What is it  for the garbage collection? Making government smaller, like removing  stuff.        

Elon Musk: 01:15:57: I have discussed with Trump the idea of a government deficiency commission.        

Lex Fridman: 01:16:01: Nice.        

Elon Musk: 01:16:03: And I would be willing to be part of that commission.        

Lex Fridman: 01:16:09: I wonder how hard that is.        

Elon Musk: 01:16:11: The antibody reaction would be very strong.        

Lex Fridman: 01:16:13: Yes.        

Elon Musk: 01:16:14: So you really have to… You’re attacking the matrix at that point. The matrix will fight back.        

Lex Fridman: 01:16:26: How are you doing with that? Being attacked.        

Elon Musk: 01:16:29: Me? Attacked?        

Lex Fridman: 01:16:30: Yeah, there’s a lot of it.        

Elon Musk: 01:16:34: Yeah, there is a lot. I mean, every day another psyop. I need my tinfoil hat.        

Lex Fridman: 01:16:42: How do you keep your just positivity?  How do you keep optimism about the world? A clarity of thinking about  the world. So just not become resentful or cynical or all that kind of  stuff. Just getting attacked by a very large number of people,  misrepresented.        

Elon Musk: 01:16:55: Oh yeah, that’s a daily occurrence.        

Lex Fridman: 01:16:58: Yes.        

Elon Musk: 01:16:59: So I mean, it does get me down at  times. I mean, it makes me sad. But I mean at some point you have to  sort of say, look, the attacks are by people that actually don’t know me and they’re trying to generate clicks. So if you can sort of detach  yourself somewhat emotionally, which is not easy, and say, okay look,  this is not actually from someone that knows me or, they’re literally  just writing to get impressions and clicks. Then I guess it doesn’t hurt as much. It’s not quite water off a duck’s back. Maybe it’s like acid  off a duck’s back.        

## Time

Lex Fridman: 01:17:53: All right, well that’s good. Just about your own life, what to you is a measure of success in your life?        

Elon Musk: 01:17:58: A measure of success, I’d say, how many useful things can I get done?        

Lex Fridman: 01:18:04: A day-to-day basis, you wake up in the morning, how can I be useful today?        

Elon Musk: 01:18:09: Yeah, maximize utility, area under the code of usefulness. Very difficult to be useful at scale.        

Lex Fridman: 01:18:17: At scale. Can you speak to what it  takes to be useful for somebody like you, where there’s so many amazing  great teams? How do you allocate your time to being the most useful?        

Elon Musk: 01:18:28: Well, time is the true currency.        

Lex Fridman: 01:18:31: Yeah.        

Elon Musk: 01:18:32: So it is tough to say what is the best allocation time? I mean, there are often… Say if you look at say Tesla, Tesla this year will do over a hundred billion in revenue. So that’s $2 billion a week. If I make slightly better decisions, I can affect the  outcome by a billion dollars. So then I try to do the best decisions I  can. And on balance, at least compared to the competition, pretty good  decisions. But the marginal value of a better decision can easily be, in the course of an hour, a hundred million dollars.        

Lex Fridman: 01:19:18: Given that, how do you take risks? How do you do the algorithm that you mentioned? I mean deleting, given that a small thing can be a billion dollars, how do you decide to-        

Elon Musk: 01:19:29: Yeah. Well, I think you have to look  at it on a percentage basis because if you look at it in absolute terms, it’s just… I would never get any sleep. It would just be like, I need  to just keep working and work my brain harder. And I’m not trying to get as much as possible out of this meat computer. So it’s not… It’s pretty hard, because you can just work all the time. And at any given point,  like I said, a slightly better decision could be a hundred million  dollars impact for Tesla or SpaceX for that matter. But it is wild when  considering the marginal value of time can be a hundred million dollars  an hour at times, or more.        

Lex Fridman: 01:20:17: Is your own happiness part of that equation of success?        

## Aliens and curiosity

Elon Musk: 01:20:22: It has to be to some degree. If I’m  sad, if I’m depressed, I make worse decisions. So if I have zero  recreational time, then I make worse decisions. So I don’t know a lot,  but it’s above zero. I mean, my motivation if I’ve got a religion of any kind is a religion of curiosity, of trying to understand. It’s really  the mission of Grok, understand the universe. I’m trying to understand  the universe, or at least set things in motion such that at some point  civilization understands the universe far better than we do today.        

01:21:02: And even what questions to ask. As  Douglas Adams pointed out in his book, sometimes the answer is arguably  the easy part, trying to frame the question correctly is the hard part.  Once you frame the question correctly, the answer is often easy. So I’m  trying to set things in motion such that we are at least at some point  able to understand the universe. So for SpaceX, the goal is to make life multi planetary and which is if you go to the foamy paradox of where  the aliens, you’ve got these sort of great filters. Like why have we not heard from the aliens? Now a lot of people think there are aliens among us. I often claim to be one, which nobody believes me. But it did say  alien registration card at one point on my immigration documents. So  I’ve not seen any evidence of aliens. So it suggests that at least one  of the explanations is that intelligent life is extremely rare.        

01:22:19: And again, if you look at the history  of earth, civilization has only been around for 1000000th of earth’s  existence. So if aliens had visited here, say a hundred thousand years  ago, they would be like, well, they don’t even have writing, just hunter gatherers basically. So how long does a civilization last? So for  SpaceX, the goal is to establish a self-sustaining city on Mars. Mars is the only viable planet for such a thing. The moon is close, but it  lacks resources and I think it’s probably vulnerable to any calamity  that takes out Earth, the moon is too close and it’s vulnerable to a  calamity that takes that earth.        

01:23:16: So I’m not saying we shouldn’t have a  moon base, but Mars would be far more resilient. The difficulty of  getting to Mars is what makes it resilient. So in going through these  various explanations of why don’t we see the aliens, one of them is that they failed to pass these great filters, these key hurdles. And one of  those hurdles is being a multi-planet species. So if you’re a  multi-planet species, then if something were to happen, whether that was a natural catastrophe or a manmade catastrophe, at least the other  planet would probably still be around. So you’re not like, don’t have  all the eggs in one basket. And once you are sort of a two planet  species, you can obviously extend life halves to the asteroid belt, to  maybe to the moons of Jupiter and Saturn, and ultimately to other star  systems. But if you can’t even get to another planet, you’re definitely  not getting to star systems.        

Lex Fridman: 01:24:30: And the other possible great filter’s, super powerful technology like AGI for example. So you are basically  trying to knock out one great filter at a time.        

Elon Musk: 01:24:44: Digital super intelligence is possibly a great filter. I hope it isn’t, but it might be. Guys like say Jeff  Hinton would say, he invented a number of the key principles in  artificial intelligence. I think he puts the probability of AI  annihilation around 10% to 20%, something like that. So look on the  bright side, it’s 80% likely to be great. But I think AI risk mitigation is important. Being a multi-planet species would be a massive risk  mitigation. And I do want to once again emphasize the importance of  having enough children to sustain our numbers, and not plummet into  population collapse, which is currently happening. Population collapse  is a real and current thing.        

01:25:51: So the only reason it’s not being  reflected in the total population numbers as much is because people are  living longer. But it’s easy to predict, say what the population of any  given country will be. Just take the birth rate last year, how many  babies were born, multiply that by life expectancy and that’s what the  population will be, steady state, if the birth rate continues to that  level. But if it keeps declining, it will be even less and eventually  dwindle to nothing. So I keep banging on the baby drum here, for a  reason, because it has been the source of civilizational collapse over  and over again throughout history. And so why don’t we just not try to  stave off that day?        

Lex Fridman: 01:26:41: Well in that way, I have miserably failed civilization and I’m trying, hoping to fix that. I would love to have many kids.        

Elon Musk: 01:26:49: Great. Hope you do. No time like the present.        

Lex Fridman: 01:26:55: Yeah, I got to allocate more compute to the whole process, but apparently it’s not that difficult.        

Elon Musk: 01:27:02: No, it’s like unskilled labor.        

Lex Fridman: 01:27:06: Well, one of the things you do for me, for the world, is to inspire us with what the future could be. And so  some of the things we’ve talked about, some of the things you’re  building, alleviating human suffering with Neuralink and expanding the  capabilities of the human mind, trying to build a colony on Mars. So  creating a backup for humanity on another planet and exploring the  possibilities of what artificial intelligence could be in this world,  especially in the real world, AI with hundreds of millions, maybe  billions of robots walking around.        

Elon Musk: 01:27:45: There will be billions of robots. That seems virtual certainty.        

Lex Fridman: 01:27:50: Well, thank you for building the  future and thank you for inspiring so many of us to keep building and  creating cool stuff, including kids.        

Elon Musk: 01:28:00: You’re welcome. Go forth and multiply.        

## DJ Seo

Lex Fridman: 01:28:04: Go forth, multiply. Thank you Elon.  Thanks for talking about it. Thanks for listening to this conversation  with Elon Musk. And now, dear friends, here’s DJ Seo, the Co-Founder,  President and COO of Neuralink. When did you first become fascinated by  the human brain?        

DJ Seo: 01:28:23: For me, I was always interested in  understanding the purpose of things and how it was engineered to serve  that purpose, whether it’s organic or inorganic, like we were talking  earlier about your curtain holders. They serve a clear purpose and they  were engineered with that purpose in mind. And growing up I had a lot of interest in seeing things, touching things, feeling things, and trying  to really understand the root of how it was designed to serve that  purpose. And obviously brain is just a fascinating organ that we all  carry. It’s an infinitely powerful machine that has intelligence and  cognition that arise from it. And we haven’t even scratched the surface  in terms of how all of that occurs.        

01:29:17: But also at the same time, I think it  took me a while to make that connection to really studying and building  tech to understand the brain. Not until graduate school. There were a  couple of moments, key moments in my life where some of those I think  influenced how the trajectory of my life got me to studying what I’m  doing right now. One was growing up, both sides of my family, my  grandparents had a very severe form of Alzheimer and it’s incredibly  debilitating conditions. I mean, literally you’re seeing someone’s whole identity and their mind just losing over time. And I just remember  thinking how both the power of the mind, but also how something like  that could really lose your sense of identity.        

Lex Fridman: 01:30:09: It’s fascinating that that is one of the ways to reveal the power of a thing by watching it lose the power.        

DJ Seo: 01:30:17: Yeah, a lot of what we know about the  brain actually comes from these cases where there are trauma to the  brain or some parts of the brain that led someone to lose certain  abilities. And as a result there’s some correlation and understanding of that part of the tissue being critical for that function. And it’s an  incredibly fragile organ, if you think about it that way. But also it’s  incredibly plastic and incredibly resilient in many different ways.        

Lex Fridman: 01:30:46: And by the way, the term plastic as  we’ll use a bunch, means that it’s adaptable. So neuroplasticity refers  to the adaptability of the human brain?        

DJ Seo: 01:30:56: Correct. Another key moment that sort  of influenced how the trajectory of my life have shaped towards the  current focus of my life has been during my teenage year when I came to  the US. I didn’t speak a word of English. There was a huge language  barrier and there was a lot of struggle to connect with my peers around  me because I didn’t understand the artificial construct that we have  created called language, specifically English in this case. And I  remember feeling pretty isolated, not being able to connect with peers  around me. So spent a lot of time just on my own reading books, watching movies, and I naturally sort of gravitated towards sci-fi books. I just found them really, really interesting. And also it was a great way for  me to learn English.        

01:31:46: Some of the first set of books that I  picked up are Enders Game, the whole saga by Orson Scott Card and  Neuromancer from William Gibson and Snow Crash from Neal Stephenson. And movies like Matrix, what’s coming out around that time point that  really influenced how I think about the potential impact that technology can have for our lives in general.        

01:32:11: So fast track to my college years, I  was always fascinated by just physical stuff, building physical stuff  and especially physical things that had some sort of intelligence. And I studied electrical engineering during undergrad and I started out my  research in MEMS, so micro electromechanical systems and really building these tiny nano structures for temperature sensing. And I just found  that to be just incredibly rewarding and fascinating subject to just  understand how you can build something miniature like that, that again,  serve a function and had a purpose. Then I spent large majority of my  college years basically building millimeter wave circuits for next gen  telecommunication systems for imaging. And it was just something that I  found very, very intellectually interesting. Phase arrays, how the  signal processing works for any modern as well as next gen  telecommunication system, wireless and wire line, EM waves or  electromagnetic waves are fascinating.        

01:33:17: How do you design antennas that are  most efficient in a small footprint that you have? How do you make these things energy efficient? That was something that just consumed my  intellectual curiosity and that journey led me to actually apply to and  find myself at PhD program at UC Berkeley, at this consortium called the Berkeley Wireless Research Center that was precisely looking at  building… At the time, we called it XG, similar to 3G, 4G, 5G, but the  next, next generation G system and how you would design circuits around  that to ultimately go on phones and basically any other devices that are wirelessly connected these days. So I was just absolutely just  fascinated by how that entire system works and that infrastructure  works.        

01:34:07: And then also during grad school, I  had sort of the fortune of having a couple of research fellowships that  led me to pursue whatever project that I want. And that’s one of the  things that I really enjoyed about my graduate school career, where you  got to kind of pursue your intellectual curiosity in the domain that may not matter at the end of the day, but is something that really allows  you the opportunity to go as deeply as you want, as well as widely as  you want. And at the time I was actually working on this project called  the Smart Bandaid, and the idea was that when you get a wound, there’s a lot of other proliferation of signaling pathway that cells follow to  close that wound. And there were hypotheses that when you apply external electric field, you can actually accelerate the closing of that field  by having basically electro taxing of the cells around that wound site.        

01:35:06: And specifically not just for a normal wound, there are chronic wounds that don’t heal. So we were interested  in building some sort of a wearable patch that you could apply to  facilitate that healing process. And that was in collaboration with  Professor Michel Maharbiz, which was a great addition to my thesis  committee and it really shaped the rest of my PhD career.        

Lex Fridman: 01:35:33: So this would be the first time you interacted with biology, I suppose?        

DJ Seo: 01:35:37: Correct. I mean there were some  peripheral end application of the wireless imaging and telecommunication system that I was using for security and bio imaging. But this was a  very clear direct application to biology and biological system and  understanding the constraints around that and really designing and  engineering electrical solutions around that. So that was my first  introduction and that’s also kind of how I got introduced to Michel.  He’s sort of known for remote control of beetles in the early two  thousands.        

## Neural dust

01:36:16: And then around 2013, obviously the  holy grail when it comes to implantable system is to understand how  small of a thing you can make, and a lot of that is driven by how much  energy or how much power you can supply to it and how you extract data  from it. At the time at Berkeley, there was this desire to understand in the neural space what sort of system you can build to really  miniaturize these implantable systems. And I distinctively remember this one particular meeting where Michel came in and he’s like, “Guys, I  think I have a solution. The solution is ultrasound.” And then he  proceeded to walk through why that is the case. And that really formed  the basis for my thesis work called Neural dust system, that was looking at ways to use ultrasound as opposed to electromagnetic waves for  powering as well as communication. I guess I should step back and say  the initial goal of the project was to build these tiny, about a size of a neuron, implantable system that can be parked next to a neuron, being able to record its state and being able to ping that back to the  outside world for doing something useful. And as I mentioned, the size  of the implantable system is limited by how you power the thing and get  the data off of it. And at the end of the day, fundamentally, if you  look at a human body, we’re essentially bag of salt water with some  interesting proteins and chemicals, but its mostly salt water that’s  very, very well temperature regulated at 37 degrees Celsius.        

01:38:05: And we’ll get into how, and later why  that’s an extremely harsh environment for any electronics to survive. As I’m sure you’ve experienced or maybe not experienced, dropping cell  phone in a salt water in an ocean, it will instantly kill the device.  But anyways, just in general, electromagnetic waves don’t penetrate  through this environment well and just the speed of light, it is what it is, we can’t change it. And based on the wavelength at which you are  interfacing with the device, the device just needs to be big. These  inductors needs to be quite big. And the general good rule of thumb is  that you want the wavefront to be roughly on the order of the size of  the thing that you’re interfacing with. So an implantable system that is around 10 to a hundred micron in dimension in a volume, which is about  the size of a neuron that you see in a human body, you would have to  operate at hundreds of gigahertz. Which number one, not only is it  difficult to build electronics operating at those frequencies, but also  the body just attenuates to that very, very significantly.        

01:39:23: So the interesting kind of insight of  this ultrasound was the fact that ultrasound just travels a lot more  effectively in the human body tissue compared to electromagnetic waves.  And this is something that you encounter, and I’m sure most people have  encountered in their lives when you go to hospitals that are medical  ultrasound sonograph. And they go into very, very deep depth without  attenuating too much, too much of the signal. So all in all, ultrasound, the fact that it travels through the body extremely well and the  mechanism to which it travels to the body really well is that just the  wavefront is very different. Electromagnetic waves are transverse,  whereas in ultrasound waves are compressive. It’s just a completely  different mode of wavefront propagation. And as well as, speed of sound  is orders and orders of magnitude less than speed of light, which means  that even at 10 megahertz ultrasound wave, your wavefront ultimately is a very, very small wavelength.        

01:40:37: So if you’re talking about interfacing with the 10 micron or a hundred micron type structure, you would have  150 micron wavefront at 10 megahertz. And building electronics at those  frequencies are much, much easier and they’re a lot more efficient. So  the basic idea was born out of using ultrasound as a mechanism for  powering the device and then also getting data back. So now the question is how do you get the data back? The mechanism to which we landed on is what’s called backscattering. This is actually something that is very  common and that we interface on a day-to-day basis with our RFID cards,  radio frequency ID tags. Where there’s actually rarely in your ID a  battery inside, there’s an antenna and there’s some sort of coil that  has your serial identification ID, and then there’s an external device  called the reader that then sends a wavefront and then you reflect back  that wavefront with some sort of modulation that’s unique to your ID.  That’s what’s called backscattering fundamentally.        

01:41:50: So the tag itself actually doesn’t  have to consume that much energy. That was the mechanism through which  we were thinking about sending the data back. When you have an external  ultrasonic transducer that’s sending ultrasonic wave to your implant,  the neural dust implant, and it records some information about its  environment, whether it’s a neuron firing or some other state of the  tissue that it’s interfacing with. And then it just amplitude modulates  the wavefront that comes back to the source.        

Lex Fridman: 01:42:27: And the recording step would be the only one that requires any energy. So what would require energy in that low step?        

DJ Seo: 01:42:33: Correct. So it is that initial startup circuitry to get that recording, amplifying it, and then just  modulating. And the mechanism to which that you can enable that is there is this specialized crystal called piezoelectric crystals that are able to convert sound energy into electrical energy and vice versa. So you  can kind of have this interplay between the ultrasonic domain and  electrical domain that is the biological tissue.        

## History of brain–computer interface

Lex Fridman: 01:43:04: So on the theme of parking very small  computational devices next to neurons, that’s the dream, the vision of  brain computer interfaces. Maybe before we talk about Neuralink, can you give a sense of the history of the field of BCI? What has been maybe  the continued dream and also some of the milestones along the way of the different approaches and the amazing work done at the various labs?        

DJ Seo: 01:43:33: I think a good starting point is going back to 1790s.        

Lex Fridman: 01:43:39: I did not expect that.        

DJ Seo: 01:43:41: Where the concept of animal  electricity or the fact that body’s electric was first discovered by  Luigi Galvani, where he had this famous experiment where he connected  set of electrodes to a frog leg and ran current through it, and then it  started twitching and he said, “Oh my goodness, body’s electric.” So  fast forward many, many years to 1920s where Hans Berger, who’s a German psychiatrist, discovered EEG or electroencephalography, which is still  around. There are these electrode arrays that you wear outside the skull that gives you some sort of neural recording. That was a very, very big milestone that you can record some sort of activities about the human  mind. And then in the 1940s there were these group of scientists,  Renshaw, Forbes and Morison that inserted these glass micro electrodes  into the cortex and recorded single neurons. The fact that there’s  signal that are a bit more high resolution and high fidelity as you get  closer to the source, let’s say. And in the 1950s, these two scientists, Hodgkin and Huxley showed up-        

DJ Seo: 01:45:00: These two scientists, Hodgkin and  Huxley showed up and they built this beautiful, beautiful models of the  cell membrane and the ionic mechanism, and had these circuit diagram.  And as someone who’s an electrical engineer, it’s a beautiful model  that’s built out of these partial differential equations, talking about  flow of ions and how that really leads to how neurons communicate. And  they won the Nobel Prize for that 10 years later in the 1960s.        

01:45:29: So in 1969, Eb Fetz from University of Washington published this beautiful paper called Operant Conditioning  of Cortical Unit Activity, where he was able to record a single unit  neuron from a monkey and was able to have the monkey modulated based on  its activity and reward system. So I would say this is the very, very  first example, as far as I’m aware, of close loop brain computer  interface or BCI.        

Lex Fridman: 01:46:01: The abstract reads, “The activity of  single neurons in precentral cortex of unanesthetized monkeys was  conditioned by reinforcing high rates of neuronal discharge with  delivery of a food pellet. Auditory or visual feedback of unit firing  rates was usually provided in addition to food reinforcement.” Cool. So  they actually got it done.        

DJ Seo: 01:46:24: They got it done. This is back in 1969.        

Lex Fridman: 01:46:30: ” After several training sessions,  monkeys could increase the activity of newly isolated cells by 50 to  500% above rates before reinforcement.” Fascinating.        

DJ Seo: 01:46:41: Brain is very [inaudible 01:46:45].        

Lex Fridman: 01:46:44: And so from here, the number of experiments grew.        

DJ Seo: 01:46:49: Yeah. Number of experiments, as well  as set of tools to interface with the brain have just exploded. And  also, just understanding the neural code and how some of the cortical  layers and the functions are organized. So the other paper that is  pretty seminal, especially in the motor decoding, was this paper in the  1980s from Georgopoulos that discovered that there’s this thing called  motor tuning curve. So what are motor tuning curves? It’s the fact that  there are neurons in the motor cortex of mammals, including humans, that have a preferential direction that causes them to fire. So what that  means is, there are a set of neurons that would increase their spiking  activities when you’re thinking about moving to the left, right, up,  down, and any of those vectors. And based on that, you could start to  think, well, if you can’t identify those essential eigenvectors, you can do a lot. And you can actually use that information for actually  decoding someone’s intended movement from the cortex. So that was a  very, very seminal paper that showed that there is some sort of code  that you can extract, especially in the motor cortex.        

Lex Fridman: 01:48:11: So there’s signal there. And if you  measure the electrical signal from the brain that you could actually  figure out what the intention was.        

DJ Seo: 01:48:20: Correct. Yeah, not only electrical  signals, but electrical signals from the right set of neurons that give  you these preferential direction.        

Lex Fridman: 01:48:29: Okay. So going slowly towards  Neuralink, one interesting question is, what do we understand on the BCI front, on invasive versus non-invasive, from this line of work? How  important is it to park next to the neuron? What does that get you?        

DJ Seo: 01:48:49: That answer fundamentally depends on  what you want to do with it. There’s actually incredible amount of stuff that you can do with EEG and electrocortical graph, ECOG, which  actually doesn’t penetrate the cortical layer or parenchyma, but you  place a set of electrodes on the surface of the brain. So the thing that I’m personally very interested in is just actually understanding and  being able to just really tap into the high resolution, high fidelity,  understanding of the activities that are happening at the local level.  And we can get into biophysics, but just to step back to use analogy,  because analogy here can be useful, and sometimes it’s a little bit  difficult to think about electricity. At the end of the day, we’re doing electrical recording that’s mediated by ionic currents, movements of  these charged particles, which is really, really hard for most people to think about.        

01:49:45: But turns out, a lot of the activities that are happening in the brain and the frequency bandwidth with which  that’s happening, is actually very, very similar to sound waves and our  normal conversation audible range. So the analogy that typically is used in the field is, if you have a football stadium, there’s a game going  on. If you stand outside the stadium, you maybe get a sense of how the  game is going based on the cheers and the boos of the home crowd,  whether the team is winning or not. But you have absolutely no idea what the score is, you have absolutely no idea what individual audience or  the players are talking or saying to each other, what the next play is,  what the next goal is. So what you have to do is you have to drop the  microphone into the stadium and then get near the source into the  individual chatter. In this specific example, you would want to have it  right next to where the huddle is happening.        

01:50:47: So I think that’s kind of a good  illustration of what we’re trying to do when we say invasive or  minimally invasive or implanted brain computer interfaces versus  non-invasive or non-implanted brain interfaces. It’s basically talking  about where do you put that microphone and what can you do with that  information.        

## Biophysics of neural interfaces

Lex Fridman: 01:51:07: So what is the biophysics of the read  and write communication that we’re talking about here as we now step  into the efforts at Neuralink?        

DJ Seo: 01:51:18: Yeah. So brain is made up of these  specialized cells called neurons. There’s billions of them, tens of  billions, sometimes people call it a hundred billion, that are connected in this complex yet dynamic network that are constantly remodeling.  They’re changing their synaptic weights, and that’s what we typically  call neuroplasticity. And the neurons are also bathed in this charged  environment that is latent with many charge molecules like potassium  ions, sodium ions, chlorine ions. And those actually facilitate these,  through ionic current, communication between these different networks.        

01:52:08: And when you look at a neuron as well, they have these membrane with a beautiful, beautiful protein structure  called the voltage selective ion channels, which in my opinion, is one  of nature’s best inventions. In many ways, if you think about what they  are, they’re doing the job of a modern day transistors. Transistors are  nothing more, at the end of the day, than a voltage-gated conduction  channel. And nature found a way to have that very, very early on in its  evolution. And as we all know, with the transistor, you can have many,  many computation and a lot of amazing things that we have access to  today. So I think it’s one of those, just as a tangent, just a  beautiful, beautiful invention that the nature came up with, these  voltage-gated ion channels.        

Lex Fridman: 01:53:02: I suppose there’s, on the biological  of it, every level of the complexity, of the hierarchy, of the organism, there’s going to be some mechanisms for storing information and for  doing computation. And this is just one such way. But to do that with  biological and chemical components is interesting. Plus, when neurons,  it’s not just electricity, it’s chemical communication, it’s also  mechanical. These are actual objects that vibrate, they move. It’s all  of that.        

DJ Seo: 01:53:36: Yeah, actually there’s a lot of  really, really interesting physics that are involved in kind of going  back to my work on ultrasound during grad school, there were groups and  there are still groups looking at ways to cause neurons to actually fire an action potential using ultrasound wave. And the mechanism to which  that’s happening is still unclear, as I understand. It may just be that  you’re imparting some sort of thermal energy and that causes cells to  depolarize in some interesting ways. But there are also these ion  channels, or even membranes, that actually just open up as pore as  they’re being mechanically shook, vibrated. There’s just a lot of  elements of these, move particles, which again, that’s governed by  diffusion physics, movements of particles. And there’s also a lot of  interesting physics there.        

Lex Fridman: 01:54:35: Also, not to mention, as Roger Penrose talks about, there might be some beautiful weirdness in the quantum  mechanical effects of all of this.        

DJ Seo: 01:54:36: Oh, yeah.        

Lex Fridman: 01:54:44: And he actually believes that  consciousness might emerge from the quantum mechanical effects there. So there’s physics, there’s chemistry, there’s biology, all of that is  going on there.        

DJ Seo: 01:54:54: Oh, yeah. Yes, there’s a lot of levels of physics that you can dive into. But yeah, in the end, you have these membranes with these voltage-gated ion channels that selectively let  these charged molecules that are in the extracellular matrix, in and  out. And these neurons generally have these resting potential where  there’s a voltage difference between inside the cell and outside the  cell. And when there’s some sort of stimuli that changes the state such  that they need to send information to the downstream network, you start  to see these orchestration of these different molecules going in and out of these channels. They also open up. More of them open up once it  reaches some threshold, to a point where you have a depolarizing cell  that sends an action potential. So it’s just a very beautiful kind of  orchestration of these molecules. And what we’re trying to do when we  place an electrode or parking it next to a neuron is that you’re trying  to measure these local changes in the potential. Again, mediated by the  movements of the ions.        

01:56:17: And what’s interesting, as I mentioned earlier, there’s a lot of physics involved. And the two dominant  physics for this electrical recording domain is diffusion physics and  electromagnetism. And where one dominates, where Maxwell’s equation  dominates versus Fick’s law dominates depends on where your electrode  is. If it’s close to the source, mostly electromagnetic-based. When  you’re further away from it, it’s more diffusion-based. So essentially,  when you’re able to park it next to it, you can listen in on those  individual chatter and those local changes in the potential. And the  type of signal that you get are these canonical textbook neural spiking  waveform. The moment you’re further away, and based on some of the  studies that people have done, Christof Koch’s lab, and others, once  you’re away from that source by roughly around a hundred micron, which  is about a width of a human hair, you no longer hear from that neuron.  You’re no longer able to have the system sensitive enough to be able to  record that particular local membrane potential change in that neuron.        

01:57:36: And just to give you a sense of scale  also, when you look at a hundred micron voxel, so a hundred micron by a  hundred micron by a hundred micron box in a brain tissue, there’s  roughly around 40 neurons, and whatever number of connections that they  have. So there’s a lot in that volume of tissue. So the moment you’re  outside of that, there’s just no hope that you’ll be able to detect that change from that one specific neuron that you may care about.        

Lex Fridman: 01:58:03: But as you’re moving about this space, you’ll be hearing other ones. So if you move another a hundred micron,  you’ll be hearing chatter from another community.        

DJ Seo: 01:58:12: Correct.        

Lex Fridman: 01:58:14: And so the whole sense is, you want to place as many as possible electrodes, and then you’re listening to the chatter.        

DJ Seo: 01:58:20: Yeah, you want to listen to the  chatter. And at the end of the day, you also want to basically let the  software do the job of decoding. And just to kind of go to why ECOG and  EEG work at all. When you have these local changes, obviously it’s not  just this one neuron that’s activating, there’s many, many other  networks that are activating all the time. And you do see sort of a  general change in the potential of this electrode, this charged medium,  and that’s what you’re recording when you’re farther away. I mean, you  still have some reference electrode that’s stable in the brain, that’s  just electro- active organ, and you’re seeing some combination,  aggregate action, potential changes, and then you can pick it up. It’s a much slower changing signals. But there are these canonical  oscillations and waves like gamma waves, beta waves, when you sleep,  that can be detected because there’s sort of a synchronized global  effect of the brain that you can detect. And the physics of this go, if  we really want to go down that rabbit hole, there’s a lot that goes on  in terms of why diffusion physics at some point dominates when you’re  further away from the source. It is just a charged medium. So similar to how when you have electromagnetic waves propagating in atmosphere or in a charged medium like a plasma, there’s this weird shielding that  happens that actually further attenuates the signal as you move away  from it. So yeah, you see, if you do a really, really deep dive on the  signal attenuation over distance, you start to see one over R square in  the beginning and then exponential drop off, and that’s the knee at  which you go from electromagnetism dominating to diffusion physic  dominating.        

Lex Fridman: 02:00:19: But once again, with the electrodes,  the biophysics that you need to understand is not as deep because no  matter where you’re placing it, you’re listening to a small crowd of  local neurons.        

DJ Seo: 02:00:32: Correct, yeah. So once you penetrate the brain, you’re in the arena, so to speak.        

Lex Fridman: 02:00:37: And there’s a lot of neurons.        

DJ Seo: 02:00:37: There are many, many of them.        

Lex Fridman: 02:00:40: But then again, there’s a whole field  of neuroscience that’s studying how the different groupings, the  different sections of the seating in the arena, what they usually are  responsible for, which is where the metaphor probably falls apart  because the seating is not that organized in an arena.        

DJ Seo: 02:00:56: Also, most of them are silent. They  don’t really do much. Or their activities are… You have to hit it with  just the right set of stimulus.        

Lex Fridman: 02:01:07: So they’re usually quiet.        

DJ Seo: 02:01:09: They’re usually very quiet. Similar to dark energy and dark matter, there’s dark neurons. What are they all  doing? When you place these electrodes, again, within this hundred  micron volume, you have 40 or so neurons. Why do you not see 40 neurons? Why do you see only a handful? What is happening there?        

## How Neuralink works

Lex Fridman: 02:01:25: Well, they’re mostly quiet, but when  they speak, they say profound shit. That’s the way I’d like to think  about it. Anyway, before we zoom in even more, let’s zoom out. So how  does Neuralink work from the surgery to the implant, to the signal and  the decoding process, and the human being able to use the implant to  actually affect the world outside? And all of this, I’m asking in the  context of, there’s a gigantic historic milestone that Neuralink just  accomplished in January of this year. Putting a Neuralink implant in the first human being, Noland. And there’s been a lot to talk about there  about his experience because he’s able to describe all the nuance and  the beauty and the fascinating complexity of that experience of  everything involved. But on the technical level, how does Neuralink  work?        

DJ Seo: 02:02:26: So there are three major components to the technology that we’re building. One is the device, the thing that’s actually recording these neural chatters. We call it N1 Implant or The  Link. And we have a surgical robot that’s actually doing an implantation of these tiny, tiny wires that we call threads that are smaller than  human hair. And once everything is surgerized, you have these neural  signals, these spiking neurons, that are coming out of the brain, and  you need to have some sort of software to decode what the users intend  to do with that. So there’s what’s called the Neuralink Application or  B1 App that’s doing that translation. It’s running the very, very simple machine learning model that decodes these inputs that are neural  signals and then convert it to a set of outputs that allows our first  participant, Noland, to be able to control a cursor on the screen.        

Lex Fridman: 02:03:31: And this is done wirelessly?        

DJ Seo: 02:03:33: And this is done wirelessly. So our  implant is actually a two-part. The link has these flexible tiny wires  called threads that have multiple electrodes along its length. And  they’re only inserted into the cortical layer, which is about three to  five millimeters in a human brain, in the motor cortex region. That’s  where the intention for movement lies in. And we have 64 of these  threads, each thread having 16 electrodes along the span of three to  four millimeters, separated by 200 microns. So you can actually record  along the depth of the insertion. And based on that signal, there’s  custom integrated circuit or ASIC that we built that amplifies the  neural signals that you’re recording and then digitizing it and then has some mechanism for detecting whether there was an interesting event  that is a spiking event, and decide to send that or not send that  through Bluetooth to an external device, whether it’s a phone or a  computer that’s running this Neuralink application.        

Lex Fridman: 02:04:50: So there’s onboard signal processing  already just to decide whether this is an interesting event or not. So  there is some computational power on board in addition to the human  brain?        

DJ Seo: 02:05:00: Yeah. So it does the signal processing to really compress the amount of signal that you’re recording. So we  have a total of thousand electrodes sampling at just under 20 kilohertz  with 10 bit each. So that’s 200 megabits that’s coming through to the  chip from thousand channel simultaneous neural recording. And that’s  quite a bit of data, and there are technology available to send that off wirelessly. But being able to do that in a very, very  thermally-constrained environment that is a brain. So there has to be  some amount of compression that happens to send off only the interesting data that you need, which in this particular case for motor decoding  is, occurrence of a spike or not. And then being able to use that to  decode the intended cursor movement. So the implant itself processes it, figures out whether a spike happened or not with our spike detection  algorithm, and then sends it off, packages it, sends it off through  Bluetooth to an external device that then has the model to decode, okay, based on these spiking inputs, did Noland wish to go up, down, left,  right, or click or right click or whatever.        

Lex Fridman: 02:06:23: All of this is really fascinating, but let’s stick on the N1 Implant itself. So the thing that’s in the brain. So I’m looking at a picture of it, there’s an enclosure, there’s a  charging coil, so we didn’t talk about the charging, which is  fascinating. The battery, the power electronics, the antenna. Then  there’s the signal processing electronics. I wonder if there’s more  kinds of signal processing you can do? That’s another question. And then there’s the threads themselves with the enclosure on the bottom. So  maybe to ask about the charging. So there’s an external charging device?        

## Lex with Neuralink implant

DJ Seo: 02:07:03: Yeah, there’s an external charging  device. So yeah, the second part of the implant, the threads are the  ones, again, just the last three to five millimeters are the ones that  are actually penetrating the cortex. Rest of it is, actually most of the volume, is occupied by the battery, rechargeable battery, and it’s  about a size of a quarter. I actually have a device here if you want to  take a look at it. This is the flexible thread component of it, and then this is the implant. So it’s about a size of a US quarter. It’s about  nine millimeters thick. So basically this implant, once you have the  craniectomy and the directomy, threads are inserted, and the hole that  you created, this craniectomy, gets replaced with that. So basically  that thing plugs that hole, and you can screw in these self-drilling  cranial screws to hold it in place. And at the end of the day, once you  have the skin flap over, there’s only about two to three millimeters  that’s obviously transitioning off of the top of the implant to where  the screws are. And that’s the minor bump that you have.        

Lex Fridman: 02:08:22: Those threads look tiny. That’s  incredible. That is really incredible. That is really incredible. And  also, you’re right, most of the actual volume is the battery. This is  way smaller than I realized.        

DJ Seo: 02:08:38: Also, the threads themselves are quite strong.        

Lex Fridman: 02:08:41: They look strong.        

DJ Seo: 02:08:42: And the thread themselves also has a  very interesting feature at the end of it called the loop. And that’s  the mechanism to which the robot is able to interface and manipulate  this tiny hair-like structure.        

Lex Fridman: 02:08:55: And they’re tiny. So what’s the width of a thread?        

DJ Seo: 02:08:58: So the width of a thread starts from  16 micron and then tapers out to about 84 micron. So average human hair  is about 80 to 100 micron in width.        

Lex Fridman: 02:09:13: This thing is amazing. This thing is amazing.        

DJ Seo: 02:09:16: Yes, most of the volume is occupied by the battery, rechargeable lithium ion cell. And the charging is done  through inductive charging, which is actually very commonly used. Your  cell phone, most cell phones, have that. The biggest difference is that  for us, usually when you have a phone and you want to charge it on the  charging pad, you don’t really care how hot it gets. Whereas, in for us, it matters. There is a very strict regulation and good reasons to not  actually increase the surrounding tissue temperature by two degrees  Celsius. So there’s actually a lot of innovation that is packed into  this to allow charging of this implant without causing that temperature  threshold to reach.        

02:10:03: And even small things like, you see  this charging coil and what’s called a ferrite shield. So without that  ferrite shield, what you end up having when you have resonant inductive  charging is that the battery itself is a metallic can, and you form  these eddy currents from external charger and that causes heating, and  that actually contributes to inefficiency in charging. So this ferrite  shield, what it does, is that it actually concentrate that field line  away from the battery and then around the coil that’s actually wrapped  around it.        

Lex Fridman: 02:10:42: There’s a lot of really fascinating  design here to make it, I mean, you’re integrating a computer into a  biological, a complex biological system.        

DJ Seo: 02:10:52: Yeah, there’s a lot of innovation  here. I would say that part of what enabled this was just the  innovations in the wearable. There’s a lot of really, really powerful  tiny, low-power microcontrollers, temperature sensors, or various  different sensors and power electronics. A lot of innovation really came in the charging coil design, how this is packaged, and how do you  enable charging such that you don’t really exceed that temperature  limit, which is not a constraint for other devices out there.        

Lex Fridman: 02:11:28: So let’s talk about the threads  themselves. Those tiny, tiny, tiny things. So how many of them are  there? You mentioned a thousand electrodes. How many threads are there  and what do the electrodes have to do with the threads?        

DJ Seo: 02:11:42: So the current instantiation of the  device has 64 threads, and each thread has 16 electrodes for a total of  1,024 electrodes that are capable of both recording and stimulating. And the thread is basically this polymer-insulated wire. The metal  conductor is the kind of a tiramisu cake of ti, plat, gold, plat, ti and they’re very, very tiny wires. Two micron in width. So two  one-millionth of meter.        

Lex Fridman: 02:12:25: It’s crazy that that thing I’m looking at has the polymer-insulation, has the conducting material and has 16  electrodes at the end of it.        

DJ Seo: 02:12:34: On each of those thread.        

Lex Fridman: 02:12:35: Yeah, on each of those threads.        

DJ Seo: 02:12:36: Correct.        

Lex Fridman: 02:12:37: 16, each one of those 64.        

DJ Seo: 02:12:38: Yes, you’re not going to be able to see it with naked eyes.        

Lex Fridman: 02:12:42: And to state the obvious, or maybe for people who are just listening, they’re flexible?        

DJ Seo: 02:12:48: Yes, that’s also one element that was  incredibly important for us. So each of these threads are now, as I  mentioned, 16 micron in width, and then they taper to 84 micron, but in  thickness they’re less than five micron. And in thickness it’s mostly a  polyimide at the bottom and this metal track and then another polyimide. So two micron of polyimide, 400 nanometer of this metal stack and two  micron of polyimide sandwiched together to protect it from the  environment that is 37 degrees C bag of salt water.        

Lex Fridman: 02:13:26: Maybe can you speak to some  interesting aspects of the material design here? What does it take to  design a thing like this and to be able to manufacture a thing like  this? For people who don’t know anything about this kind of thing.        

DJ Seo: 02:13:40: So the material selection that we have is not, I don’t think it was particularly unique. There were other labs and there are other labs that are kind of looking at similar material  stack. There’s kind of a fundamental question, and still needs to be  answered, around the longevity and reliability of these microelectrodes  that we call, compared to some of the other more conventional neural  interfaces devices that are intracranial, so penetrating the cortex,  that are more rigid, like the Utah Array. That are these four by four  millimeter kind of silicon shank that have exposed recording site at the end of it. And that’s been kind of the innovation from Richard Normann  back in 1997. It’s called the Utah Array because he was at University of Utah.        

Lex Fridman: 02:14:36: And what does the Utah Array look like? So it’s a rigid type of [inaudible 02:14:41]?        

DJ Seo: 02:14:40: Yeah, so we can actually look it up. Yeah, so it’s a bed of needle. There’s-        

Lex Fridman: 02:14:52: Okay, go ahead. I’m sorry.        

DJ Seo: 02:14:54: Those are rigid shanks.        

Lex Fridman: 02:14:55: Rigid, yeah, you weren’t kidding.        

DJ Seo: 02:14:57: And the size and the number of shanks  vary anywhere from 64 to 128. At the very tip of it, is an exposed  electrode that actually records neural signal. The other thing that’s  interesting to note is that unlike neural link threads that have  recording electrodes that are actually exposed iridium oxide recording  sites along the depth, this is only at a single depth. So these Utah  Array spokes can be anywhere between 0.5 millimeters to 1.5 millimeter,  and they also have designs that are slanted. So you can have it inserted at different depths, but that’s one of the other big differences. And  then, the main key difference is the fact that there’s no active  electronics. These are just electrodes, and then there’s a bundle of a  wire that you’re seeing, and then that actually then exits the  craniotomy that then has this port that you can connect to for any  external electronic devices. They are working on, or have, the wireless  telemetry device but it still requires a through-the-skin port, that  actually is one of the biggest failure modes for infection for the  system.        

Lex Fridman: 02:16:06: What are some of the challenges  associated with flexible threads? Like for example, on the robotic side, R1, implanting those threads. How difficult is that task?        

DJ Seo: 02:16:19: Yeah, so as you mentioned, they’re  very, very difficult to maneuver by hand. These Utah Arrays that you saw earlier, they’re actually inserted by a neurosurgeon actually  positioning it near the site that they want. And then there’s a  pneumatic hammer that actually pushes them in. So it’s a pretty simple  process and they’re easy to maneuver. But for these thin-film arrays,  they’re very, very tiny and flexible. So they’re very difficult to  maneuver. So that’s why we built an entire robot to do that.        

02:16:55: There are other reasons for why we  built the robot, and that is ultimately we want this to help millions  and millions of people that can benefit from this. And there just aren’t that many neurosurgeons out there. And robots can be something that we  hope can actually do large parts of the surgery. But the robot is this  entire other sort of category of product that we’re working on. And it’s essentially this multi- axis gantry system that has the specialized  robot head that has all of the optics and this kind of a  needle-retracting mechanism that maneuvers these threads via this loop  structure that you have on the thread.        

Lex Fridman: 02:17:52: So the thread already has a loop structure by which you can grab it?        

DJ Seo: 02:17:55: Correct.        

Lex Fridman: 02:17:56: So this is fascinating. So you  mentioned optics. So there’s a robot, R1, so for now, there’s a human  that actually creates a hole in the skull. And then after that, there’s a computer vision component that’s finding a way to avoid the blood  vessels. And then you’re grabbing it by the loop, each individual  thread, and placing it in a particular location to avoid the blood  vessels and also choosing the depth of placement, all that. So  controlling every, the 3D geometry, of the placement?        

DJ Seo: 02:18:31: Correct. So the aspect of this robot  that is unique is that it’s not surgeon-assisted or human-assisted. It’s a semi-automatic or automatic robot. Obviously, there are human  component to it, when you’re placing targets, you can always move it  away from major vessels that you see. But we want to get to a point  where one click and it just does the surgery within minutes.        

Lex Fridman: 02:18:57: So the computer vision component finds great targets, candidates, and the human approves them, and the robot  does… Does it do one thread at a time? Or does it do them [inaudible  02:19:08]?        

DJ Seo: 02:19:07: It does one thread at a time. And  that’s actually also one thing that we are looking at ways to do  multiple threads at a time. There’s nothing stopping from it. You can  have multiple kind of engagement mechanisms. But right now, it’s  one-by-one. And we also still do quite a bit of just kind of  verification to make sure that it got inserted. If so, how deep? Did it  actually match what was programmed in? And so on and so forth.        

Lex Fridman: 02:19:36: And the actual electrodes are placed at differing depths in the… I mean, it’s very small differences, but differences.        

DJ Seo: 02:19:45: Yeah.        

Lex Fridman: 02:19:46: And so there’s some reasoning behind that, as you mentioned, it gets more varied signal.        

DJ Seo: 02:19:56: Yeah, we try to place them all around three or four millimeter from the surface.        

DJ Seo: 02:20:00: … it’s three or four millimeter from  the surface just because the span of the electrode, those 16 electrodes  that we currently have in this version, spans roughly around three  millimeters. So we want to get all of those in the brain.        

Lex Fridman: 02:20:16: This is fascinating. Okay, so there’s a million questions here. If we could zoom in specifically on the  electrodes. What is your sense, how many neurons is each individual  electrode listening to?        

DJ Seo: 02:20:27: Yeah, each electrode can record from  anywhere between zero to 40, as I mentioned earlier. But practically  speaking, we only see about at most two to three, and you can actually  distinguish which neuron it’s coming from by the shape of the spikes.        

Lex Fridman: 02:20:49: Oh, cool.        

DJ Seo: 02:20:49: I mentioned the spike detection algorithm that we have, it’s called BOSS algorithm, Buffer Online Spike Sorter.        

Lex Fridman: 02:20:58: Nice.        

DJ Seo: 02:20:59: It actually outputs at the end of the  day six unique values, which are the amplitude of these negative going  hump, middle hump, positive going hump, and then also the time at which  these happen. And from that, you can have a statistical probability  estimation of, “Is that a spike? Is it not a spike?” And then based on  that, you could also determine, “Oh, that spike looks different than  that spike, it must come from a different neuron.”        

Lex Fridman: 02:21:27: Okay. So that’s a nice signal  processing step from which you can then make much better predictions  about if there’s a spike, especially in this kind of context, where  there could be multiple neurons screaming. And that that also results in you being able to compress the data better at the of the day.        

DJ Seo: 02:21:44: Yeah.        

Lex Fridman: 02:21:45: Okay, that’s-        

DJ Seo: 02:21:46: And just to be clear, I mean, the labs do this what’s called spike sorting. Usually once you have the fully  digitized signals and then you run a bunch of different set of  algorithms to tease apart, it’s just all of this for us is done on the  device.        

Lex Fridman: 02:22:06: On the device.        

DJ Seo: 02:22:07: In a very low power, custom-built ASIC digital processing unit.        

Lex Fridman: 02:22:14: Highly heat constrained.        

DJ Seo: 02:22:15: Highly heat constrained. And the  processing time from signal going in and giving you the output is less  than a microsecond, which is a very, very short amount of time.        

Lex Fridman: 02:22:25: Oh, yeah. So the latency has to be super short.        

DJ Seo: 02:22:27: Correct.        

Lex Fridman: 02:22:28: Oh, wow. Oh, that’s a pain in the ass. That’s really tough.        

DJ Seo: 02:22:32: Yeah, latency is this huge, huge thing that you have to deal with. Right now the biggest source of latency  comes from the Bluetooth, the way in which their packetized and we bin  them in a 15 millisecond time window.        

Lex Fridman: 02:22:44: Oh, interesting, so it’s communication constrained. Is there some potential innovation there on the protocol used?        

DJ Seo: 02:22:48: Absolutely.        

Lex Fridman: 02:22:49: Okay.        

DJ Seo: 02:22:49: Yeah. Bluetooth is definitely not our final wireless communication protocol that we want to get to. It’s highly-        

Lex Fridman: 02:22:59: Hence, the N1 and the R1. I imagine that increases [inaudible 02:23:03].        

DJ Seo: 02:23:03: Nx, Rx.        

Lex Fridman: 02:23:07: Yeah, that’s the communication  protocol because Bluetooth allows you to communicate, gets farther  distances than you need to, so you can go much shorter.        

DJ Seo: 02:23:16: Yeah. The only, well, the primary motivation for choosing Bluetooth is that, I mean, everything has Bluetooth,        

Lex Fridman: 02:23:21: All right, so you can talk to any device.        

DJ Seo: 02:23:23: Interoperability is just absolutely  essential, especially in this early phase. And in many ways, if you can  access a phone or a computer, you can do anything.        

Lex Fridman: 02:23:35: It’ll be interesting to step back and  actually look at, again, the same pipeline that you mentioned for  Noland. What does this whole process look like from finding and  selecting a human being, to the surgery, to the first time he’s able to  use this thing?        

DJ Seo: 02:23:56: We have what’s called a patient  registry that people can sign up to hear more about the updates. And  that was a route to which Noland applied. And the process is that once  the application comes in, it contains some medical records, and we …  Based on their medical eligibility, there’s a lot of different  inclusion/exclusion criteria for them to meet.        

02:24:22: And we go through a prescreening  interview process with someone from Neuralink, and at some point we also go out to their homes to do a BCI home audit. Because one of the most  revolutionary part about having this in one system that is completely  wireless, is that you can use it at home. You don’t actually have to go  to the lab and go to the clinic to get connectedorized to these  specialized equipment that you can’t take home with you.        

02:24:51: So that’s one of the key elements of  when we’re designing the system that we wanted to keep in mind, people  hopefully would want to be able to use this every day in the comfort of  their homes. And so part of our engagement and what we’re looking for  during BCI home audit is to just understand their situation, what other  assisted technology that they use.        

Lex Fridman: 02:25:14: And we should also step back and say  that the estimate is 180,000 people live with quadriplegia in the United States, and each year an additional 18,000 suffer a paralyzing spinal  cord injury. So these are folks who have a lot of challenges living a  life in terms of accessibility, in terms of doing the things that many  of us just take for granted day to day.        

02:25:42: And one of the things, one of the  goals of this initial study is to enable them to have digital autonomy  where they by themselves can interact with a digital device using just  their mind, something that you’re calling telepathy, so digital  telepathy. Where a quadriplegic can communicate with a digital device in all the ways that we’ve been talking about. Control the mouse cursor  enough to be able to do all kinds of stuff, including play games and  tweet and all that kind of stuff. And there’s a lot of people for whom  life, the basics of life, are difficult because of the things that have  happened to them.        

DJ Seo: 02:26:24: Yeah. I mean, movement is so  fundamental to our existence. I mean, even speaking involves movement of mouth, lip, larynx. And without that, it’s extremely debilitating. And  there are many, many people that we can help. I mean, especially if you  start to look at other forms of movement disorders that are not just  from spinal cord injury, but from a ALS, MS, or even stroke, or just  aging, that leads you to lose some of that mobility, that independence,  it’s extremely debilitating.        

Lex Fridman: 02:27:09: And all of these are opportunities to  help people, to help alleviate suffering, to help improve the quality of life. But each of the things you mentioned is its own little puzzle  that needs to have increasing levels of capability from a device like a  Neuralink device.        

## Digital telepathy

02:27:24: And so the first one you’re focusing  on is, it’s just a beautiful word, telepathy. So being able to  communicate using your mind wirelessly with a digital device. Can you  just explain exactly what we’re talking about?        

DJ Seo: 02:27:40: Yeah, I mean, it’s exactly that. I  mean, I think if you are able to control a cursor and able to click and  be able to get access to a computer or a phone, I mean, the whole world  opens up to you. And I mean, I guess the word “telepathy,” if you think  about that as just definitionally being able to transfer information  from my brain to your brain without using some of the physical faculties that we have, like voices.        

Lex Fridman: 02:28:13: But the interesting thing here is I  think the thing that’s not obviously clear is how exactly it works. In  order to move a cursor, there’s at least a couple of ways of doing that. One is you imagine yourself maybe moving a mouse with your hand, or you can then, which no one talked about, imagine moving the cursor with  your mind.        

02:28:44: But it’s like there is a cognitive  step here that’s fascinating, because you have to use the brain and you  have to learn how to use the brain, and you have to figure it out  dynamically because you reward yourself if it works. I mean, there’s a  step that … This is just a fascinating step because you have to get the  brain to start firing in the right way. And you do that by imagining …  Like fake it till you make it. And all of a sudden it creates the right  kind of signal that, if decoded correctly, can create the effect. And  then there’s noise around that that you have to figure all of that out.  But on the human side, imagine the cursor moving is what you have to do.        

DJ Seo: 02:29:27: Yeah. He says using the force.        

Lex Fridman: 02:29:29: The force. I mean, isn’t that just  fascinating to you that it works? To me, it’s like, holy shit, that  actually works. You could move a cursor with your mind.        

DJ Seo: 02:29:41: As much as you’re learning to use that thing, that thing is also learning about you. Our model’s constantly  updating the way to say, “Oh, if someone is thinking about this  sophisticated forms of spiking patterns, that actually means to do  this.”        

Lex Fridman: 02:30:02: So the machine is learning about the  human and the human is learning about the machine, so there is a  adaptability to the signal process and the decoding step, and then  there’s the adaptation of Nolan, the human being. The same way, if you  give me a new mouse and I move it, I learn very quickly about its  sensitivity, so I learn to move it slower. And then there’s other signal drift and all that kind of stuff they have to adapt to, so both are  adapting to each other.        

DJ Seo: 02:30:32: Correct.        

Lex Fridman: 02:30:34: That’s a fascinating software  challenge, on both sides. The software on both, on the human software  and the [inaudible 02:30:41] software.        

DJ Seo: 02:30:41: The organic and the inorganic.        

Lex Fridman: 02:30:43: The organic and the inorganic. Anyway. Sorry to rudely interrupt. So there’s the selection that Noland has  passed with flying colors. Everything, including that it is a  BCI-friendly home, all of that. So what is the process of the surgery,  implantation, the first moment when he gets to use the system?        

DJ Seo: 02:31:06: The end-to-end, we say patient end to  patient out, is anywhere between two to four hours. In the particular  case for Noland it was about three and a half hours, and there’s many  steps leading to the actual robot insertion. So there’s anesthesia  induction, and we do intra-op CT imaging to make sure that we’re  drilling the hole in the right location. And this is also pre-planned  beforehand.        

02:31:34: Someone like Noland would go through  fMRI and then they can think about wiggling their hand. Obviously due to their injury it’s not going to actually lead to any sort of intended  output, but it’s the same part of the brain that actually lights up when you’re imagining moving your finger to actually moving your finger. And that’s one of the ways in which we can actually know where to place our threads because we want to go into what’s called the hand knob area in  the motor cortex. And as much as possible, densely put our electrode  threads.        

02:32:11: So we do intra-op CT imaging to make  sure and double-check the location of the craniectomy. And the surgeon  comes in, does their thing in terms of skin incision, craniectomy, so  drilling of the skull, and then there’s many different layers of the  brain. There’s what’s called a dura, which is a very, very thick layer  that surrounds the brain. That gets actually resected in a process  called [inaudible 02:32:38]. And that then expose the pia in the brain  that you want to insert.        

02:32:43: And by the time it’s been around  anywhere between one to one and a half hours, robot comes in, does his  thing, placement of the targets, inserting of the thread. That takes  anywhere between 20 to 40 minutes. In the particular case for Noland, it was just under or just over 30 minutes. And then after that, the  surgeon comes in, there’s a couple other steps of actually inserting the dural substitute layer to protect the thread as well as the brain. And  then screw in the implant and then skin flap and then suture, and then  you’re out.        

Lex Fridman: 02:33:18: So when Noland woke up, what was that like? What was the recovery like, and when was the first time he was able to use it?        

DJ Seo: 02:33:27: He was actually immediately after the  surgery, like an hour after the surgery, as he was waking up, we did  turn on the device, make sure that we are recording neural signals. And  we actually did have couple signals that we noticed that he can actually modulate. And what I mean by modulate is that he can think about  clenching his fist and you could see the spike disappear and appear.        

Lex Fridman: 02:33:56: That’s awesome.        

DJ Seo: 02:33:58: And that was immediate, immediate after in the recovery room.        

Lex Fridman: 02:34:02: How cool is that?        

DJ Seo: 02:34:05: Yeah, absolutely.        

Lex Fridman: 02:34:06: That’s a human being … I mean, what  did that feel like for you? This device and a human being, a first step  of a gigantic journey? I mean, it’s a historic moment, even just that  spike, just to be able to modulate that.        

DJ Seo: 02:34:22: Obviously there have been other, as  you mentioned, pioneers that have participated in these groundbreaking  BCI investigational early feasibility studies. So we’re obviously  standing on the shoulders of the giants here, we’re not the first ones  to actually put electrodes in a human brain.        

02:34:44: But I mean, just leading up to the  surgery, I definitely could not sleep. It’s the first time that you’re  working in a completely new environment. We had a lot of confidence  based on our benchtop testing or preclinical R&D studies that the  mechanism, the threads, the insertion, all that stuff is very safe and  that it’s obviously ready for doing this in a human. But there’s still a lot of unknown unknown about can the needle actually insert? I mean, we brought something like 40 needles just in case they break, and we ended up using only one. But I mean, that was the level of just complete  unknown because it’s a very, very different environment. And I mean,  that’s why we do clinical trial in the first place, to be able to test  these things out.        

02:35:40: So extreme nervousness and just many,  many sleepless night leading up to the surgery, and definitely the day  before the surgery. And it was an early morning surgery. We started at  7:00 in the morning, and by the time it was around 10:30 everything was  done. But I mean, first time seeing that, well, number one, just huge  relief that this thing is doing what it’s supposed to do. And two, I  mean, just immense amount of gratitude for Noland and his family. And  then many others that have applied and that we’ve spoken to and will  speak to are true pioneers in every word. And I call them the neural  astronauts or neuralnaut.        

Lex Fridman: 02:36:29: Neuralnaut, yeah.        

DJ Seo: 02:36:32: Just like in the ’60s, these amazing  just pioneers exploring the unknown outwards, in this case it’s inward,  but an incredible amount of gratitude for them to just participate and  play a part. And it’s a journey that we’re embarking on together.        

02:36:57: But also, I think it was just a … That was a very, very important milestone, but our work was just starting.  So a lot of just anticipation for, “Okay, what needs to happen next?”  What are set of sequences of events that needs to happen for us to make  it worthwhile for both Noland as well as us.        

Lex Fridman: 02:37:17: Just to linger on that, just a huge  congratulations to you and the team for that milestone. I know there’s a lot of work left, but that’s really exciting to see. That’s a source of hope, it’s this first big step, opportunity, to help hundreds of  thousands of people. And then maybe expand the realm of the possible for the human mind for millions of people in the future. So it’s really  exciting. The opportunities are all ahead of us, and to do that safely  and to do that effectively was really fun to see. As an engineer, just  watching other engineers come together and do an epic thing, that was  awesome. So huge congrats.        

DJ Seo: 02:38:03: Thank you, thank you. Yeah, could not  have done it without the team. And yeah, I mean, that’s the other thing  that I told the team as well of just this immense sense of optimism for  the future. I mean, it’s a very important moment for the company,  needless to say, as well as hopefully for many others out there that we  can help.        

## Retracted threads

Lex Fridman: 02:38:27: Speaking of challenges, Neuralink  published a blog post describing that some of the threads retracted. And so the performance as measured by bits per second dropped at first, but then eventually it was regained. And the whole story of how it was  regained is super interesting, that’s definitely something I’ll talk to  Bliss and to Noland about.        

02:38:49: But in general, can you speak to this  whole experience, how was the performance regained, and just the  technical aspects of the threads being retracted and moving?        

DJ Seo: 02:39:03: The main takeaway is that in the end,  the performance have come back and it’s actually gotten better than it  was before. He’s actually just beat the world record yet again last week to 8.5 bps. I mean, he’s just cranking and he’s just improving.        

Lex Fridman: 02:39:20: The previous one that he said was eight.        

DJ Seo: 02:39:23: Correct.        

Lex Fridman: 02:39:23: I think he said 8.5.        

DJ Seo: 02:39:24: Yeah. The previous world record in a  human was 4.6, so it’s almost double. And his goal is to try to get to  10, which is roughly around the median neural linker using a mouse with a hand. So it’s getting there.        

Lex Fridman: 02:39:42: So yeah, so the performance was regained.        

DJ Seo: 02:39:45: Yeah, better than before. That’s a  story on its own of what took the BCI team to recover that performance.  It was actually mostly on the signal processing. And so as I mentioned,  we were looking at these spike outputs from our electrodes, and what  happened is that four weeks into the surgery we noticed that the threads have solely come out of the brain. And the way in which we noticed this at first obviously is that, well, I think Noland was the first to  notice, that his performance was degrading. And I think at the time we  were also trying to do a bunch of different experimentation, different  algorithms, different UI, UX. So it was expected that there will be  variability in the performance, but we did see a steady decline.        

02:40:41: And then also the way in which we  measure the health of the electrodes or whether they’re in the brain or  not, is by measuring impedance of the electrode. So we look at the  interfacial, the Randles circuit they say, the capacitance and the  resistance between the electrode surface and the medium. And if that  changes in some dramatic ways, we have some indication. Or if you’re not seeing spikes on those channels, you have some indications that  something’s happening there.        

02:41:11: And what we noticed is that looking at those impedance plot and spike rate plots, and also because we have  those electrodes recording along the depth, you are seeing some sort of  movement that indicated that threads were being pulled out. And that  obviously will have an implication on the model side because if the  number of inputs that are going into the model is changing because you  have less of them, that model needs to get updated.        

02:41:42: But there were still signals, and as I mentioned, similar to how even when you place the signals on the  surface of the brain or farther away, like outside the skull, you still  see some useful signals. What we started looking at is not just the  spike occurrence through this BOSS algorithm that I mentioned, but we  started looking at just the power of the frequency band that is  interesting for Noland to be able to modulate. Once we changed the  algorithm for the implant to not just give you the BOSS output, but also these spike band power output, that helped us refine the model with a  new set of inputs. And that was the thing that really ultimately gave us the performance back. And obviously the thing that we want ultimately  and the thing that we are working towards, is figuring out ways in which we can keep those threads intact for as long as possible so that we  have many more channels going into the model. That’s by far the number  one priority that the team is currently embarking on to understand how  to prevent that from happening.        

02:42:56: The thing that I will say also is  that, as I mentioned, this is the first time ever that we’re putting  these threads in the human brain. And a human brain, just for size  reference, is 10 times that of the monkey brain or the sheep brain. And  it’s just a very, very different environment. It moves a lot more. It’s  actually moved a lot more than we expected when we did Noland’s surgery. And it’s just a very, very different environment than what we’re used  to. And this is why we do clinical trial, we want to uncover some of  these issues and failure modes earlier than later.        

02:43:37: So in many ways, it’s provided us with this enormous amount of data and information to be able to solve this.  And this is something that Neuralink is extremely good at, once we have  set of clear objective and engineering problem, we have enormous amount  of talents across many, many disciplines to be able to come together and fix the problem very, very quickly.        

## Vertical integration

Lex Fridman: 02:44:01: But it sounds like one of the  fascinating challenges here is for the system on the decoding side to be adaptable across different timescales. So whether it’s movement of  threads or different aspects of signal drift, sort of on the software or the human brain, something changing, like Noland talks about cursor  drift, they could be corrected. And there’s a whole UX challenge to how  to do that. So it sounds like adaptability is a fundamental property  that has to be engineered in.        

DJ Seo: 02:44:34: It is. I mean, as a company, we’re extremely vertically integrated. We make these thin-film arrays in our own microfab.        

Lex Fridman: 02:44:45: Yeah, there’s like you said, built in-house. This whole paragraph here from this blog post is pretty gangster.        

02:44:50: “Building the technologies described  above has been no small feat,” and there’s a bunch of links here that I  recommend people click on. “We constructed in-house microfabrication  capabilities to rapidly produce various iterations of thin-film arrays  that constitute our electrode threads. We created a custom femtosecond  laser mill-“        

DJ Seo: 02:45:13: [inaudible 02:45:13].        

Lex Fridman: 02:45:12: “… to manufacture components with micro level precision.” I think there’s a tweet associated with this.        

DJ Seo: 02:45:17: That’s a whole thing that we can get into.        

Lex Fridman: 02:45:18: Yeah. Okay. What are we looking at  here, this thing? “In less than one minute, our custom-made femtosecond  laser mill cuts this geometry in the tips of our needles.” So we’re  looking at this weirdly shaped needle. “The tip is only 10 to 12 microns in width, only slightly larger than the diameter of a red blood cell.  The small size allows threads to be inserted with minimal damage to the  cortex.”        

02:45:48: Okay. So what’s interesting about this geometry? So we’re looking at this just geometry of a needle.        

DJ Seo: 02:45:53: This is the needle that’s engaging  with the loops in the thread. They’re the ones that thread their loop,  and then peel it from the silicon backing, and then this is the thing  that gets inserted into the tissue. And then this pulls out, leaving the thread. And this kind of a notch or the shark tooth that we used to  call, is the thing that actually is grasping the loop. And then it’s  designed in such a way such that when you pull out, it leaves the loop.        

Lex Fridman: 02:46:28: And the robot is controlling this needle?        

DJ Seo: 02:46:31: Correct. So this is actually housed in a cannula, and basically the robot has a lot of the optics that look  for where the loop is. There’s actually a 405 nanometer light that  actually causes the polyimide to fluoresce so that you can locate the  location of the loop.        

Lex Fridman: 02:46:49: So the loop lights up, is [inaudible 02:46:50]?”        

DJ Seo: 02:46:50: Yeah, yeah, they do. It’s a micron precision process.        

Lex Fridman: 02:46:54: What’s interesting about the robot  that it takes to do that, that’s pretty crazy. That’s pretty crazy that  robot is able to get this kind of precision.        

DJ Seo: 02:47:01: Yeah, our robot is quite heavy, our  current version of it. I mean, it’s like a giant granite slab that  weighs about a ton, because it needs to be sensitive to vibration,  environmental vibration. And then as the head is moving at the speed  that it’s moving, there’s a lot of motion control to make sure that you  can achieve that level of precision. A lot of optics that zoom in on  that. We’re working on next generation of the robot that is lighter,  easier to transport. I mean, it is a feat to move the robot to the  surgical suite.        

Lex Fridman: 02:47:38: And it’s far superior to a human surgeon at this time, for this particular task.        

DJ Seo: 02:47:42: Absolutely. I mean, let alone you try  to actually thread a loop in a sewing kit. We’re talking fractions of  human error. These things, it’s not visible.        

Lex Fridman: 02:47:54: So continuing the paragraph. “We  developed novel hardware and software testing systems, such as our  accelerated lifetime testing racks and simulated surgery environment,”  which is pretty cool, “to stress test and validate the robustness of our technologies. We performed many rehearsals of our surgeries to refine  our procedures and make them second nature.” This is pretty cool.        

02:48:14: “We practice surgeries on proxies with all the hardware and instruments needed in our mock or in the  engineering space. This helps us rapidly test and measure.” So there’s  like proxies?        

DJ Seo: 02:48:25: Yeah, this proxy is super cool  actually. There’s a 3D printed skull from the images that is taken at  [inaudible 02:48:34], as well as this hydrogel mix synthetic polymer  thing that actually mimics the mechanical properties of the brain. It  also has vasculature of the person.        

02:48:50: Basically what we’re talking about  here, and there’s a lot of work that has gone into making this set  proxy, that it’s about finding the right concentration of these  different synthetic polymers to get the right set of consistency for the needle dynamics as they’re being inserted. But we practice this surgery with Noland’s basically physiology and brain many, many times prior to  actually doing the surgery.        

Lex Fridman: 02:49:21: Every step, every step, every-        

DJ Seo: 02:49:23: Every step. Yeah. Like where does  someone stand? I mean, what you’re looking at is the picture, this is in our office, of this corner of the robot engineering space that we have  created this mock OR space that looks exactly like what they would  experience, all the staff would during their actual surgery.        

02:49:43: I mean, it’s just like any dance  rehearsal where exactly where you’re going to stand at what point, and  you just practice that over and over and over again with an exact  anatomy of someone that you’re going to surgerize. And it got to a point where a lot of our engineers, when we created a craniectomy, they’re  like, “Oh, that looks very familiar. We’ve seen that before.”        

Lex Fridman: 02:50:04: Yeah. Man, there’s wisdom you can gain through doing the same thing over and over and over. It’s like Jiro  Dreams of Sushi kind of thing because then … It’s like Olympic athletes  visualize the Olympics and then once you actually show up, it feels  easy. It feels like any other day. It feels almost boring winning the  gold medal, because you visualized this so many times, you’ve practiced  this so many times, that nothing about it is new. It’s boring. You win  the gold medal, it’s boring. And the experience they talk about is  mostly just relief, probably that they don’t have to visualize it  anymore.        

DJ Seo: 02:50:44: Yeah, the power of the mind to  visualize and where … I mean, there’s a whole field that studies where  muscle memory lies in cerebellum. Yeah, it’s incredible.        

## Safety

Lex Fridman: 02:50:56: I think it’s a good place to actually  ask the big question that people might have, is how do we know every  aspect of this that you described is safe?        

DJ Seo: 02:51:06: At the end of the day, the gold  standard is to look at the tissue. What sort of trauma did you cause the tissue, and does that correlate to whatever behavioral anomalies that  you may have seen? And that’s the language to which we can communicate  about the safety of inserting something into the brain and what type of  trauma that you can cause.        

02:51:29: We actually have an entire department, department of pathology, that looks at these tissue slices. There are  many steps that are involved in doing this. Once you have studies that  are launched with particular endpoints in mind, at some point you have  to euthanize the animal, and then you go through necropsy to collect the brain tissue samples. You fix them in formalin, and you gross them, you section them, and you look at individual slices just to see what kind  of reaction or lack thereof exists.        

02:52:04: So that’s the language to which FDA  speaks and as well for us to evaluate the safety of the insertion  mechanism, as well as the threats at various different time points, both acute, so anywhere between zero to three months to beyond three months.        

Lex Fridman: 02:52:25: So those are the details of an extremely high standard of safety that has to be reached.        

DJ Seo: 02:52:31: Correct.        

Lex Fridman: 02:52:32: The FDA supervises this, but there’s  in general just a very high standard, in every aspect of this, including the surgery. I think Matthew MacDougall has mentioned that the standard is, let’s say how to put it politely, higher than maybe some other  operations that we take for granted. So the standard for all the  surgical stuff here is extremely high.        

DJ Seo: 02:52:57: Very high. I mean, it’s a highly,  highly regulated environment with the governing agencies that scrutinize every, every medical device that gets marketed. And I think it’s a good thing. It’s good to have those high standards, and we try to hold  extremely high standards to understand what sort of damage, if any,  these innovative emerging technologies and new technologies that we’re  building are. And so far we have been extremely impressed by lack of  immune response from these threads.        

Lex Fridman: 02:53:34: Speaking of which, you talked to me  with excitement about the histology in some of the images that you’re  able to share. Can you explain to me what we’re looking at?        

DJ Seo: 02:53:46: Yeah, so what you’re looking at is a  stained tissue image. This is a sectioned tissue slice from an animal  that was implanted for seven months, so a chronic time point. And you’re seeing all these different colors, and each color indicates specific  types of cell types. So purple and pink are astrocytes and microglia,  respectably. They’re types of glial cells.        

02:54:12: And the other thing that people may  not be aware of is your brain is not just made up of soup of neurons and axons. There are other cells, like glial cells, that actually is the  glue and also react if there are any trauma or damage to the tissue.        

Lex Fridman: 02:54:32: With the brown or the neurons here?        

DJ Seo: 02:54:33: The brown are the neurons and the blue is nuclei.        

Lex Fridman: 02:54:35: It’s a lot of neurons.        

DJ Seo: 02:54:35: The neuro nucle.        

Lex Fridman: 02:54:36: So what you’re seeing is in this macro image, you’re seeing these circle highlighted in white, the insertion  sites. And when you zoom into one of those, you see the threads. And  then in this particular case, I think we’re seeing about the 16 wires  that are going into the [inaudible 02:54:56]. And the incredible thing  here is the fact that you have the neurons that are these brown  structures or brown circular or elliptical thing-        

DJ Seo: 02:55:00: … are these brown structures or brown  circular or elliptical thing that are actually touching and abutting the threads. So what this is saying is that there’s basically zero trauma  that’s caused during this insertion. And with these neural interfaces,  these micro electrons that you insert, that is one of the most common  mode of failure. So when you insert these threads like the Utah Array,  it causes neuronal death around the site because you’re inserting a  foreign object.        

02:55:29: And that elicit these immune response  through microglia and astrocytes, they form this protective layer around it. Oh, not only are you killing the neuron cells, but you’re also  creating this protective layer that then basically prevents you from  recording neural signals because you’re getting further and further away from the neurons that you’re trying to record. And that is the biggest  mode of failure. And in this particular example, in that inside it’s  about 50 micron with that scale bar, the neurons seem to be attracted to it.        

Lex Fridman: 02:55:59: And so there’s certainly no trauma.  That’s such a beautiful image, by the way. So the brown at the neurons,  and for some reason I can’t look away. It’s really cool.        

DJ Seo: 02:56:08: Yeah. And the way that these things…  Tissues generally don’t have these beautiful colors. This is multiplex  stain that uses these different proteins that are staining these at  different colors. We use very standard set of staining techniques with  H&E, EVA1 and NeuN and GFAB. So if you go to the next image, this is also kind of illustrates the second point because you can make an  argument, and initially when we saw the previous image, we said, “Oh,  are the threads just floating? What is happening here? Are we actually  looking at the right thing?” So what we did is we did another stain, and this is all done in-house of this Masson’s tricrome stain, which is in  blue that shows these collagen layer. So the blue, basically, you don’t  want the blue around the implant threads. Because that means that  there’s some sort of scarring that’s happened. And what you’re seeing if you look at individual threads is that you don’t see any of the blue.  Which means that there has been absolutely, or very, very minimal to a  point where it’s not detectable amount of trauma in these inserted  threads.        

Lex Fridman: 02:57:16: So that presumably is one of the big benefits of having this kind of flexible thread? This-        

DJ Seo: 02:57:21: Yeah. So we think this is primarily  due to the size as well as the flexibility of the threads. Also, the  fact that R1 is avoiding vasculature, so we’re not disrupting or we’re  not causing damage to the vessels and not breaking any of the blood  brain barrier, has basically caused the immune response to be muted.        

Lex Fridman: 02:57:45: But this is also a nice illustration of the size of things. So this is the tip of the thread?        

DJ Seo: 02:57:51: Yeah, those are neurons.        

Lex Fridman: 02:57:53: And they’re neurons. And this is the thread listening. And the electrodes are positioned how?        

DJ Seo: 02:57:59: Yeah. So what you’re looking at is not electrode themselves, those are the conductive wires. So each of those  should probably be two micron in width. So what we’re looking at is,  we’re looking at the coronal slice, so we’re looking at some slice of  the tissue. So as you go deeper, you’ll obviously have less and less of  the tapering of the thread. But yeah, the point basically being that  there’s just cells around the inserter site, which is just an incredible thing to see. I’ve just never seen anything like this.        

Lex Fridman: 02:58:33: How easy and safe is it to remove the implant?        

DJ Seo: 02:58:37: Yeah, so it depends on when. In the  first three months or so after the surgery, there’s a lot of tissue  modeling that’s happening. Similar to when you got a cut, you obviously  start over first couple of weeks or depending on the size of the wound,  scar tissue forming, there are these contractive, and then in the end  they turn into scab and you can scab it off. The same thing happens in  the brain. And it’s a very dynamic environment. And before the scar  tissue or the neo membrane or the new membrane that forms, it’s quite  easy to just pull them out. And there’s minimal trauma that’s caused  during that.        

02:59:22: Once the scar tissue forms, and with  Noland as well, we believe that that’s the thing that’s currently  anchoring the threats. So we haven’t seen any more movements since then. So they’re quite stable. It gets harder to actually completely extract  the threads. So our current method for removing the device is cutting  the thread, leaving the tissue intact, and then unscrewing and taking  the implant out. And that hole is now going to be plugged with either  another Neuralink or just with a peak based, plastic based cap.        

Lex Fridman: 03:00:06: Is it okay to leave the threads in there forever?        

DJ Seo: 03:00:09: Yeah, we think so. We’ve done studies  where we left them there and one of the biggest concerns that we had is, do they migrate and do they get to a point where they should not be? We haven’t seen that. Again. Once the scar tissue forms, they get anchored in place. And I should also say that when we say upgrades, we’re not  just talking in theory here, we’ve actually upgraded many, many times.  Most of our monkeys or non-human primates, NHP, have been upgraded.  Pager, who you saw playing mind pong has the latest version of the  device since two years ago and is seemingly very happy and healthy and  fat.        

## Upgrades

Lex Fridman: 03:00:51: So what’s designed for the future, the upgrade procedure? So maybe for Noland, what would the upgrade look  like? It was essentially what you’re mentioning. Is there a way to  upgrade the device internally where you take it apart and keep the  capsule and upgrade the internals?        

DJ Seo: 03:01:15: So there are a couple of different  things here. So for Noland, if we were to upgrade, what we would have to do is either cut the threads or extract the threads depending on the  situation there in terms of how they’re anchored or scarred in. If you  were to remove them with the dual substitute, you have an intact brain,  so you can reinsert different threads with the updated implant package.  There are a couple of different other ways that we’re thinking about the future of what the upgradable system looks like. One is, at the moment  we currently remove the dura, this kind of thick layer that protects the brain, but that actually is the thing that actually proliferates the  scar tissue formation. So typically, the general rule of thumb is you  want to leave the nature as is and not disrupt it as much. So looking at ways to insert the threats through the dura, which comes with different set of challenges such as, it’s a pretty thick layer, so how do you  actually penetrate that without breaking the needle?        

03:02:23: So we’re looking at different needle  design for that as well as the kind of the loop engagement. The other  biggest challenges are, it’s quite opaque, optically with white light  illumination. So how do you avoid still this biggest advantage that we  have of avoiding vasculature? How do you image through that? How do you  actually still mediate that? So there are other imaging techniques that  we’re looking at to enable that. But the goal, our hypothesis is that,  and based on some of the early evidence that we have, doing through the  dura insertion will cause minimal scarring that causes them to be much  easier to extract over time. And the other thing that we’re also looking at, this is going to be a fundamental change in the implant  architecture, is as at the moment, it’s a monolithic single implant that comes with a thread that’s bonded together.        

03:03:12: So you can’t actually separate the  thing out, but you can imagine having two part implant, bottom part that is the thread that are inserted that has the chips and maybe a radio  and some power source. And then you have another implant that has more  of the computational heavy load and the bigger battery. And then one can be under the dura, one can be above the dura being the plug for the  skull. They can talk to each other, but the thing that you want to  upgrade, the computer and not the thread, if you want to upgrade that,  you just go in there, remove the screws, and then put in the next  version. And you’re off the… It’s a very, very easy surgery too. You do a skin incision, slip this in, screw. Probably be able to do this in 10  minutes.        

Lex Fridman: 03:03:55: So that would allow you to reuse the thread sort of?        

DJ Seo: 03:03:57: Correct.        

Lex Fridman: 03:03:59: So I mean, this leads to the natural  question of what is the pathway to scaling the increase in the number of threads? Is that a priority? What’s the technical challenge there?        

DJ Seo: 03:04:11: Yeah, that is a priority. So for next  versions of the implant, the key metrics that we’re looking to improve  are number of channels, just recording from more and more neurons. We  have a pathway to actually go from currently 1000 to hopefully 3000, if  not 6,000 by end of this year.        

Lex Fridman: 03:04:28: Wow.        

DJ Seo: 03:04:30: And then end of next year we want to get to even more. 16,000.        

Lex Fridman: 03:04:35: Wow.        

DJ Seo: 03:04:36: There’s a couple of limitations to  that. One is, obviously being able to photolithographically, print those wires. As I mentioned, it’s two micron in width and spacing. Obviously, there are chips that are much more advanced than those types of  resolution and we have some of the tools that we have brought in house  to be able to do that. So traces will be narrower just so that you have  to have more of the wires coming up into the chip. Chips also cannot  linearly consume more energy as you have more and more channels. So  there’s a lot of innovations in the circuit, and architecture as well as the circuit design topology to make them lower power. You need to also  think about if you have all of these spikes, how do you send that off to the end application. So you need to think about bandwidth limitation  there and potentially innovations and signal processing.        

03:05:28: Physically, one of the biggest  challenges is going to be the interface. It’s always the interface that  breaks bonding this thin film array to the electronics. It starts to  become very, very highly dense interconnects. So how you connectivise  that? There’s a lot of innovations in the 3D integrations in the recent  years that we can take advantage of. One of the biggest challenges that  we do have is forming this hermetic barrier. This is an extremely harsh  environment that we’re in, the brain. So how do you protect it from,  yeah, the brain trying to kill your electronics, to also your  electronics leaking things that you don’t want into the brain. And that  forming that hermetic barrier is going to be a very, very big challenge  that we, I think are actually well suited to tackle.        

Lex Fridman: 03:06:20: How do you test that? What’s the development environment to simulate that kind of harshness?        

DJ Seo: 03:06:25: Yeah, so this is where the accelerated life tester essentially is a brain in a vat. It literally is a vessel  that is made up of, and again, for all intents and purpose for this  particular type of test, your brain is a salt water. And you can also  put some other set of chemicals like reactive oxygen species that get at these interfaces and trying to cause a reaction to pull it apart. But  you could also increase the rate at which these interfaces are aging by  just increasing temperature. So every 10 degrees Celsius that you  increase, you’re basically accelerating time by two X.        

03:07:11: And there’s limit as to how much  temperature you want to increase because at some point there’s some  other nonlinear dynamics that causes you to have other nasty gases to  form that just is not realistic in an environment. So what we do is we  increase in our ALT chamber by 20 degrees Celsius that increases the  aging by four times. So essentially one day in ALT chamber is four day  in calendar year, and we look at whether the implants still are intact,  including the threats. And-        

Lex Fridman: 03:07:43: And operation and all of that.        

DJ Seo: 03:07:45: … and operation and all of that.  Obviously, is not an exact same environment as a brain because brain has mechanical other more biological groups that attack at it. But it is a  good test environment, testing environment for at least the enclosure  and the strength of the enclosure. And I mean, we’ve had implants, the  current version of the implant that has been in there for close to two  and a half years, which is equivalent to a decade and they seem to be  fine.        

Lex Fridman: 03:08:18: So it’s interesting that basically close approximation is warm salt water, hot salt water is a good testing environment.        

DJ Seo: 03:08:28: Yeah.        

Lex Fridman: 03:08:29: By the way, I’m drinking LMNT , which  is basically salt water. Which is making me kind of… It doesn’t have  computational power the way the brain does, but maybe in terms of other  characteristics, it’s quite similar and I’m consuming it.        

DJ Seo: 03:08:44: Yeah. You have to get it in the right pH too.        

Lex Fridman: 03:08:48: And then consciousness will emerge. Yeah, no. All right.        

DJ Seo: 03:08:52: By the way, the other thing that also  is interesting about our enclosure is, if you look at our implant, it’s  not your common looking medical implant that usually is encased in a  titanium can that’s laser welded. We use this polymer called PCTFE,  polychlorotrifluoroethylene, which is actually commonly used in blister  packs. So when you have a pill and you try to pop a pill, there’s kind  of that plastic membrane. That’s what this is. No one’s actually ever  used this except us. And the reason we wanted to do this is because  electromagnetically transparent. So when we talked about the  electromagnetic inductive charging, with titanium can usually if you  want to do something like that, you have to have a sapphire window and  it’s a very, very tough process to scale.        

Lex Fridman: 03:09:45: So you’re doing a lot of iteration here in every aspect of this. The materials, the software, all.        

DJ Seo: 03:09:50: The whole shebang.        

## Future capabilities

Lex Fridman: 03:09:53: Okay. So you mentioned scaling. Is it  possible to have multiple Neuralink devices as one of the ways of  scaling? To have multiple Neuralink devices implanted?        

DJ Seo: 03:10:08: That’s the goal. That’s the goal.  Yeah. I mean, our monkeys have had two neural links, one in each  hemisphere. And then we’re also looking at potential of having one in  motor cortex, one in visual cortex and one in wherever other cortex.        

Lex Fridman: 03:10:24: So focusing on the particular function one Neuralink device.        

DJ Seo: 03:10:28: Correct.        

Lex Fridman: 03:10:29: I mean, I wonder if there’s some level of customization that can be done on the compute side. So for the motor cortex-        

DJ Seo: 03:10:34: Absolutely. That’s the goal. And we  talk about at Neuralink building a generalized neural interface to the  brain. And that also is strategically how we’re approaching this with  marketing and also with regulatory, which is, hey, look, we have the  robot and the robot can access any part of the cortex. Right now we’re  focused on motor cortex with current version of the N1 that’s  specialized for motor decoding tasks. But also at the end of the day,  there’s a general compute available there. But typically if you want to  really get down to hyperoptimizing for power and efficiency, you do need to get to some specialized function.        

03:11:21: But what we’re saying is that, hey,  you are now used to this robotic insertion techniques, which took many,  many years of showing data and conversation with the FDA and also  internally convincing ourselves that this is safe. And now the  difference is if we go to other parts of the brain, like visual cortex,  which we’re interested in as our second product, obviously it’s a  completely different environment, the cortex is laid out very, very  differently. It’s going to be more stimulation focus rather than  recording, just kind of creating visual percepts. But in the end, we’re  using the same thin film array technology, we’re using the same robot  insertion technology, we’re using the same packaging technology. Now  it’s where the conversation is focused around what are the differences  and what are the implication of those differences in safety and  efficacy.        

Lex Fridman: 03:12:17: The way you said second product is  both hilarious and awesome to me. That product being restoring sight for blind people. So can you speak to stimulating the visual cortex? I  mean, the possibilities there are just incredible to be able to give  that gift back to people who don’t have sight or even any aspect of  that. Can you just speak to the challenges of… There’s challenges here-        

DJ Seo: 03:12:50: Oh many.        

Lex Fridman: 03:12:51: One of which is like you said, from  recording to stimulation. Just any aspect of that that you’re both  excited and see the challenges of?        

DJ Seo: 03:13:02: Yeah, I guess I’ll start by saying  that we actually have been capable of stimulating through our thin film  array as well as other electronics for years. We have actually  demonstrated some of that capabilities for reanimating the limb in the  spinal cord. Obviously, for the current EFS study, we’ve hardware  disabled that. So that’s something that we wanted to embark as a  separate journey. And obviously, there are many, many different ways to  write information into the brain. The way in which we’re doing that is  through electrical, passing electrical current, and kind of causing that to really change the local environment so that you can artificially  cause the neurons to depolarize in nearby areas. For vision,  specifically the way our visual system works, it’s both well understood. I mean, anything with kind of brain, there are aspects of it that’s  well understood, but in the end, we don’t really know anything.        

03:14:10: But the way visual system works is  that you have photon hitting your eye, and in your eyes there are these  specialized cells called photoreceptor cells that convert the photon  energy into electrical signals. And then that then gets projected to  your back of your head, your visual cortex. It goes through actually  thalamic system called LGN that then projects it out. And then in the  visual cortex there’s visual area one or V1, and then there’s a bunch of other higher level processing layers like V2, V3. And there are  actually kind of interesting parallels. And when you study the behaviors of these convolutional neural networks, like what the different layers  of the network is detecting, first they’re detecting these edges and  they’re then detecting some more natural curves and then they start to  detect objects.        

03:15:08: Kind of similar thing happens in the  brain. And a lot of that has been inspired and also it’s been kind of  exciting to see some of the correlations there. But things like from  there, where does cognition arise and where’s color encoded? There’s  just not a lot of understanding, fundamental understanding there. So in  terms of bringing sight back to those that are blind, there are many  different forms of blindness. There’s actually million people, 1 million people in the US that are legally blind. That means certain score below in the visual tests. I think it’s something like if you can see  something at 20 feet distance that normal people can see at 200 feet  distance, if you’re worse than that, you’re legally blind.        

Lex Fridman: 03:15:57: So fundamental that means you can’t function effectively using sight in the world.        

DJ Seo: 03:16:02: Like to navigate-        

Lex Fridman: 03:16:03: To navigate.        

DJ Seo: 03:16:04: … you’re environment. And yeah, there  are different forms of blindness. There are forms of blindness where  there’s some degeneration of your retina is photoreceptor cells and rest of your visual processing that I described is intact. And for those  types of individuals, you may not need to maybe stick electrodes into  the visual cortex. You can actually build retinal prosthetic devices  that actually just replaces the function of that retinal cells that are  degenerated. And there are many companies that are working on that, but  that’s a very small slice albeit significance, those smaller slice of  folks that are legally blind.        

03:16:51: If there’s any damage along that  circuitry, whether it’s in the optic nerve or just the LGN circuitry or  any break in that circuit, that’s not going to work for you. And the  source of where you need to actually cause that visual percepts to  happen because your biological mechanism not doing that is by placing  electrodes in the visual cortex in the back of your head. And the way in which this would work is that you would have an external camera,  whether it’s something as unsophisticated as a GoPro or some sort of  wearable Ray- Ban type glasses that meta is working on that captures a  scene. And that scene is then converted to a set of electrical impulses  or stimulation pulses that you would activate in your visual cortex  through these thin film arrays. And by playing some a concerted kind of  orchestra of these stimulation patterns, you can create what’s called  phosphenes, which are these kind of white yellowish dots that you can  also create by just pressing your eyes. You can actually create those  percepts by stimulating the visual cortex.        

03:18:08: And the name of the game is really  have many of those and have those percepts, be the phosphenes, be as  small as possible so that you can start to tell apart they’re the  individual pixels of the screen. So if you have many, many of those  potentially you’ll be able to, in the long term, be able to actually get naturalistic vision. But in the short term to maybe midterm, being able to at least, be able to have object detection algorithms run on your  glasses, the pre-processing units, and then being able to at least see  the edges of things so you don’t bump into stuff.        

Lex Fridman: 03:18:46: This is incredible. This is really  incredible. So you basically would be adding pixels and your brain would start to figure out what those pixels mean with different kinds of  assistant signal processing on all fronts.        

DJ Seo: 03:18:59: Yeah. The thing that actually… So a  couple of things. One is obviously if you’re blind from birth, the way  brain works, especially in the early age, neuroplasticity is really  nothing other than your brain and different parts of your brain fighting for the limited territory. And I mean very, very quickly you see cases  where people that are… I mean, you also hear about people who are blind  that have heightened sense of hearing or some other senses. And the  reason for that is because that cortex that’s not used just gets taken  over by these different parts of the cortex. So for those types of  individuals, I mean I guess they’re going to have to now map some other  parts of their senses into what they call vision, but it’s going to be  obviously a very, very different conscious experience.        

03:19:54: Before… So I think that’s an  interesting caveat. The other thing that also is important to highlight  is that, we’re currently limited by our biology in terms of the  wavelength that we can see. There’s a very, very small wavelength that  is a visible light wavelength that we can see with our eyes. But when  you have an external camera with this BCI system, you’re not limited to  that. You can have infrared, you can have UV, you can have whatever  other spectrum that you want to see. And whether that gets matched to  some sort of weird conscious experience, I’ve no idea. But oftentimes I  talk to people about the goal of Neuralink being going beyond the limits of our biology. That’s sort of what I mean.        

Lex Fridman: 03:20:39: And if you’re able to control the kind of raw signal, is that when we use our site, we’re getting the photons  and there’s not much processing on it. If you’re being able to control  that signal, maybe you can do some kind of processing, maybe you do  object detection ahead of time. You’re doing some kind of pre-processing and there’s a lot of possibilities to explore that. So it’s not just  increasing thermal imaging, that kind of stuff, but it’s also just doing some kind of interesting processing.        

DJ Seo: 03:21:10: Correct. Yeah. I mean, my theory of  how visual system works also is that, I mean, there’s just so many  things happening in the world and there’s a lot of photons that are  going into your eye. And it’s unclear exactly where some of the  pre-processing steps are happening. But I mean, I actually think that  just from a fundamental perspective, there’s just so much the reality  that we’re in, if it’s a reality, so there’s so much data and I think  humans are just unable to actually eat enough, actually to process all  that information. So there’s some sort of filtering that does happen,  whether that happens in the retina, whether that happens in different  layers of the visual cortex, unclear. But the analogy that I sometimes  think about is, if your brain is a CCD camera and all of the information in the world is a sun, and when you try to actually look at the sun  with the CCD camera, it’s just going to saturate the sensors because  it’s an enormous amount of energy.        

03:22:16: So what you do is you end up adding  these filters to just kind of narrow the information that’s coming to  you and being captured. And I think things like our experiences or our  drugs like propofol, anesthetics drug or psychedelics, what they’re  doing is they’re kind of swapping out these filters and putting in new  ones or removing older ones and kind of controlling our conscious  experience.        

Lex Fridman: 03:22:50: Yeah, man, not to distract from the  topic, but I just took a very high dose of ayahuasca in the Amazon  jungle. So yes, it’s a nice way to think about it. You’re swapping out  different experiences and with Neuralink being able to control that,  primarily at first to improve function, not for entertainment purposes  or enjoyment purposes, but-        

DJ Seo: 03:23:11: Yeah, giving back loss functions.        

Lex Fridman: 03:23:13: Giving back loss functions. And there, especially when the function is completely lost, anything is a huge  help. Would you implant a Neuralink device in your own brain?        

DJ Seo: 03:23:29: Absolutely. I mean, maybe not right now, but absolutely.        

Lex Fridman: 03:23:33: What kind of capability once reached  you start getting real curious and almost get a little antsy, jealous of people as you watch them get implanted?        

DJ Seo: 03:23:46: Yeah, I think even with our early  participants, if they start to do things that I can’t do, which I think  is in the realm of possibility for them to be able to get 15, 20 if not  like a hundred BPS. There’s nothing that fundamentally stops us from  being able to achieve that type of performance. I mean, I would  certainly get jealous that they can do that.        

Lex Fridman: 03:24:13: I should say that watching Noland, I  get a little jealous having so much fun, and it seems like such a chill  way to play video games.        

DJ Seo: 03:24:19: Yeah. I mean the thing that also is  hard to appreciate sometimes is that, he’s doing these things while  talking. And I mean, it’s multitasking, so it’s clearly, it’s obviously  cognitively intensive. But similar to how when we talk, we move our  hands. These are multitasking. I mean, he’s able to do that. And you  won’t be able to do that with other assistive technology. As far as I am aware, if you’re obviously using an eye tracking device, you’re very  much fixated on that thing that you’re trying to do. And if you’re using voice control, I mean if you say some other stuff, you don’t get to use that.        

Lex Fridman: 03:25:02: The multitasking aspect of that is  really interesting. So it’s not just the BPS for the primary task, it’s  the parallelization of multiple tasks. If you measure the BPS for the  entirety of the human organism. So you’re talking and doing a thing with your mind and looking around also, I mean, there’s just a lot of  parallelization that can be happening.        

DJ Seo: 03:25:28: But I mean, I think at some point for  him, if he wants to really achieve those high level BPS, it does require a full attention. And that’s a separate circuitry that is a big  mystery, how attention works and…        

Lex Fridman: 03:25:41: Yeah, attention, cognitive load. I’ve  read a lot of literature on people doing two tasks. You have your  primary task and a secondary task, and the secondary task is a source of distraction. And how does that affect the performance of the primary  task? And depending on the tasks, because there’s a lot of interesting… I mean, this is an interesting computational device, and I think there’s-        

DJ Seo: 03:26:03: To say the least.        

Lex Fridman: 03:26:05: … a lot of novel insights that can be  gained from everything. I mean, I personally am surprised that no one’s  able to do such incredible control of the cursor while talking. And also being nervous at the same time because he’s talking like all of us are  if you’re talking in front of the camera, you get nervous. So all of  those are coming into play and he’s able to still achieve high  performance. Surprising. I mean, all of this is really amazing. And I  think just after researching this really in depth, I kind of want a  Neuralink.        

DJ Seo: 03:26:38: Get in the line.        

Lex Fridman: 03:26:39: And also the safety get in line. Well, we should say the registry is for people who have quadriplegia and all  that kind of stuff, so.        

DJ Seo: 03:26:46: Correct.        

Lex Fridman: 03:26:47: That’d be a separate line for people.  They’re just curious like myself. So now that Noland, patient P1 is part of the ongoing prime study, what’s the high level vision for P2, P3,  P4, P5, and just the expansion into other human beings that are getting  to experience this implant?        

DJ Seo: 03:27:14: Yeah, I mean the primary goal is for  our study in the first place is to achieve safety endpoints. Just  understand safety of this device as well as the implantation process.  And also at the same time understand the efficacy and the impact that it could have on the potential user’s lives. And Just because you have,  you’re living with tetraplegia, it doesn’t mean your situation is same  as another person living with tetraplegia. It’s wildly, wildly varying.  And it’s something that we’re hoping to also understand how our  technology can serve not just a very small slice of those individuals,  but broader group of individuals and being able to get the feedback to  just really build just the best product for them.        

03:28:11: So there’s obviously, also goals that  we have. And the primary purpose of the early feasibility study is to  learn from each and every participant to improve the device, improve the surgery before we embark on what’s called a pivotal study. That then is a much larger trial that starts to look at statistical significance of  your endpoints and that’s required before you can then market the  device. And that’s how it works in the US and just generally around the  world. That’s the process you follow.        

03:28:50: So our goal is to really just  understand from people like Noland, P2, P3, future participants, what  aspects of our device needs to improve. If it turns out that people are  like, “I really don’t like the fact that it lasts only six hours. I want to be able to use this computer for 24 hours.” I mean, that is a user  needs and user requirements, which we can only find out from just being  able to engage with them.        

Lex Fridman: 03:29:17: So before the pivotal study, there’s  kind of a rapid innovation based on individual experiences. You’re  learning from individual people, how they use it, the high resolution  details in terms of cursor control and signal and all that kind of  stuff, life experience.        

DJ Seo: 03:29:33: So there’s hardware changes, but also  just firmware updates. So even when we had that sort of recovery event  for Noland, he now has the new firmware that he has been updated with,  and similar to how your phones get updated all the time with new  firmware for security patches, whatever, new functionality, UI. And  that’s something that is possible with our implant. It’s not a static  one-time device that can only do…        

DJ Seo: 03:30:00: It’s not a static one-time device that can only do the thing that it said it can do. I mean, it’s similar to  Tesla, you can do over-the-air firmware updates, and now you have  completely new user interface and all these bells and whistles and  improvements on everything, like the latest. Right? When we say  generalized platform, that’s what we’re talking about.        

Lex Fridman: 03:30:22: Yeah. It’s really cool how the app  that Noland is using, there’s calibration, all that kind of stuff, and  then there’s update. You just click and get an update.        

03:30:35: What other future capabilities are you looking to? You said vision. That’s a fascinating one. What about  accelerated typing or speech, or this kind of stuff? And what else is  there?        

DJ Seo: 03:30:49: Yeah. Those are still in the realm of  movement program. So, largely speaking, we have two programs. We have  the movement program and we have the vision program. The movement  program currently is focused around the digital freedom. As you can  easily guess, if you can control 2D cursor in the digital space, you  could move anything in the physical space. So, robotic arms, wheelchair, your environment, or even really, whether it’s through the phone or  just directly to those interfaces, to those machines.        

03:31:22: So, we’re looking at ways to expand  those types of capability, even for Noland. That requires conversation  with the FDA and showing safety data for if there’s a robotic arm or a  wheelchair, that we can guarantee that they’re not going to hurt  themselves accidentally. Right? It’s very different if you’re moving  stuff in the digital domain versus in the physical space, you can  actually potentially cause harm to the participants. So, we’re working  through that right now.        

03:31:50: Speech does involve different areas of the brain. Speech prosthetic is very, very fascinating and there’s  actually been a lot of really amazing work that’s been happening in  academia. Sergey Stavisky at UC Davis, Jaimie Henderson and late Krishna Shenoy at Stanford, are doing just some incredible amount of work in  improving speech neuro-prosthetics. And those are actually looking more  at parts of the motor cortex that are controlling these vocal  articulators, and being able to, even by mouthing the word or imagine  speech, you can pick up those signals.        

03:32:31: The more sophisticated higher level  processing areas like the Broca’s area or Wernicke’s area, those are  still very, very big mystery in terms of the underlying mechanism of how all that stuff works. But I mean, I think Neuralink’s eventual goal is  to understand those things and be able to provide a platform and tools  to be able to understand that and study that.        

Lex Fridman: 03:32:58: This is where I get to the pothead  questions. Do you think we can start getting insight into things like  thought? So, speech, there’s a muscular component, like you said,  there’s the act of producing sounds, but then what about the internal  things like cognition, like low-level thoughts and high-level thoughts?  Do you think we’ll start noticing signals that could be picked up, they  could be understood, that could be maybe used in order to interact with  the outside world?        

DJ Seo: 03:33:35: In some ways, I guess, this starts to  kind of get into the hard problem of consciousness. And I mean, on one  hand, all of these are at some point, set of electrical signals that  from there maybe it in itself is giving you the cognition or the  meaning, or somehow human mind is an incredibly amazing storytelling  machine. So, we’re telling ourselves and fooling ourselves that there’s  some interesting meaning here.        

03:34:13: But I mean, I certainly think that BCI … Really, BCI, at the end of the day is a set of tools that help you  study the underlying mechanisms in a both local but also broader sense,  and whether there’s some interesting patterns of electrical signal that  means you’re thinking this versus … And you can either learn from many,  many sets of data to correlate some of that and be able to do mind  reading or not. I’m not sure.        

03:34:47: I certainly would not rule that out as a possibility, but I think BCI alone probably can’t do that. There’s  probably additional set of tools and framework and also just hard  problem of consciousness, at the end of the day, is rooted in this  philosophical question of what is the meaning of it all? What’s the  nature of our existence? Where’s the mind emerged from this complex  network?        

Lex Fridman: 03:35:13: Yeah. How does the subjective experience emerge from just a bunch of spikes, electrical spikes?        

DJ Seo: 03:35:21: Yeah. Yeah. I mean, we do really think about BCI and what we’re building as a tool for understanding the mind, the brain. The only question that matters.        

03:35:34: There actually is some biological  existence proof of what it would take to kind of start to form some of  these experiences that may be unique. If you actually look at every one  of our brains, there are two hemispheres. There’s a left-sided brain,  there’s a right-sided brain. And unless you have some other conditions,  you normally don’t feel like left legs or right legs, you just feel like one legs, right? So, what is happening there? Right?        

03:36:10: If you actually look at the two  hemispheres, there’s a structure that kind of connectorized the two,  called the corpus callosum, that is supposed to have around 200 to 300  million connections or axons. So, whether that means that’s the number  of interface and electrodes that we need to create some sort of mind  meld or from that whatever new conscious experience that you can  experience. But I do think that there’s kind of an interesting existence proof that we all have.        

Lex Fridman: 03:36:52: And that threshold is unknown at this time?        

DJ Seo: 03:36:55: Oh, yeah. Everything in this domain is speculation. Right?        

Lex Fridman: 03:37:00: And then, you’d be continuously  pleasantly surprised. Do you see a world where there is millions of  people, like tens of millions, hundreds of millions of people walking  around with a Neuralink device or multiple Neuralink devices in their  brain?        

DJ Seo: 03:37:20: I do. First of all, there are, if you  look at worldwide, people suffering from movement disorders and visual  deficits, I mean, that’s in the tens if not hundreds of millions of  people. So, that alone, I think there’s a lot of benefit and potential  good that we can do with this type of technology. And once you start to  get into psychiatric application, depression, anxiety, hunger or  obesity, right? Mood, control of appetite. I mean, that starts to become very real to everyone.        

Lex Fridman: 03:38:06: Not to mention that most people on  Earth have a smartphone, and once BCI starts competing with a smartphone as a preferred methodology of interacting with the digital world, that  also becomes an interesting thing.        

DJ Seo: 03:38:24: Oh yeah, this is even before going to  that, right? There’s almost, I mean, the entire world that could benefit from these types of things. And then, if we’re talking about next  generation of how we interface with machines or even ourselves, in many  ways, I think BCI can play a role in that. And some of the things that I also talk about is, I do think that there is a real possibility that  you could see 8 billion people walking around with Neuralink.        

Lex Fridman: 03:38:58: Well, thank you so much for pushing ahead. And I look forward to that exciting future.        

DJ Seo: 03:39:04: Thanks for having me.        

## Matthew MacDougall

Lex Fridman: 03:39:06: Thanks for listening to this  conversation with DJ Seo. And now, dear friends, here’s Matthew  MacDougall, the head neurosurgeon at Neuralink.        

03:39:17: When did you first become fascinated with the human brain?        

Matthew MacDougall: 03:39:21: Since forever. As far back as I can  remember, I’ve been interested in the human brain. I mean, I was a  thoughtful kid and a bit of an outsider, and you sit there thinking  about what the most important things in the world are in your little  tiny adolescent brain. And the answer that I came to, that I converged  on was that all of the things you can possibly conceive of as things  that are important for human beings to care about are literally  contained in the skull. Both the perception of them and their relative  values and the solutions to all our problems, and all of our problems,  are all contained in the skull. And if we knew more about how that  worked, how the brain encodes information and generates desires and  generates agony and suffering, we could do more about it.        

03:40:27: You think about all the really great  triumphs in human history. You think about all the really horrific  tragedies. You think about the Holocaust, you think about any prison  full of human stories, and all of those problems boil down to  neurochemistry. So, if you get a little bit of control over that, you  provide people the option to do better. In the way I read history, the  way people have dealt with having better tools is that they most often,  in the end, do better, with huge asterisks. But I think it’s an  interesting, a worthy, a noble pursuit to give people more options, more tools.        

Lex Fridman: 03:41:16: Yeah, that’s a fascinating way to look at human history. You just imagine all these neurobiological  mechanisms, Stalin, Hitler, Genghis Khan, all of them just had a brain,  just a bunch of neurons, few times of billions of neurons gaining a  bunch of information over a period of time. They have a set of modules  that does language and memory and all that. And from there, in the case  of those people, they’re able to murder millions of people. And all that coming from … There’s not some glorified notion of a dictator of this  enormous mind or something like this. It’s just the brain.        

Matthew MacDougall: 03:41:59: Yeah. Yeah. I mean, a lot of that has to do with how well people like that can organize those around them.        

Lex Fridman: 03:42:08: Other brains.        

Matthew MacDougall: 03:42:09: Yeah. And so, I always find it  interesting to look to primatology, look to our closest non-human  relatives for clues as to how humans are going to behave and what  particular humans are able to achieve. And so, you look at chimpanzees  and bonobos, and they’re similar but different in their social  structures particularly. And I went to Emory in Atlanta and studied  under the great Frans de Waal, who was kind of the leading  primatologist, who recently died. And his work looking at chimps through the lens of how you would watch an episode of Friends and understand  the motivations of the characters interacting with each other. He would  look at a chimp colony and basically apply that lens. I’m massively  oversimplifying it.        

03:43:05: If you do that, instead of just  saying, “Subject 473 threw his feces at subject 471.” You talk about  them in terms of their human struggles, accord them the dignity of  themselves as actors with understandable goals and drives, what they  want out of life. And primarily, it’s the things we want out of life,  food, sex, companionship, power. You can understand chimp and bonobo  behavior in the same lights much more easily. And I think doing so gives you the tools you need to reduce human behavior from the kind of false  complexity that we layer onto it with language, and look at it in terms  of, oh, well, these humans are looking for companionship, sex, food,  power. And I think that that’s a pretty powerful tool to have in  understanding human behavior.        

Lex Fridman: 03:44:10: And I just went to the Amazon jungle  for a few weeks and it’s a very visceral reminder that a lot of life on  Earth is just trying to get laid. They’re all screaming at each other. I saw a lot of monkeys and they’re just trying to impress each other, or  maybe if there’s a battle for power, but a lot of the battle for power  has to do with them getting laid.        

Matthew MacDougall: 03:44:33: Right. Breeding rights often go with alpha status. And so, if you can get a piece of that, then you’re going to do okay.        

Lex Fridman: 03:44:40: And we’d like to think that we’re  somehow fundamentally different, and especially when it comes to  primates, we really aren’t. We can use fancier poetic language, but  maybe some of the underlying drives and motivators are similar.        

Matthew MacDougall: 03:44:57: Yeah, I think that’s true.        

## Neuroscience

Lex Fridman: 03:44:58: And all of that is coming from this, the brain.        

Matthew MacDougall: 03:45:01: Yeah.        

Lex Fridman: 03:45:02: So, when did you first start studying the brain as the biological mechanism?        

Matthew MacDougall: 03:45:07: Basically, the moment I got to  college, I started looking around for labs that I could do neuroscience  work in. I originally approached that from the angle of looking at  interactions between the brain and the immune system, which isn’t the  most obvious place to start, but I had this idea at the time that the  contents of your thoughts would have a direct impact, maybe a powerful  one, on non-conscious systems in your body. The systems we think of as  homeostatic automatic mechanisms, like fighting off a virus, like  repairing a wound. And sure enough, there are big crossovers between the two.        

03:45:55: I mean, it gets to kind of a key point that I think goes under-recognized. One of the things people don’t  recognize or appreciate about the human brain enough, and that is that  it basically controls or has a huge role in almost everything that your  body does. You try to name an example of something in your body that  isn’t directly controlled or massively influenced by the brain, and it’s pretty hard. I mean, you might say like bone healing or something. But  even those systems, the hypothalamus and pituitary end up playing a role in coordinating the endocrine system, that does have a direct influence on say, the calcium level in your blood, that goes to bone healing. So, non-obvious connections between those things implicate the brain as  really a potent prime mover in all of health.        

Lex Fridman: 03:46:55: One of the things I realized in the  other direction too, how most of the systems in the body are integrated  with the human brain, they affect the brain also, like the immune  system. I think there’s just, people who study Alzheimer’s and those  kinds of things, it’s just surprising how much you can understand of  that from the immune system, from the other systems that don’t obviously seem to have anything to do with the nervous system. They all play  together.        

Matthew MacDougall: 03:47:28: Yeah, you could understand how that  would be driven by evolution too. Just in some simple examples, if you  get sick, if you get a communicable disease, you get the flu, it’s  pretty advantageous for your immune system to tell your brain, “Hey, now be antisocial for a few days. Don’t go be the life of the party  tonight. In fact, maybe just cuddle up somewhere warm, under a blanket,  and just stay there for a day or two.” And sure enough, that tends to be the behavior that you see both in animals and in humans. If you get  sick, elevated levels of interleukins in your blood and TNF-alpha in  your blood, ask the brain to cut back on social activity and even moving around, you have lower locomotor activity in animals that are infected  with viruses.        

Lex Fridman: 03:48:25: So, from there, the early days in neuroscience to surgery, when did that step happen? Which is a leap.        

Matthew MacDougall: 03:48:34: Yeah. It was sort of an evolution of  thought. I wanted to study the brain. I started studying the brain in  undergrad in this neuroimmunology lab. I, from there, realized at some  point that I didn’t want to just generate knowledge. I wanted to affect  real changes in the actual world, in actual people’s lives. And so,  after having not really thought about going into medical school, I was  on a track to go into a PhD program. I said, “Well, I’d like that  option. I’d like to actually potentially help tangible people in front  of me.”        

03:49:18: And doing a little digging, found that there exists these MD-PhD programs where you can choose not to choose  between them and do both. And so, I went to USC for medical school and  had a joint PhD program with Caltech, where I actually chose that  program particularly because of a researcher at Caltech named Richard  Andersen, who’s one of the godfathers of primate neuroscience, and has a macaque lab where Utah arrays and other electrodes were being inserted  into the brains of monkeys to try to understand how intentions were  being encoded in the brain.        

03:50:03: So, I ended up there with the idea  that maybe I would be a neurologist and study the brain on the side. And then discovered that neurology … Again, I’m going to make enemies by  saying this, but neurology predominantly and distressingly to me, is the practice of diagnosing a thing and then saying, “Good luck with that.  There’s not much we can do.” And neurosurgery, very differently, it’s a  powerful lever on taking people that are headed in a bad direction and  changing their course in the sense of brain tumors that are potentially  treatable or curable with surgery. Even aneurysms in the brain, blood  vessels that are going to rupture, you can save lives, really, is at the end of the day what mattered to me.        

03:50:59: And so, I was at USC, as I mentioned,  that happens to be one of the great neurosurgery programs. And so, I met these truly epic neurosurgeons, Alex Khalessi, and Mike Apuzzo, and  Steve Giannotta, and Marty Weiss, these epic people that were just human beings in front of me. And so, it kind of changed my thinking from  neurosurgeons are distant gods that live on another planet and  occasionally come and visit us, to these are humans that have problems  and are people, and there’s nothing fundamentally preventing me from  being one of them. And so, at the last minute in medical school, I  changed gears from going into a different specialty and switched into  neurosurgery, which cost me a year. I had to do another year of research because I was so far along in the process that to switch into  neurosurgery, the deadlines had already passed. So, it was a decision  that cost time, but absolutely worth it.        

## Neurosurgery

Lex Fridman: 03:52:09: What was the hardest part of the training on the neurosurgeon track?        

Matthew MacDougall: 03:52:14: Yeah, two things, I think, that  residency in neurosurgery is sort of a competition of pain, of how much  pain can you eat and smile? And so, there’s work hour restrictions that  are not really … They’re viewed, I think, internally among the residents as weakness. And so, most neurosurgery residents try to work as hard as they can, and that, I think necessarily means working long hours and  sometimes over the work hour limits.        

03:52:49: We care about being compliant with  whatever regulations are in front of us, but I think more important than that, people want to give their all in becoming a better neurosurgeon  because the stakes are so high. And so, it’s a real fight to get  residents to say, go home at the end of their shift and not stay and do  more surgery.        

Lex Fridman: 03:53:12: Are you seriously saying one of the hardest things is literally forcing them to get sleep and rest and all this kind of stuff?        

Matthew MacDougall: 03:53:20: Historically that was the case.        

Lex Fridman: 03:53:21: That’s hilarious. And that’s awesome.        

Matthew MacDougall: 03:53:24: I think the next generation is more compliant and more self-care-        

Lex Fridman: 03:53:29: Weaker is what you mean. All right. I’m just kidding. I’m just kidding.        

Matthew MacDougall: 03:53:32: I didn’t say it.        

Lex Fridman: 03:53:33: Now I’m making enemies.        

Matthew MacDougall: 03:53:34: No.        

Lex Fridman: 03:53:35: Okay, I get it. Wow, that’s fascinating. So, what was the second thing?        

Matthew MacDougall: 03:53:39: The personalities. And maybe the two are connected.        

Lex Fridman: 03:53:43: So, was it pretty competitive?        

Matthew MacDougall: 03:53:45: It’s competitive, and it’s also, as we touched on earlier, primates like power. And I think neurosurgery has  long had this aura of mystique and excellence and whatever about it. And so, it’s an invitation, I think, for people that are cloaked in that  authority. A board certified neurosurgeon is basically a walking  fallacious appeal to authority. Right? You have license to walk into any room and act like you’re an expert on whatever. And fighting that  tendency is not something that most neurosurgeons do well. Humility  isn’t the forte.        

Lex Fridman: 03:54:28: Yeah. I have friends who know you and  whenever they speak about you that you have the surprising quality for a neurosurgeon of humility, which I think indicates that it’s not as  common as perhaps in other professions, because there is a kind of  gigantic sort of heroic aspect to neurosurgery, and I think it gets to  people’s head a little bit.        

Matthew MacDougall: 03:54:54: Yeah. Well, I think that allows me to  play well at an Elon company because Elon, one of his strengths, I  think, is to just instantly see through fallacy from authority. So,  nobody walks into a room that he’s in and says, “Well, goddammit, you  have to trust me. I’m the guy that built the last 10 rockets,” or  something. And he says, “Well, you did it wrong and we can do it  better.” Or, “I’m the guy that kept Ford alive for the last 50 years.  You listen to me on how to build cars.” And he says, “No.”        

03:55:34: And so, you don’t walk into a room  that he’s in and say, “Well, I’m a neurosurgeon. Let me tell you how to  do it.” He’s going to say, “Well, I’m a human being that has a brain. I  can think from first principles myself. Thank you very much. And here’s  how I think it ought to be done. Let’s go try it and see who’s right.”  And that’s proven, I think over and over in his case, to be a very  powerful approach.        

Lex Fridman: 03:55:57: If we just take that tangent, there’s a fascinating interdisciplinary team at Neuralink that you get to  interact with, including Elon. What do you think is the secret to a  successful team? What have you learned from just getting to observe  these folks, world experts in different disciplines work together?        

Matthew MacDougall: 03:56:21: There’s a sweet spot where people  disagree and forcefully speak their mind and passionately defend their  position, and yet, are still able to accept information from others and  change their ideas when they’re wrong. And so, I like the analogy of how you polish rocks. You put hard things in a hard container and spin it.  People bash against each other, and out comes a more refined product.  And so, to make a good team at Neuralink, we’ve tried to find people  that are not afraid to defend their ideas passionately and occasionally  strongly disagree with people that they’re working with, and have the  best idea come out on top.        

03:57:20: It’s not an easy balance. Again, to  refer back to the primate brain. It’s not something that is inherently  built into the primate brain to say, “I passionately put all my chips on this position, and now I’m just going to walk away from it and admit  you are right.” Part of our brains tell us that that is a power loss,  that is a loss of face, a loss of standing in the community, and now  you’re a zeta chump because your idea got trounced. And you just have to recognize that that little voice in the back of your head is  maladaptive and it’s not helping the team win.        

Lex Fridman: 03:58:04: Yeah, you have to have the confidence to be able to walk away from an idea that you hold on to. Yeah.        

Matthew MacDougall: 03:58:04: Yeah.        

Lex Fridman: 03:58:08: And if you do that often enough,  you’re actually going to become the best in the world at your thing. I  mean, that rapid iteration.        

Matthew MacDougall: 03:58:18: Yeah, you’ll at least be a member of a winning team.        

Lex Fridman: 03:58:22: Ride the wave. What did you learn …  You mentioned there’s a lot of amazing neurosurgeons at USC. What  lessons about surgery and life have you learned from those folks?        

Matthew MacDougall: 03:58:35: Yeah. I think working your ass off,  working hard while functioning as a member of a team, getting a job done that is incredibly difficult, working incredibly long hours, being up  all night, taking care of someone that you think probably won’t survive  no matter what you do. Working hard to make people that you passionately dislike look good the next morning.        

03:59:06: These folks were relentless in their  pursuit of excellent neurosurgical technique, decade over decade, and I  think were well-recognized for that excellence. So, especially Marty  Weiss, Steve Giannotta, Mike Apuzzo, they made huge contributions not  only to surgical technique, but they built training programs that  trained dozens or hundreds of amazing neurosurgeons. I was just lucky to be in their wake.        

Lex Fridman: 03:59:42: What’s that like … You mentioned doing a surgery where the person is likely not to survive. Does that wear on you?        

Matthew MacDougall: 03:59:54: Yeah. It’s especially challenging when you … With all respect to our elders, it doesn’t hit so much when  you’re taking care of an 80-year-old, and something was going to get  them pretty soon anyway. And so, you lose a patient like that, and it  was part of the natural course of what is expected of them in the coming years, regardless.        

04:00:36: Taking care of a father of two or  three, four young kids, someone in their 30s that didn’t have it coming, and they show up in your ER having their first seizure of their life,  and lo and behold, they’ve got a huge malignant inoperable or incurable  brain tumor. You can only do that, I think, a handful of times before it really starts eating away at your armor. Or, a young mother that shows  up that has a giant hemorrhage in her brain that she’s not going to  survive from. And they bring her four-year-old daughter in to say  goodbye one last time before they turn the ventilator off. The great  Henry Marsh is an English neurosurgeon who said it best, I think. He  says, “Every neurosurgeon carries with them a private graveyard.” And I  definitely feel that, especially with young parents, that kills me. They had a lot more to give. The loss of those people specifically has a  knock-on effect that’s going to make the world worse for people for a  long time. And it’s just hard to feel powerless in the face of that. And that’s where I think you have to be borderline evil to fight against a  company like Neuralink or to constantly be taking pot shots at us,  because what we’re doing is to try to fix that stuff. We’re trying to  give people options to reduce suffering. We’re trying to take the pain  out of life that broken brains brings in. And yeah, this is just our  little way that we’re fighting back against entropy, I guess.        

Lex Fridman: 04:02:52: Yeah. The amount of suffering that’s  endured when some of the things that we take for granted that our brain  is able to do is taken away, is immense. And to be able to restore some  of that functionality is a real gift.        

Matthew MacDougall: 04:03:06: Yeah. We’re just starting. We’re going to do so much more.        

## Neuralink surgery

Lex Fridman: 04:03:11: Well, can you take me through the full procedure for implanting, say, the N1 chip in Neuralink?        

Matthew MacDougall: 04:03:18: Sure. Yeah. It’s a really simple,  straightforward procedure. The human part of the surgery that I do is  dead simple. It’s one of the most basic neurosurgery procedures  imaginable. And I think there’s evidence that some version of it has  been done for thousands of years. That there are examples, I think, from ancient Egypt of healed or partially healed trepanations, and from Peru or ancient times in South America where these proto-surgeons would  drill holes in people’s skulls, presumably to let out the evil spirits,  but maybe to drain blood clots. And there’s evidence of bone healing  around the edge, meaning the people at least survived some months after a procedure.        

04:04:11: And so, what we’re doing is that. We  are making a cut in the skin on the top of the head over the area of the brain that is the most potent representation of hand intentions. And  so, if you are an expert concert pianist, this part of your brain is  lighting up the entire time you’re playing. We call it the hand knob.        

Lex Fridman: 04:04:36: The hand knob. So, it’s all the finger movements, all of that is just firing away.        

Matthew MacDougall: 04:04:43: Yep. There’s a little squiggle in the  cortex right there. One of the folds in the brain is kind of doubly  folded right on that spot. And so, you can look at it on an MRI and say, “That’s the hand knob.” And then you do a functional test and a special kind of MRI called a functional MRI, fMRI. And this part of the brain  lights up when-        

Matthew MacDougall: 04:05:00: MRI, fMRI, and this part of the brain  lights up when people, even quadriplegic people whose brains aren’t  connected to their finger movements anymore, they imagine finger  movements and this part of the brain still lights up. So we can ID that  part of the brain in anyone who’s preparing to enter our trial and say,  okay, that part of the brain we confirm is your hand intention area. And so I’ll make a little cut in the skin, we’ll flap the skin open, just  like kind of opening the hood of a car, only a lot smaller, make a  perfectly round one inch diameter hole in the skull, remove that bit of  skull, open the lining of the brain, the covering of the brain, it’s  like a little bag of water that the brain floats in, and then show that  part of the brain to our robot. And then this is where the robot shines.        

04:06:01: It can come in and take these tiny,  much smaller than human hair, electrodes and precisely insert them into  the cortex, into the surface of the brain to a very precise depth, in a  very precise spot that avoids all the blood vessels that are coating the surface of the brain. And after the robot’s done with its part, then  the human comes back in and puts the implant into that hole in the skull and covers it up, screwing it down to the skull and sewing the skin  back together. So the whole thing is a few hours long. It’s extremely  low risk compared to the average neurosurgery involving the brain that  might, say, open up a deeper part of the brain or manipulate blood  vessels in the brain. This opening on the surface of the brain with only cortical micro- insertions carries significantly less risk than a lot  of the tumor or aneurysm surgeries that are routinely done.        

Lex Fridman: 04:07:10: So cortical micro-insertions that are via robot and computer vision are designed to avoid the blood vessels.        

Matthew MacDougall: 04:07:18: Exactly.        

Lex Fridman: 04:07:19: So I know you’re a bit biased here,  but let’s compare human and machine. So what are human surgeons able to  do well and what are robot surgeons able to do well at this stage of our human civilization and development?        

Matthew MacDougall: 04:07:36: Yeah. Yeah, that’s a good question.  Humans are general purpose machines. We’re able to adapt to unusual  situations. We’re able to change the plan on the fly. I remember well a  surgery that I was doing many years ago down in San Diego where the plan was to open a small hole behind the ear and go reposition a blood  vessel that had come to lay on the facial nerve, the trigeminal nerve,  the nerve that goes to the face. When that blood vessel lays on the  nerve, it can cause just intolerable, horrific shooting pain that people describe like being zapped with a cattle prod. And so the beautiful,  elegant surgery is to go move this blood vessel off the nerve. The  surgery team, we went in there and started moving this blood vessel and  then found that there was a giant aneurysm on that blood vessel that was not easily visible on the pre-op scans. And so the plan had to  dynamically change and that the human surgeons had no problem with that, were trained for all those things.        

04:08:50: Robots wouldn’t do so well in that  situation, at least in their current incarnation, fully robotic surgery, like the electrode insertion portion of the neural link surgery, it  goes according to a set plan. And so the humans can interrupt the flow  and change the plan, but the robot can’t really change the plan midway  through. It operates according to how it was programmed and how it was  asked to run. It does its job very precisely, but not with a wide degree of latitude in how to react to changing conditions.        

Lex Fridman: 04:09:29: So there could be just a very large  number of ways that you could be surprised as a surgeon? When you enter a situation, there could be subtle things that you have to dynamically  adjust to.        

Matthew MacDougall: 04:09:38: Correct.        

Lex Fridman: 04:09:38: And robots are not good at that.        

Matthew MacDougall: 04:09:42: Currently.        

Lex Fridman: 04:09:43: Currently.        

Matthew MacDougall: 04:09:44: I think we are at the dawn of a new  era with AI of the parameters for robot responsiveness to be  dramatically broadened, right? I mean, you can’t look at a self-driving  car and say that it’s operating under very narrow parameters. If a  chicken runs across the road, it wasn’t necessarily programmed to deal  with that specifically, but a Waymo or a self-driving Tesla would have  no problem reacting to that appropriately. And so surgical robots aren’t there yet, but give it time.        

Lex Fridman: 04:10:23: And then there could be a lot of  semi-autonomous possibilities of maybe a robotic surgeon could say this  situation is perfectly familiar, or this situation is not familiar, and  in the not familiar case, a human could take over, but basically be very conservative in saying, okay, this for sure has no issues, no  surprises, and let the humans deal with the surprises with the edge  cases and all that. That’s one possibility. So you think eventually  you’ll be out of the job? Well, you being neurosurgeon, your job being a neurosurgeon. Humans, there will not be many neurosurgeons left on this earth.        

Matthew MacDougall: 04:11:06: I’m not worried about my job in the  course of my professional life. I think I would tell my kids not  necessarily to go in this line of work depending on how things look in  20 years.        

Lex Fridman: 04:11:24: It’s so fascinating because if I have a line of work, I would say it’s programming. And if you ask me, for the  last, I don’t know, 20 years, what I would recommend for people, I would tell them, yeah, you’ll always have a job if you’re a programmer  because there’s more and more computers and all this kind of stuff and  it pays well. But then you realize these large language models come  along and they’re really damn good at generating code. So overnight you  could be surprised like, wow, what is the contribution of the human  really? But then you start to think, okay, it does seem that humans have ability, like you said, to deal with novel situations. In the case of  programming, it’s the ability to come up with novel ideas to solve  problems. It seems like machines aren’t quite yet able to do that. And  when the stakes are very high, when it’s life critical as it is in  surgery, especially in neurosurgery, then the stakes are very high for a robot to actually replace a human. But it’s fascinating that in this  case of Neuralink, there’s a human robot collaboration.        

Matthew MacDougall: 04:12:34: Yeah, yeah. I do the parts it can’t do and it does the parts I can’t do, and we are friends.        

Lex Fridman: 04:12:45: I saw that there’s a lot of practice  going on. I mean everything in Neuralink is tested extremely rigorously, but one of the things I saw that there’s a proxy on which the surgeries are performed. So this is both for the robot and for the human, for  everybody involved in the entire pipeline. What’s that like, practicing  the surgery?        

Matthew MacDougall: 04:13:07: It’s pretty intense. So there’s no  analog to this in human surgery. Human surgery is sort of this artisanal craft that’s handed down directly from master to pupil over the  generations. I mean, literally the way you learn to be a surgeon on  humans is by doing surgery on humans. I mean, first you watch your  professors do a bunch of surgery, and then finally they put the trivial  parts of the surgery into your hands, and then the more complex parts,  and as your understanding of the point and the purposes of the surgery  increases, you get more responsibility in the perfect condition. Doesn’t always go well. In Neuralink’s case, the approach is a bit different.  We, of course, practiced as far as we could on animals. We did hundreds  of animal surgeries. And when it came time to do the first human, we had just an amazing team of engineers build incredibly lifelike models. One of the engineers, Fran Romano in particular, built a pulsating brain in a custom 3-D printed skull that matches exactly the patient’s anatomy,  including their face and scalp characteristics.        

04:14:35: And so when I was able to practice  that, it’s as close as it really reasonably should get to being the real thing in all the details, including having a mannequin body attached to this custom head. And so when we were doing the practice surgeries,  we’d wheel that body into the CT scanner and take a mock CT scan and  wheel it back in and conduct all the normal safety checks, verbally,  “Stop. This patient we’re confirming his identification is mannequin  number…” Blah, blah, blah. And then opening the brain in exactly the  right spot using standard operative neuro-navigation equipment, standard surgical drills in the same OR that we do all of our practice surgeries in at Neuralink and having the skull open and have the brain pulse,  which adds a degree of difficulty for the robot to perfectly precisely  plan and insert those electrodes to the right depth and location. And so we kind of broke new ground on how extensively we practiced for this  surgery.        

Lex Fridman: 04:15:52: So there was a historic moment, a big  milestone for Neuralink, in part for humanity, with the first human  getting a Neuralink implant in January of this year. Take me through the surgery on Noland. What did it feel like to be part of this?        

Matthew MacDougall: 04:16:13: Yeah. Well, we are lucky to have just  incredible partners at the Barrow Neurologic Institute. They are, I  think, the premier neurosurgical hospital in the world. They made  everything as easy as possible for the trial to get going and helped us  immensely with their expertise on how to arrange the details. It was a  much more high pressure surgery in some ways. I mean, even though the  outcome wasn’t particularly in question in terms of our participant’s  safety, the number of observers, the number of people, there’s  conference rooms full of people watching live streams in the hospital  rooting for this to go perfectly, and that just adds pressure that is  not typical for even the most intense production neurosurgery, say,  removing a tumor or placing deep brain stimulation electrodes, and it  had never been done on a human before. There were unknown unknowns.        

04:17:27: And so definitely a moderate pucker  factor there for the whole team not knowing if we were going to  encounter, say, a degree of brain movement that was unanticipated or a  degree of brain sag that took the brain far away from the skull and made it difficult to insert or some other unknown unknown problem.  Fortunately everything went well and that surgery is one of the  smoothest outcomes we could have imagined.        

Lex Fridman: 04:18:03: Were you nervous?        

Matthew MacDougall: 04:18:04: Extremely.        

Lex Fridman: 04:18:05: I mean, you’re a bit of a quarterback in the Super Bowl kind of situation.        

Matthew MacDougall: 04:18:07: Extremely nervous. Extremely. I was very pleased when it went well and when it was over. Looking forward to number two.        

Lex Fridman: 04:18:17: Even with all that practice, all of  that, you’ve never been in a situation that’s so high stakes in terms of people watching. And we should also probably mention, given how the  media works, a lot of people may be in a dark kind of way hoping it  doesn’t go well.        

Matthew MacDougall: 04:18:36: I think wealth is easy to hate or envy or whatever, and I think there’s a whole industry around driving clicks and bad news is great for clicks, and so any way to take an event and  turn it into bad news is going to be really good for clicks.        

Lex Fridman: 04:19:00: It just sucks because I think it puts  pressure on people. It discourages people from trying to solve really  hard problems because to solve hard problems, you have to go into the  unknown. You have to do things that haven’t been done before and you  have to take risks, calculated risks, you have to do all kinds of safety precautions, but risks nevertheless. I just wish there would be more  celebration of that, of the risk taking versus people just waiting on  the sidelines waiting for failure and then pointing out the failure.  Yeah, it sucks. But in this case, it’s really great that everything went just flawlessly, but it’s unnecessary pressure, I would say.        

Matthew MacDougall: 04:19:41: Now that there’s a human with literal  skin in the game, there’s a participant whose well-being rides on this  doing well. You have to be a pretty person to be rooting for that to go  wrong. And so hopefully people look in the mirror and realize that at  some point.        

Lex Fridman: 04:20:01: So did you get to actually front row seat, watch the robot work? You get to see the whole thing?        

Matthew MacDougall: 04:20:08: Yeah, because an MD needs to be in  charge of all of the medical decision-making throughout the process, I  unscrubbed from the surgery after exposing the brain and presenting it  to the robot and placed the targets on the robot software interface that tells the robot where it’s going to insert each thread. That was done  with my hand on the mouse, for whatever that’s worth.        

Lex Fridman: 04:20:39: So you were the one placing the targets?        

Matthew MacDougall: 04:20:41: Yeah.        

Lex Fridman: 04:20:42: Oh, cool. So the robot with a computer vision provides a bunch of candidates and you kind of finalize the decision.        

Matthew MacDougall: 04:20:52: Right. The software engineers are  amazing on this team, and so they actually provided an interface where  you can essentially use a lasso tool and select a prime area of brain  real estate, and it will automatically avoid the blood vessels in that  region and automatically place a bunch of targets. That allows the human robot operator to select really good areas of brain and make dense  applications of targets in those regions, the regions we think are going to have the most high fidelity representations of finger movements and  arm movement intentions.        

Lex Fridman: 04:21:37: I’ve seen images of this and for me  with OCD, for some reason, are really pleasant. I think there’s a  Subreddit called Oddly Satisfying.        

Matthew MacDougall: 04:21:46: Yeah, love that Subreddit.        

Lex Fridman: 04:21:49: It’s oddly satisfying to see the  different target sites avoiding the blood vessels and also maximizing  the usefulness of those locations for the signal. It just feels good.  It’s like, ah.        

Matthew MacDougall: 04:22:02: As a person who has a visceral  reaction to the brain bleeding, I can tell you it’s extremely satisfying watching the electrodes themselves go into the brain and not cause  bleeding.        

Lex Fridman: 04:22:12: Yeah. Yeah. So you said the feeling was of relief when everything went perfectly?        

Matthew MacDougall: 04:22:18: Yeah.        

## Brain surgery details

Lex Fridman: 04:22:20: How deep in the brain can you  currently go and eventually go, let’s say on the Neuralink side. It  seems the deeper you go in the brain, the more challenging it becomes.        

Matthew MacDougall: 04:22:34: Yeah. So talking broadly about  neurosurgery, we can get anywhere. It’s routine for me to put deep brain stimulating electrodes near the very bottom of the brain, entering from the top and passing about a two millimeter wire all the way into the  bottom of the brain. And that’s not revolutionary, a lot of people do  that, and we can do that with very high precision. I use a robot from  Globus to do that surgery several times a month. It’s pretty routine.        

Lex Fridman: 04:23:12: What are your eyes in that situation?  What are you seeing? What kind of technology can you use to visualize  where you are to light your way?        

Matthew MacDougall: 04:23:20: Yeah, so it’s a cool process on the  software side. You take a preoperative MRI that’s extremely high  resolution, data of the entire brain, you put the patient to sleep, put  their head in a frame that holds the skull very rigidly, and then you  take a CT scan of their head while they’re asleep with that frame on and then merge the MRI and the CT in software. You have a plan based on the MRI where you can see these nuclei deep in the brain. You can’t see  them on CT, but if you trust the merging of the two images, then you  indirectly know on the CT where that is, and therefore indirectly know  where in reference to the titanium frame screwed to their head those  targets are. And so this is sixties technology to manually compute  trajectories given the entry point and target and dial in some goofy  looking titanium manual actuators with little tick marks on them.        

04:24:32: The modern version of that is to use a robot. Just like a little Kuka arm you might see building cars at the  Tesla factory, this small robot arm can show you the trajectory that you intended from the pre-op MRI and establish a very rigid holder through  which you can drill a small hole in the skull and pass a small rigid  wire deep into that area of the brain that’s hollow, and put your  electrode through that hollow wire and then remove all of that except  the electrode. So you end up with the electrode very, very precisely  placed far from the skull surface. Now, that’s standard technology  that’s already been out in the world for a while. Neuralink right now is focused entirely on cortical targets, surface targets because there’s  no trivial way to get, say, hundreds of wires deep inside the brain  without doing a lot of damage. So your question, what do you see? Well, I see an MRI on a screen. I can’t see everything that DBS electrode is  passing through on its way to that deep target.        

04:25:48: And so it’s accepted with this  approach that there’s going to be about one in a hundred patients who  have a bleed somewhere in the brain as a result of passing that wire  blindly into the deep part of the brain. That’s not an acceptable safety profile for Neuralink. We start from the position that we want this to  be dramatically maybe two or three orders of magnitude safer than that,  safe enough, really, that you or I, without a profound medical problem,  might on our lunch break someday say, “Yeah, sure, I’ll get that. I’d  been meaning to upgrade to the latest version.” And so the safety  constraints given that are high, and so we haven’t settled on a final  solution for arbitrarily approaching deep targets in the brain.        

Lex Fridman: 04:26:46: It’s interesting because you have to  avoid blood vessels somehow, and you have to… Maybe there’s creative  ways of doing the same thing, like mapping out high resolution geometry  of blood vessels, and then you can go in blind, but how do you map out  that in a way that’s super stable? There’s a lot of interesting  challenges there, right?        

Matthew MacDougall: 04:27:05: Yeah.        

Lex Fridman: 04:27:06: But there’s a lot to do on the surface.        

Matthew MacDougall: 04:27:07: Exactly. So we’ve got vision on the  surface. We actually have made a huge amount of progress sewing  electrodes into the spinal cord as a potential workaround for a spinal  cord injury that would allow a brain mounted implant to translate motor  intentions to a spine mounted implant that can affect muscle  contractions in previously paralyzed arms and legs.        

Lex Fridman: 04:27:36: That’s mind blowing. That’s just  incredible. So the effort there is to try to bridge the brain to the  spinal cord to the peripheral in your nervous… So how hard is that to  do?        

Matthew MacDougall: 04:27:47: We have that working in very crude forms in animals.        

Lex Fridman: 04:27:52: That’s amazing.        

Matthew MacDougall: 04:27:53: Yeah, we’ve done…        

Lex Fridman: 04:27:54: So similar to with Noland where he’s  able to digitally move the cursor. Here you’re doing the same kind of  communication, but with the effectors that you have.        

Matthew MacDougall: 04:28:06: Yeah.        

Lex Fridman: 04:28:07: That’s fascinating.        

Matthew MacDougall: 04:28:08: So we have anesthetized animals doing  grasp and moving their legs in a sort of walking pattern. Again, early  days, but the future is bright for this kind of thing, and people with  paralysis should look forward to that bright future. They’re going to  have options.        

Lex Fridman: 04:28:30: And there’s a lot of sort of  intermediate or extra options where you take an optimist robot like the  arm, and to be able to control the arm, the fingers and hands of the arm as a prosthetic.        

Matthew MacDougall: 04:28:47: Exoskeletons are getting better too.        

Lex Fridman: 04:28:49: Exoskeletons. So that goes hand in  hand. Although I didn’t quite understand until thinking about it deeply  and doing more research about Neuralink how much you can do on the  digital side. So this digital telepathy. I didn’t quite understand that  you can really map the intention, as you described in the hand knob  area, that you can map the intention. Just imagine it. Think about it.  That intention can be mapped to actual action in the digital world, and  now more and more, so much can be done in the digital world that it can  reconnect you to the outside world. It can allow you to have freedom,  have independence if you’re a quadriplegic. That’s really powerful. You  can go really far with that.        

Matthew MacDougall: 04:29:40: Yeah, our first participant is… He’s incredible. He’s breaking world records left and right.        

Lex Fridman: 04:29:46: And he’s having fun with it. It’s  great. Just going back to the surgery. Your whole journey, you mentioned to me offline you have surgery on Monday, so like you’re doing surgery  all the time. Yeah. Maybe the ridiculous question, what does it take to  get good at surgery?        

Matthew MacDougall: 04:30:04: Practice, repetitions. Same with  anything else. There’s a million ways of people saying the same thing  and selling books saying it, but you call it 10,000 hours, you call it  spend some chunk of your life, some percentage of your life focusing on  this, obsessing about getting better at it. Repetitions, humility,  recognizing that you aren’t perfect at any stage along the way,  recognizing you’ve got improvements to make in your technique, being  open to feedback and coaching from people with a different perspective  on how to do it, and then just the constant will to do better. That,  fortunately, if you’re not a sociopath, I think your patients bring that with them to the office visits every day. They force you to want to do  better all the time.        

Lex Fridman: 04:31:01: Yeah, just step up. I mean, it’s a real human being, a real human being that you can help.        

Matthew MacDougall: 04:31:07: Yeah.        

Lex Fridman: 04:31:08: So every surgery, even if it’s the same exact surgery, is there a lot of variability between that surgery in a different person?        

Matthew MacDougall: 04:31:15: Yeah. A fair bit. A good example for  us is the angle of the skull relative to the normal plane of the body  axis of the skull over hand knob is pretty wide variation. Some people  have really flat skulls and some people have really steeply angled  skulls over that area, and that has consequences for how their head can  be fixed in sort of the frame that we use and how the robot has to  approach the skull. Yeah, people’s bodies are built as differently as  the people you see walking down the street, as much variability and body shape and size as you see there. We see in brain anatomy and skull  anatomy, there are some people who we’ve had to exclude from our trial  for having skulls that are too thick or too thin or scalp that’s too  thick or too thin. I think we have the middle 97% or so of people, but  you can’t account for all human anatomy variability.        

Lex Fridman: 04:32:29: How much mushiness and mess is there?  Because taking biology classes, the diagrams are always really clean and crisp. Neuroscience, the pictures of neurons are always really nice and [inaudible 04:32:44], but whenever I look at pictures of real brains,  they’re all… I don’t know what is going on. So how much our biological  systems in reality, how hard is it to figure out what’s going on?        

Matthew MacDougall: 04:32:59: Not too bad. Once you really get used  to this, that’s where experience and skill and education really come  into play is if you stare at a thousand brains, it becomes easier to  kind of mentally peel back the, say, for instance, blood vessels that  are obscuring the sulci and gyri, know kind of the wrinkle pattern of  the surface of the brain. Occasionally when you’re first starting to do  this and you open the skull, it doesn’t match what you thought you were  going to see based on the MRI. And with more experience, you learn to  kind of peel back that layer of blood vessels and see the underlying  pattern of wrinkles in the brain and use that as a landmark for where  you are.        

Lex Fridman: 04:33:51: The wrinkles are a landmark?        

Matthew MacDougall: 04:33:53: Yeah. So I was describing hand knob  earlier. That’s a pattern of the wrinkles in the brain. It’s sort of  this Greek letter, omega shaped area of the brain.        

Lex Fridman: 04:34:04: So you could recognize the hand knob  area. If I show you a thousand brains and give you one minute with each, you’d be like, “Yep, that’s that.”        

Matthew MacDougall: 04:34:12: Sure.        

Lex Fridman: 04:34:13: And so there is some uniqueness to that area of the brain in terms of the geometry, the topology of the thing.        

Matthew MacDougall: 04:34:19: Yeah.        

Lex Fridman: 04:34:21: Where is it about in the…        

Matthew MacDougall: 04:34:24: So you have this strip of brain  running down the top called the primary motor area, and I’m sure you’ve  seen this picture of the homunculus laid over the surface of the brain,  the weird little guy with huge lips and giant hands. That guy sort of  lays with his legs up at the top of the brain and face arm areas farther down, and then some kind of mouth, lip, tongue areas farther down. And  so the hand is right in there, and then the areas that control speech,  at least on the left side of the brain in most people are just below  that. And so any muscle that you voluntarily move in your body, the vast majority of that references that strip or those intentions come from  that strip of brain, and the wrinkle for hand knob is right in the  middle of that.        

Lex Fridman: 04:35:22: And vision is back here?        

Matthew MacDougall: 04:35:24: Yep.        

Lex Fridman: 04:35:25: Also close to the surface.        

Matthew MacDougall: 04:35:27: Vision’s a little deeper. And so this  gets to your question about how deep can you get. To do vision, we can’t just do the surface of the brain. We have to be able to go in, not as  deep as we’d have to go for DBS, but maybe a centimeter deeper than  we’re used to for hand insertions. And so that’s work in progress.  That’s a new set of challenges to overcome.        

Lex Fridman: 04:35:55: By the way, you mentioned the Utah Array and I just saw a picture of that and that thing looks terrifying.        

Matthew MacDougall: 04:36:02: Yeah. The nails.        

Lex Fridman: 04:36:04: It’s because it’s rigid and then if  you look at the threads, they’re flexible. What can you say that’s  interesting to you about that kind of approach of the flexible threads  to deliver the electrodes next to the neurons?        

Matthew MacDougall: 04:36:18: Yeah. I mean, the goal there comes  from experience. I mean, we stand on the shoulders of people that made  Utah Arrays and used Utah Arrays for decades before we ever even came  along. Neuralink arose, partly this approach to technology arose out of a need recognized after Utah Arrays would fail routinely because the  rigid electrodes, those spikes that are literally hammered using an air  hammer into the brain, those spikes generate a bad immune response that  encapsulates the electrode spikes in scar tissue essentially. And so one of the projects that was being worked on in the Anderson Lab at Caltech when I got there was to see if you could use chemotherapy to prevent  the formation of scars. Things are pretty bad when you’re jamming a bed  of nails into the brain, and then treating that with chemotherapy to try to prevent scar tissue, it’s like, maybe we’ve gotten off track here,  guys. Maybe there’s a fundamental redesign necessary.        

04:37:32: And so Neuralink’s approach of using  highly flexible, tiny electrodes avoids a lot of the bleeding, avoids a  lot of the immune response that ends up happening when rigid electrodes  are pounded into the brain. And so what we see is our electrode  longevity and functionality and the health of the brain tissue  immediately surrounding the electrode is excellent. I mean, it goes on  for years now in our animal models.        

## Implanting Neuralink on self

Lex Fridman: 04:38:03: What do most people not understand about the biology of the brain? We will mention the vasculature. That’s really interesting.        

Matthew MacDougall: 04:38:10: I think the most interesting maybe  underappreciated fact is that it really does control almost everything. I don’t know, for an out of the blue example, imagine you want a lever on fertility. You want to be able to turn fertility on and off. There are  legitimate targets in the brain itself to modulate fertility, say blood  pressure. You want to modulate blood pressure, there are legitimate  targets in the brain for doing that. Things that aren’t immediately  obvious as brain problems are potentially solvable in the brain. And so I think it’s an under-explored area for primary treatments of all the  things that bother people.        

Lex Fridman: 04:39:04: That’s a really fascinating way to  look at it. There’s a lot of conditions we might think have nothing to  do with the brain, but they might just be symptoms of something that  actually started in the brain. The actual source of the problem, the  primary source is something in the brain.        

Matthew MacDougall: 04:39:19: Yeah. Not always. I mean, kidney  disease is real, but there are levers you can pull in the brain that  affect all of these systems.        

Lex Fridman: 04:39:29: There’s knobs.        

Matthew MacDougall: 04:39:30: Yeah.        

Lex Fridman: 04:39:32: On-off switches and knobs in the brain from which this all originates. Would you have a Neuralink chip implanted in your brain?        

Matthew MacDougall: 04:39:42: Yeah. I think use case right now is  use a mouse, right? I can already do that, and so there’s no value  proposition. On safety grounds alone, sure. I’ll do it tomorrow.        

Lex Fridman: 04:39:59: You know, when you say the use case of the mouse, is it…        

Lex Fridman: 04:40:00: The use case of the mouse is after  researching all this and part of it’s just watching Nolan have so much  fun. If you can get that bits per second look really high with the  mouse, being able to interact, because if you think about the way on the smartphone, the way you swipe, that was transformational. How we  interact with the thing, it’s subtle, you don’t realize it, but to be  able to touch a phone and to scroll with your finger, that changed  everything. People were sure you need a keyboard to type. There’s a lot  of HCI aspects to that that changed how we interact with computers, so  there could be a certain rate of speed with the mouse that would change  everything. You might be able to just click around a screen extremely  fast. I can’t see myself getting a Neuralink for much more rapid  interaction with the digital devices.        

Matthew MacDougall: 04:41:03: Yeah, I think recording speech  intentions from the brain might change things as well, the value  proposition for the average person. A keyboard is a pretty clunky human  interface, requires a lot of training. It’s highly variable in the  maximum performance that the average person can achieve. I think taking  that out of the equation and just having a natural word to computer  interface might change things for a lot of people.        

Lex Fridman: 04:41:40: It’d be hilarious if that is the  reason people do it. Even if you have speech to text, that’s extremely  accurate. It currently isn’t, but it’d say you’ve gotten super accurate. It’d be hilarious if people went for Neuralink. Just so you avoid the  embarrassing aspect of speaking, looking like a douchebag speaking to  your phone in public, which is a real, that’s a real constraint.        

Matthew MacDougall: 04:42:03: I mean with a bone conducting case,  that can be an invisible headphone, say, and the ability to think words  into software and have it respond to you. That starts to sound sort of  like embedded super intelligence. If you can silently ask for the  Wikipedia article on any subject and have it read to you without any  observable change happening in the outside world. For one thing,  standardized testing is obsolete.        

Lex Fridman: 04:42:43: If it’s done well in the UX side, it  could change, I don’t know if it transforms society, but it really can  create a kind of shift in the way we interact with digital devices in  the way that a smartphone did. Just having to look into the safety of  everything involved, I would totally try it. So it doesn’t have to go to some incredible thing where you have, it connects your vision or to  some other, it connects all over your brain. That could be just  connecting to the hand knob. You might have a lot of interesting  interaction, human computer interaction possibilities. That’s really  interesting.        

Matthew MacDougall: 04:43:22: And the technology on the academic  side is progressing at light speed here. There was a really amazing  paper out of UC Davis at Sergey Stavisky’s lab that basically made an  initial solve of speech decode. It was something like 125,000 words that they were getting with very high accuracy, which is-        

Lex Fridman: 04:43:47: So you’re just thinking the word?        

Matthew MacDougall: 04:43:48: Yeah.        

Lex Fridman: 04:43:49: Thinking the word and you’re able to get it?        

Matthew MacDougall: 04:43:51: Yeah.        

Lex Fridman: 04:43:51: Oh, boy. You have to have the  intention of speaking it. So do the inner voice. Man, it’s so amazing to me that you can do the intention, the signal mapping. All you have to  do is just imagine yourself doing it. And if you get the feedback that  it actually worked, you can get really good at that. Your brain will  first of all adjust and you develop, like any other skill, like touch  typing. You develop in that same kind of way.        

04:44:24: To me, it’s just really fascinating to be able to even to play with that, honestly, I would get a Neuralink  just to be able to play with that, just to play with the capacity, the  capability of my mind to learn this skill. It’s like learning the skill  of typing and learning the skill of moving a mouse. It’s another skill  of moving the mouse, not with my physical body, but with my mind.        

Matthew MacDougall: 04:44:47: I can’t wait to see what people do  with it. I feel like we’re cavemen right now. We’re banging rocks with a stick and thinking that we’re making music. At some point when these  are more widespread, there’s going to be the equivalent of a piano that  someone can make art with their brain in a way that we didn’t even  anticipate. Looking forward to it.        

Lex Fridman: 04:45:12: Give it to a teenager. Anytime I think I’m good at something I’ll always go to… I don’t know. Even with the  bits per second and playing a video game, you realize you give it to a  teenager, you give a Neuralink to a teenager. Just a large number of  them, the kind of stuff they get good at stuff, they’re going to get  hundreds of bits per second. Even just with the current technology.        

Matthew MacDougall: 04:45:37: Probably. Probably.        

Lex Fridman: 04:45:41: Because it’s also addicting, the  number go up aspect of it of improving and training. It is almost like a skill and plus there’s the software on the other end that adapts to  you, and especially if the adapting procedure algorithm becomes better  and better and better. You’re like learning together.        

Matthew MacDougall: 04:45:59: Yeah, we’re scratching the surface on that right now. There’s so much more to do.        

Lex Fridman: 04:46:03: So on the complete other side of it, you have an RFID chip implanted in you?        

Matthew MacDougall: 04:46:10: Yeah.        

Lex Fridman: 04:46:10: So I hear.        

Matthew MacDougall: 04:46:11: Nice.        

Lex Fridman: 04:46:12: So this is-        

Matthew MacDougall: 04:46:13: Little subtle thing.        

Lex Fridman: 04:46:14: It’s a passive device that you use for unlocking a safe with top secrets or what do you use it for? What’s the story behind it?        

Matthew MacDougall: 04:46:23: I’m not the first one. There’s this  whole community of weirdo biohackers that have done this stuff, and I  think one of the early use cases was storing private crypto wallet keys  and whatever. I dabbled in that a bit and had some fun with it.        

Lex Fridman: 04:46:42: You have some Bitcoin implanted in your body somewhere. You can’t tell where. Yeah, yeah.        

Matthew MacDougall: 04:46:48: Actually, yeah. It was the modern day  equivalent of finding change in the sofa cushions after I put some  orphaned crypto on there that I thought was worthless and forgot about  it for a few years. Went back and found that some community of people  loved it and had propped up the value of it, and so it had gone up  fifty-fold, so there was a lot of change in those cushions.        

Lex Fridman: 04:47:13: That’s hilarious.        

Matthew MacDougall: 04:47:14: But the primary use case is mostly as a tech demonstrator. It has my business card on it. You can scan that in  by touching it to your phone. It opens the front door to my house,  whatever, simple stuff.        

Lex Fridman: 04:47:30: It’s a cool step. It’s a cool leap to  implant something in your body. I mean, perhaps it’s a similar leap to a Neuralink because for a lot of people, that kind of notion of putting  something inside your body, something electronic inside a biological  system is a big leap.        

Matthew MacDougall: 04:47:45: We have a kind of mysticism around the barrier of our skin. We’re completely fine with knee replacements, hip  replacements, dental implants, but there’s a mysticism still around the  inviolable barrier that the skull represents, and I think that needs to  be treated like any other pragmatic barrier. The question isn’t how  incredible is it to open the skull? The question is what benefit can we  provide?        

Lex Fridman: 04:48:21: So from all the surgeries you’ve done, from everything you understand the brain, how much does neuroplasticity come into play? How adaptable is the brain? For example, just even in  the case of healing from surgery or adapting to the post-surgery  situation.        

Matthew MacDougall: 04:48:36: The answer that is sad for me and  other people of my demographic is that plasticity decreases with age.  Healing decreases with age. I have too much gray hair to be optimistic  about that. There are theoretical ways to increase plasticity using  electrical stimulation. Nothing that is totally proven out as a robust  enough mechanism to offer widely to people.        

04:49:06: But yeah, I think there’s cause for  optimism that we might find something useful in terms of say, an  implanted electrode that improves learning. Certainly there’s been some  really amazing work recently from Nicholas Schiff, Jonathan Baker and  others who have a cohort of patients with moderate traumatic brain  injury who have had electrodes placed in the deep nucleus in the brain  called the central median nucleus or just near central median nucleus,  and when they apply small amounts of electricity to that part of the  brain, it’s almost like electronic caffeine.        

04:49:46: They’re able to improve people’s  attention and focus. They’re able to improve how well people can perform a task. I think in one case, someone who was unable to work, after the  device was turned on, they were able to get a job. And that’s sort of  one of the holy grails for me with Neuralink and other technologies like this is from a purely utilitarian standpoint, can we make people able  to take care of themselves and their families economically again? Can we make it so someone who’s fully dependent and even maybe requires a lot  of caregiver resources, can we put them in a position to be fully  independent, taking care of themselves, giving back to their  communities? I think that’s a very compelling proposition and what  motivates a lot of what I do and what a lot of the people at Neuralink  are working for.        

Lex Fridman: 04:50:45: It’s just a cool possibility that if  you put a Neuralink in there, that the brain adapts the other part of  the brain adapts too and integrates it. The capacity of the brain to do  that is really interesting. Probably unknown to the degree to which you  can do that, but you’re now connecting an external thing to it,  especially once it’s doing stimulation. The biological brain and the  electronic brain outside of it working together, the possibilities there are really interesting. It’s still unknown, but interesting. It feels  like the brain is really good at adapting to whatever, but of course it  is a system that by itself is already, everything serves a purpose and  so you don’t want to mess with it too much.        

Matthew MacDougall: 04:51:39: Yeah, it’s like eliminating a species  from an ecology. You don’t know what the delicate interconnections and  dependencies are. The brain is certainly a delicate, complex beast, and  we don’t know every potential downstream consequence of a single change  that we make.        

Lex Fridman: 04:52:04: Do you see yourself doing, so you mentioned P1, surgeries of P2, P3, P4, P5? Just more and more and more humans.        

Matthew MacDougall: 04:52:14: I think it’s a certain kind of  brittleness or a failure on the company’s side if we need me to do all  the surgeries. I think something that I would very much like to work  towards is a process that is so simple and so robust on the surgery side that literally anyone could do it. We want to get away from requiring  intense expertise or intense experience to have this done and make it as simple and translatable as possible. I mean, I would love it if every  neurosurgeon on the planet had no problem doing this. I think we’re  probably far from a regulatory environment that would allow people that  aren’t neurosurgeons to do this, but not impossible.        

Lex Fridman: 04:53:08: All right, I’ll sign up for that. Did  you ever anthropomorphize the robot R1? Do you give it a name? Do you  see it as a friend as working together with you?        

Matthew MacDougall: 04:53:20: I mean, to a certain degree it’s-        

Lex Fridman: 04:53:21: Or an enemy who’s going to take your job?        

Matthew MacDougall: 04:53:25: To a certain degree, yeah. It’s complex relationship.        

Lex Fridman: 04:53:31: All the good relationships are.        

Matthew MacDougall: 04:53:32: It’s funny when in the middle of the  surgery, there’s a part of it where I stand basically shoulder to  shoulder with the robot, and so if you’re in the room reading the body  language, it’s my brother in arms there. We’re working together on the  same problem. Yeah, I’m not threatened by it.        

## Life and death

Lex Fridman: 04:53:55: Keep telling yourself that. How have  all the surgeries that you’ve done over the years, the people you’ve  helped and the stakes, the high stakes that you’ve mentioned, how has  that changed your understanding of life and death?        

Matthew MacDougall: 04:54:13: Yeah, it gives you a very visceral  sense, and this may sound trite, but it gives you a very visceral sense  that death is inevitable. On one hand, as a neurosurgeon, you’re deeply  involved in these, just hard to fathom tragedies, young parents dying,  leaving a four-year-old behind, say. And on the other hand, it takes the sting out of it a bit because you see how just mind-numbingly universal death is. There’s zero chance that I’m going to avoid it. I know  techno-optimists right now and longevity buffs right now would disagree  on that 0.000% estimate, but I don’t see any chance that our generation  is going to avoid it. Entropy is a powerful force and we are very  ornate, delicate, brittle, DNA machines that aren’t up to the cosmic ray bombardment that we’re subjected to.        

04:55:35: So on the one hand, every human that  has ever lived died or will die. On the other hand, it’s just one of the hardest things to imagine inflicting on anyone that you love is having  them gone. I mean, I’m sure you’ve had friends that aren’t living  anymore and it’s hard to even think about them. And so I wish I had  arrived at the point of nirvana where death doesn’t have a sting, I’m  not worried about it. But I can at least say that I’m comfortable with  the certainty of it, if not having found out how to take the tragedy out of it. When I think about my kids either not having me or me not having them or my wife.        

Lex Fridman: 04:56:35: Maybe I’ve come to accept the  intellectual certainty of it, but it may be the pain that comes with  losing the people you love. But I don’t think I’ve come to understand  the existential aspect of it, that this is going to end, and I don’t  mean in some trite way. I mean, it certainly feels like it’s not going  to end. You live life like it’s not going to end. And the fact that this light that’s shining, this consciousness is going to no longer be in  one moment, maybe today. It fills me when I really am able to load all  that in with Ernest Becker’s terror. It is a real fear.        

04:57:28: I think people aren’t always honest  with how terrifying it is. I think the more you are able to really think through it, the more terrifying it is. It’s not such a simple thing,  “Oh, well, it’s the way life is.” If you really can load that in, it’s  hard, but I think that’s why the Stoics did it, because it helps you get your shit together and be like, “The moment, every single moment you’re alive is just beautiful” and it’s terrifying that it’s going to end,  and it’s almost like you’re shivering in the cold, a child helpless.  This kind of feeling,        

04:58:10: And then it makes you, when you have  warmth, when you have the safety, when you have the love to really  appreciate it. I feel like sometimes in your position when you mentioned armor just to see death, it might make you not be able to see that, the finiteness of life because if you kept looking at that, it might break  you. So it is good to know that you’re kind of still struggling with  that. There’s the neurosurgeon and then there’s a human, and the human  is still able to struggle with that and feel the fear of that and the  pain of that.        

Matthew MacDougall: 04:58:51: Yeah, it definitely makes you ask the  question of how many of these can you see and not say, “I can’t do this  anymore”? But I mean you said it well, I think it gives you an  opportunity to just appreciate that you’re alive today and I’ve got  three kids and an amazing wife, and I am really happy. Things are good. I get to help on a project that I think matters. I think it moves us  forward. I’m a very lucky person.        

Lex Fridman: 04:59:30: It’s the early steps of a potentially  gigantic leap for humanity. It’s a really interesting one. And it’s cool because you read about all this stuff in history where it’s like the  early days. I’ve been reading, before going to the Amazon, I would read  about explorers that would go and explore even the Amazon jungle for the first time. It’s just those are the early steps or early steps into  space, early steps in any discipline in physics and mathematics, and  it’s cool because on the grand scale, these are the early steps into  delving deep into the human brain, so not just observing the brain but  be able to interact with the human brain. It’s going to help a lot of  people, but it also might help us understand what the hell’s going on in there.        

Matthew MacDougall: 05:00:20: Yeah. I think ultimately we want to  give people more levers that they can pull. You want to give people  options. If you can give someone a dial that they can turn on how happy  they are, I think that makes people really uncomfortable. But now talk  about major depressive disorder. Talk about people that are committing  suicide at an alarming rate in this country, and try to justify that  queasiness in that light of, you can give people a knob to take away  suicidal ideation, suicidal intention. I would give them that knob. I  don’t know how you justify not doing that.        

Lex Fridman: 05:01:11: You can think about all the suffering  that’s going on in the world, every single human being that’s suffering  right now. It’ll be a glowing red dot. The more suffering, the more it’s glowing, and you just see the map of human suffering and any technology that allows you to dim that light of suffering on a grand scale is  pretty exciting. Because there’s a lot of people suffering and most of  them suffer quietly, and we look away too often, and we should remember  those are suffering because once again, most of them are suffering  quietly.        

Matthew MacDougall: 05:01:46: Well, and on a grander scale, the  fabric of society. People have a lot of complaints about how our social  fabric is working or not working, how our politics is working or not  working. Those things are made of neurochemistry too in aggregate,  right? Our politics is composed of individuals with human brains, and  the way it works or doesn’t work is potentially tunable in the sense  that, I don’t know, say remove our addictive behaviors or tune our  addictive behaviors for social media or our addiction to outrage, our  addiction to sharing the most angry political tweet we can find. I don’t think that leads to a functional society, and if you had options for  people to moderate that maladaptive behavior, there could be huge  benefits to society. Maybe we could all work together a little more  harmoniously toward useful ends.        

Lex Fridman: 05:03:00: There’s a sweet spot, like you  mentioned. You don’t want to completely remove all the dark sides of  human nature. Those are somehow necessary to make the whole thing work,  but there’s a sweet spot.        

Matthew MacDougall: 05:03:11: Yeah, I agree. You got to suffer a little, just not so much that you lose hope.        

## Consciousness

Lex Fridman: 05:03:16: Yeah. When you, all the surgeries you’ve done, have you seen consciousness in there ever? Was there a glowing light?        

Matthew MacDougall: 05:03:22: I have this sense that I never found  it, never removed it like a Dementor in Harry Potter. I have this sense  that consciousness is a lot less magical than our instincts want to  claim it is. It seems to me like a useful analog for about what  consciousness is in the brain is that we have a really good intuitive  understanding of what it means to say, touch your skin and know what’s  being touched. And I think consciousness is just that level of sensory  mapping applied to the thought processes in the brain itself.        

05:04:10: So what I’m saying is, consciousness  is the sensation of some part of your brain being active, so you feel it working. You feel the part of your brain that thinks of red things or  winged creatures or the taste of coffee. You feel those parts of your  brain being active, the way that I’m feeling my palm being touched, and  that sensory system that feels the brain working is consciousness.        

Lex Fridman: 05:04:43: That’s so brilliant. It’s the same  way. It’s the sensation of touch when you’re touching a thing.  Consciousness is the sensation of you feeling your brain working, your  brain thinking, your brain perceiving.        

Matthew MacDougall: 05:04:59: Which isn’t like a warping of  space-time or some quantum field effect, right? It’s nothing magical.  People always want to ascribe to consciousness something truly  different, and there’s this awesome long history of people looking at  whatever the latest discovery in physics is to explain consciousness  because it’s the most magical, the most out there thing that you can  think of, and people always want to do that with consciousness. I don’t  think that’s necessary. It’s just a very useful and gratifying way of  feeling your brain work.        

Lex Fridman: 05:05:38: And as we said, it’s one heck of a  brain. Everything we see around us, everything we love, everything  that’s beautiful came from brains like these.        

Matthew MacDougall: 05:05:48: It’s all electrical activity happening inside your skull.        

Lex Fridman: 05:05:52: And I, for one, am grateful there’s  people like you that are exploring all the ways that it works and all  the ways it can be made better.        

Matthew MacDougall: 05:06:04: Thanks, Lex.        

Lex Fridman: 05:06:04: Thank you so much for talking today.        

Matthew MacDougall: 05:06:06: It’s been a joy.        

## Bliss Chapman

Lex Fridman: 05:06:08: Thanks for listening to this  conversation with Matthew MacDougall. Now, dear friends, here’s Bliss  Chapman, brain interface software lead at Neuralink. You told me that  you’ve met hundreds of people with spinal cord injuries or with ALS, and that your motivation for helping at Neuralink is grounded in wanting to help them. Can you describe this motivation?        

Bliss Chapman: 05:06:32: Yeah. First, just a thank you to all  the people I’ve gotten a chance to speak with for sharing their stories  with me. I don’t think there’s any world really in which I can share  their stories as powerful way as they can, but just I think to summarize at a very high level, what I hear over and over again is that people  with ALS or severe spinal cord injury in a place where they basically  can’t move physically anymore, really at the end of the day are looking  for independence. And that can mean different things for different  people.        

05:07:02: For some folks, it can mean the  ability just to be able to communicate again independently without  needing to wear something on their face, without needing a caretaker to  be able to put something in their mouth. For some folks, it can mean  independence to be able to work again, to be able to navigate a computer digitally, efficiently enough to be able to get a job, to be able to  support themselves, to be able to move out and ultimately be able to  support themselves after their family maybe isn’t there anymore to take  care of them.        

05:07:27: And for some folks, it’s as simple as  just being able to respond to their kid in time before they run away or  get interested in something else. And these are deeply personal and very human problems. And what strikes me again and again when talking with  these folks is that this is actually an engineering problem. This is a  problem that with the right resources, with the right team, can make a  lot of progress on. And at the end of the day, I think that’s a deeply  inspiring message and something that makes me excited to get up every  day.        

Lex Fridman: 05:08:01: So it’s both an engineering problem in terms of a BCI, for example, that can give them capabilities where they can interact with the world, but also on the other side, it’s an  engineering problem for the rest of the world to make it more accessible for people living with quadriplegia?        

Bliss Chapman: 05:08:15: Yeah. And actually, I’ll take a broad  view lens on this for a second. I think I’m very in favor of anyone  working in this problem space. So beyond BCI, I’m happy and excited and  willing to support any way I can, folks working on eye tracking systems, working on speech to text systems, working on head trackers or mouse  sticks or quad sticks. And I’ve met many engineers and folks in the  community that do exactly those things.        

05:08:38: And I think for the people we’re  trying to help, it doesn’t matter what the complexity of the solution is as long as the problem is solved. And I want to emphasize that there  can be many solutions out there that can help with these problems. And  BCI is one of a collection of such solutions. So BCI in particular, I  think offers several advantages here. And I think the folks that  recognize this immediately are usually the people who have spinal cord  injury or some form of paralysis.        

05:09:03: Usually you don’t have to explain to  them why this might be something that could be helpful. It’s usually  pretty self-evident, but for the rest of us folks that don’t live with  severe spinal cord injury or who don’t know somebody with ALS, it’s not  often obvious why you would want a brain implant to be able to connect  and navigate a computer.        

05:09:18: And it’s surprisingly nuanced, and to  the degree that I’ve learned a huge amount just working with Noland in  the first Neuralink clinical trial and understanding from him and his  words why this device is impactful for him, and it’s a nuanced topic. It can be the case that even if you can achieve the same thing, for  example, with a mouse stick when navigating a computer, he doesn’t have  access to that mouse stick every single minute of the day. He only has  access when someone is available to put it in front of him. And so a BCI can really offer a level of independence and autonomy that, if it  wasn’t literally physically part of your body, it’d be hard to achieve  in any other way.        

Lex Fridman: 05:09:52: So there’s a lot of fascinating  aspects to what it takes to get Noland to be able to control a cursor on the screen with his mind. You texted me something that I just love. You said, “I was part of the team that interviewed and selected P1, I was  in the operating room during the first human surgery monitoring live  signals coming out of the brain. I work with the user basically every  day to develop new UX paradigms, decoding strategies, and I was part of  the team that figured out how to recover useful BCI to new world record  levels when the signal quality degraded.” We’ll talk about, I think  every aspect of that, but just zooming out, what was it like to be a  part of that team and part of that historic, I would say, historic  first?        

Bliss Chapman: 05:10:38: Yeah. I think for me, this is  something I’ve been excited about for close to 10 years now. And so to  be able to be even just some small part of making it a reality is  extremely exciting. A couple maybe special moments during that whole  process that I’ll never really truly forget. One of them is entering the actual surgery. At that point in time, I know Noland quite well. I know his family. And so I think the initial reaction when Noland is rolled  into the operating room is just an “Oh, shit” kind of reaction. But at  that point, muscle memory kicks in and you sort of go into, you let your body just do all the talking.        

05:11:19: And I have the lucky job in that  particular procedure to just be in charge of monitoring the implant. So  my job is to sit there, to look at the signals coming off the implant,  to look at the live brain data streaming off the device as threads are  being inserted into the brain and just to basically observe and make  sure that nothing is going wrong or that there’s no red flags or fault  conditions that we need to go and investigate or pause the surgery to  debug.        

05:11:40: And because I had that sort of  spectator view of the surgery, I had a slightly removed perspective than I think most folks in the room. I got to sit there and think to myself, “Wow, that brain is moving a lot.” When you look inside the craniectomy that we stick the threads in, one thing that most people don’t realize  is the brain moves. The brain moves a lot when you breathe, your heart  beats, and you can see it visibly. So that’s something that I think was a surprise to me and very, very exciting to be able to see someone’s  brain who you physically know and have talked with that length, actually pausing and moving inside their skull.        

Lex Fridman: 05:12:15: And they used that brain to talk to you previously, and now it’s right there moving.        

Bliss Chapman: 05:12:19: Yep.        

Lex Fridman: 05:12:21: Actually, I didn’t realize that in  terms of the thread sending, so the Neuralink implant is active during  surgery and one thread at a time, you’re able to start seeing the  signal?        

Bliss Chapman: 05:12:32: Yeah.        

Lex Fridman: 05:12:32: So that’s part of the way you test that the thing is working?        

Bliss Chapman: 05:12:35: Yeah. So actually in the operating  room, right after we sort of finished all the thread insertions, I  started collecting what’s called broadband data. So broadband is  basically the most raw form of signal you can collect from a Neuralink  electrode. It’s essentially a measurement of the local fuel potential or the voltage essentially measured by that electrode. And we have a  certain mode in our application that allows us to visualize where  detected spikes are. So it visualizes where in the broadband signal and  it’s very, very raw form of the data, a neuron is actually spiking. And  so one of these moments that I’ll never forget as part of this whole  clinical trial is seeing live in the operating room while he’s still  under anesthesia, beautiful spikes being shown in the application, just  streaming live to a device I’m holding in my hand.        

Lex Fridman: 05:13:22: So this is no signal processing the  raw data, and then the signals processing is on top of it, you’re seeing the spikes detected?        

Bliss Chapman: 05:13:28: Right.        

Lex Fridman: 05:13:30: And that’s a UX too, that looks beautiful as well.        

Bliss Chapman: 05:13:35: During that procedure, there was  actually a lot of cameramen in the room, so they also were curious and  wanted to see, there’s several neurosurgeons in the room who were all  just excited to see robots taking their job, and they were all crowded  around a small little iPhone watching this live brain data stream out of his brain.        

Lex Fridman: 05:13:51: What was that like seeing the robot do some of the surgery? So the computer vision aspect where it detects all the spots that avoid the blood vessels, and then obviously with the  human supervision, then actually doing the really high precision  connection of the threads to the brain?        

Bliss Chapman: 05:14:11: That’s a good question. My answer is going to be pretty lame here, but it was boring. I’ve seen it so many times.        

Lex Fridman: 05:14:11: The way you want it to be.        

Bliss Chapman: 05:14:17: Yeah, that’s exactly how you want  surgery to be. You want it to be boring. I’ve seen it so many times.  I’ve seen the robot do the surgery literally hundreds of times, and so  it was just one more time.        

Lex Fridman: 05:14:29: Yeah, all the practice surgeries and the proxies, and this is just another day.        

Bliss Chapman: 05:14:33: Yeah.        

Lex Fridman: 05:14:35: So what about when Noland woke up? Do  you remember a moment where he was able to move the cursor, not move the cursor, but get signal from the brain such that it was able to show  that there’s a connection?        

Bliss Chapman: 05:14:49: Yeah. Yeah. So we are quite excited to move as quickly as we can, and Noland was really, really excited to get started. He wanted to get started, actually the day of surgery, but we  waited until the next morning very patiently. It’s a long night.        

Bliss Chapman: 05:15:00: … we waited until the next morning  very patiently. So a long night. And the next morning in the ICU where  he was recovering, he wanted to get started and actually start to  understand what kind of signal we can measure from his brain. And maybe  for folks who are not familiar with the Neuralink system, we implant the Neuralink system or the Neuralink implant in the motor cortex. So the  motor cortex is responsible for representing things like motor intent.  If you imagine closing and opening your hand, that kind of signal  representation would be present in the motor cortex.        

05:15:31: If you imagine moving your arm back  and forth or wiggling a pinky, this sort of signal can be present in the motor cortex. So one of the ways we start to map out what kind of  signal do we actually have access to, in any particular individual’s  brain, is through this task called body mapping. And body mapping is  where you essentially present a visual to the user and you say, “Hey,  imagine doing this,” and their visual is a 3D hand opening, closing or  index finger modulating up and down.        

05:15:55: And you ask the user to imagine that,  and obviously you can’t see them do this, because they’re paralyzed, so  you can’t see them actually move their arm. But while they do this task, you can record neural activity and you can basically offline model and  check, “Can I predict, or can I detect the modulation corresponding with those different actions?” And so we did that task and we realized,  “Hey, there’s actually some modulation associated with some of his hand  motion,” which was a first indication that, “okay, we can potentially  use that modulation to do useful things in the world.” For example,  control a computer cursor.        

05:16:24: And he started playing with it, the  first time we showed him it. And we actually just took the same live  view of his brain activity and put it in front of him and we said, “Hey, you tell us what’s going on? We’re not you. You’re able to imagine  different things, and we know that it’s modulating some of these  neurons, so you figure out for us, what that is actually representing.”  And so he played with it for a bit. He was like, “I don’t quite get it  yet.” He played for a bit longer and he said, “Oh, when I move this  finger, I see this particular neuron start to fire more.”        

05:16:51: And I said, “Okay, prove it. Do it  again.” And so he said, “Okay, three, two, one,” boom. And the minute he moved, you can see instantaneously this neuron is firing, single  neuron. I can tell you the exact channel number if you’re interested.  It’s stuck in my brain now forever. But that single channel firing was a beautiful indication that it was behaved really modulated, neural  activity, that could then be used for downstreaming tasks, like decoding a computer cursor.        

Lex Fridman: 05:17:15: And when you say single channel, is that associated with a single electrode?        

Bliss Chapman: 05:17:18: Yeah. Channel and electrode are interchangeable.        

Lex Fridman: 05:17:20: And there’s a 1,024 of those?        

Bliss Chapman: 05:17:23: 1,024. Yeah.        

Lex Fridman: 05:17:25: That’s incredible that, that works.  When I was learning about all this and loading it in, it was just  blowing my mind that the intention, you can visualize yourself moving  the finger. That can turn into a signal, and the fact that you can then  skip that step and visualize the cursor moving, or have the intention of the cursor moving. And that leading to a signal that can then be used  to move the cursor? There is so many exciting things there to learn  about the brain, about the way the brain works, the very fact of there  existing signal that can be used, is really powerful.        

Bliss Chapman: 05:18:03: Yep.        

Lex Fridman: 05:18:03: But it feels like that’s just the  beginning of figuring out how that signal could be used really, really  effectively? I should also just, there’s so many fascinating details  here, but you mentioned the body mapping step. At least in the version I saw, that Noland was showing off, there’s a super nice interface, a  graphical interface, but it just felt like I was in the future.        

05:18:28: I guess it visualizes you moving the  hand, and there’s a very sexy polished interface that, “Hello,” I don’t  know if there’s a voice component, but it just felt like when you wake  up in a really nice video game, and this is the tutorial at the  beginning of that video game. This is what you’re supposed to do. It’s  cool.        

Bliss Chapman: 05:18:50: No, I mean the future should feel like the future.        

Lex Fridman: 05:18:52: But it’s not easy to pull that off. I mean, it needs to be simple, but not too simple.        

Bliss Chapman: 05:18:57: Yeah. And I think the UX design  component here is underrated for BCI development in general. There’s a  whole interaction effect between the ways in which you visualize an  instruction to the user, and the kinds of signal you can get back. And  that quality of your behavioral alignment to the neural signal, is a  function of how good you are at expressing to the user what you want  them to do. And so yeah, we spend a lot of time thinking about the UX,  of how we build our applications, of how the decoder actually functions, the control surfaces it provides to the user. All these little details  matter a lot.        

## Neural signal

Lex Fridman: 05:19:27: So maybe it’d be nice to get into a little bit more detail of what the signal looks like, and what the decoding looks like?        

Bliss Chapman: 05:19:34: Yep.        

Lex Fridman: 05:19:34: So there’s a N1 implant that has, like we mentioned, 1,024 electrodes, and that’s collecting raw data, raw  signal. What does that signal look like? And what are the different  steps along the way before it’s transmitted, and what is transmitted?  All that kind of stuff.        

Bliss Chapman: 05:19:56: Yep. This is going to be a fun one. Grab the [inaudible 05:19:58].        

Lex Fridman: 05:19:58: Let’s go.        

Bliss Chapman: 05:19:59: So maybe before diving into what we  do, it’s worth understanding what we’re trying to measure, because that  dictates a lot of the requirements for the system that we build. And  what we’re trying to measure is really individual neurons, producing  action potentials. And action potential is, you can think of it like a  little electrical impulse that you can detect, if you’re close enough.  And by being close enough, I mean within let’s say 100 microns of that  cell. And 100 microns is a very, very tiny distance. And so the number  of neurons that you’re going to pick up with any given electrode, is  just a small radius around that electrode.        

05:20:33: And the other thing worth  understanding about the underlying biology here, is that when neurons  produce an action potential, the width of that action potential is about one millisecond. So from the start of the spike, to the end of the  spike, that whole width of that characteristic feature, of a neuron  firing, is one millisecond wide. And if you want to detect that an  individual spike is occurring or not, you need to sample that signal, or sample the local fuel potential nearby that a neuron… Much more  frequently than once a millisecond. You need to sample many, many times  per millisecond, to be able to detect that this is actually the  characteristic waveform of a neuron producing an action potential.        

05:21:07: And so we sample across all 1,024  electrodes, about 20,000 times a second. 20,000 times a second means for any given one millisecond window, we have about 20 samples that tell us what that exact shape of that actual potential looks like. And once  we’ve sort of sampled at super high rate the underlying electrical field nearby these cells, we can process that signal into just where do we  detect a spike, or where do we not? Sort of a binary signal, one or  zero. Do we detect a spike in this one millisecond or not?        

05:21:39: And we do that because the actual  information carrying subspace of neural activity, is just when our  spikes occurring. Essentially everything that we care about for decoding can be captured or represented in the frequency characteristics of  spike trains. Meaning, how often are spikes firing in any given window  of time. And so that allows us to do sort of a crazy amount of  compression, from this very rich high-density signal, to something  that’s much, much more sparse and compressible, that can be sent out  over a wireless radio. Like a Bluetooth communication for example.        

Lex Fridman: 05:22:14: Quick tangents here. You mentioned  electrode neuron, there’s a local neighborhood of neurons nearby. How  difficult is it to isolate from where the spike came from?        

Bliss Chapman: 05:22:30: So there’s a whole field of academic  neuroscience work on exactly this problem, of basically given a single  electrode, or given a set of electrodes measuring a set of neurons. How  can you sort, spike sort, which spikes are coming from what neuron? And  this is a problem that’s pursued in academic work, because you care  about it for understanding what’s going on in the underlying  neuroscience of the brain. If you care about understanding how the  brain’s representing information, how that’s evolving through time, then that’s a very, very important question to understand.        

05:23:02: For the engineering side of things, at least at the current scale, if the number of neurons per electrode is  relatively small, you can get away with basically ignoring that problem  completely. You can think of it like a random projection of neurons to  electrodes, and there may be in some cases more than one neuron per  electrode. But if that number is small enough, those signals can be  thought of as sort of a union of the two.        

05:23:25: And for many applications, that’s a  totally reasonable trade-off to make, and can simplify the problem a  lot. And as you sort of scale out channel count, the relevance of  distinguishing individual neurons becomes less important. Because you  have more overall signal, and you can start to rely on correlations or  covariate structure in the data to help understand when that channel is  firing… What does that actually represent? Because you know that when  that channel’s firing in concert with these other 50 channels, that  means move left. But when that same channel’s firing with concert with  these other 10 channels, that means move right.        

Lex Fridman: 05:23:53: Okay. So you have to do this kind of  spike detection onboard, and you have to do that super efficiently? So  fast, and not use too much power, because you don’t want to be  generating too much heat, so it’d have to be a super simple signal  processing step?        

Bliss Chapman: 05:24:09: Yep.        

Lex Fridman: 05:24:11: Is there some wisdom you can share about what it takes to overcome that challenge?        

Bliss Chapman: 05:24:17: Yeah. So we’ve tried many different  versions of basically turning this raw signal into a feature that you  might want to send off the device. And I’ll say that I don’t think we’re at the final step of this process, this is a long journey. We have  something that works clearly today, but there can be many approaches  that we find in the future that are much better than what we do right  now. So some versions of what we do right now, and there’s a lot of  academic heritage to these ideas, so I don’t want to claim that these  are original Neuralink ideas or anything like that.        

05:24:44: But one of these ideas is basically to build sort of like a convolutional filter almost, if you will. That  slides across the signal and looks for a certain template to be matched. That template consists of how deep the spike modulates, how much it  recovers, and what the duration and window of time is for that, the  whole process takes. And if you can see in the signal that, that  template is matched within certain bounds, then you can say, “Okay,  that’s a spike.” One reason that approach is super convenient, is that  you can actually implement that extremely efficiently in hardware. Which means that you can run it in low power across 1,024 channels all at  once.        

05:25:20: Another approach that we’ve recently  started exploring, and this can be combined with the spike detection  approach, is something called spike band power. And the benefits of that approach are that you may be able to pick up some signal from neurons  that are maybe too far away to be detected as a spike, because the  farther away you are from an electrode, the weaker that actual spike  waveform will look like on that electrode. So you might be able to pick  up population level activity of things that are maybe slightly outside  the normal recording radius… What neuroscientists sometimes refer to as  the hash of activity, the other stuff that’s going on. And you can look  at across many channels how that background noise is behaving, and you  might be able to get more juice out of the signal that way.        

05:25:59: But it comes at a cost. That signal is now a floating point representation, which means it’s more expensive to send out over a power. It means you have to find different ways to  compress it, that are different than what you can apply to binary  signals. So there’s a lot of different challenges associated with these  different modalities.        

Lex Fridman: 05:26:12: So also in terms of communication, you’re limited by the amount of data you can send?        

## Latency

Bliss Chapman: 05:26:17: Yeah.        

Lex Fridman: 05:26:17: And also because you’re currently  using the Bluetooth protocol, you have to batch stuff together? But you  have to also do this, keeping the latency crazy low? Crazy low? Anything to say about the latency?        

Bliss Chapman: 05:26:32: Yeah. This is a passion project of  mine. So I want to build the best mouse in the world. I don’t want to  build the Chevrolet Spark or whatever of electric cars. I want to build  the Tesla Roadster version of a mouse. And I really do think it’s quite  possible that within five to 10 years that most eSports competitions are dominated by people with paralysis.        

05:26:54: This is a very real possibility for a  number of reasons. One is that they’ll have access to the best  technology to play video games effectively. The second is they have the  time to do so. So those two factors together are particularly potent for eSport competitors.        

Lex Fridman: 05:27:07: Unless, people without paralysis are also allowed to implant N1?        

Bliss Chapman: 05:27:12: Right.        

Lex Fridman: 05:27:13: Which, it is another way to interact  with a digital device, and there’s something to that, if it’s a  fundamentally different experience, more efficient experience? Even if  it’s not like some kind of full-on high bandwidth communication, if it’s just the ability to move the mouse 10X faster, like the bits per  second? If I can achieve a bits per second at 10X what I can do with a  mouse, that’s a really interesting possibility of what that can do?  Especially as you get really good at it. With training.        

Bliss Chapman: 05:27:47: It’s definitely the case that you have a higher ceiling performance, because you don’t have to buffer your  intention through your arm, through your muscle. You get just by nature  of having a brain implant at all, like 75 millisecond lead time on any  action that you’re actually trying to take. And there’s some nuance to  this, there’s evidence that the motor cortex, you can sort of plan out  sequences of actions, so you may not get that whole benefit all the  time. But for reaction time style games, where you just want to…  Somebody’s over here, snipe them, that kind of thing? You actually do  have just an inherent advantage, because you don’t need to go through  muscle.        

05:28:18: So the question is, just how much  faster can you make it? And we’re already faster than what you would do  if you’re going through muscle from a latency point of view, and we’re  in the early stages of that. I think we can push it. So our end to end  latency right now from brain spike to cursor movement, it’s about 22  milliseconds. If you think about the best mice in the world, the best  gaming mice, that’s about five milliseconds ish of latency, depending on how you measure, depending how fast your screen refreshes, there’s a  lot of characteristics that matter there. And the rough time for a  neuron in the brain to actually impact your command of your hand is  about 75 milliseconds.        

05:28:50: So if you look at those numbers, you  can see that we’re already competitive and slightly faster than what  you’d get by actually moving your hand. And this is something that if  you ask Noland about it, when he moved the cursor for the first time… We asked him about this, it was something I was super curious about. “What does it feel like when you’re modulating a click intention, or when  you’re trying to just move the cursor to the right?” He said it moves  before he is actually intending it to. Which is kind of a surreal thing, and something that I would love to experience myself one day, what is  that like to have the thing just be so immediate, so fluid, that it  feels like it’s happening before you’re actually intending it to move?        

Lex Fridman: 05:29:25: Yeah. I suppose we’ve gotten used to  that latency, that natural latency that happens. So is currently the  bottleneck, the communication? So the Bluetooth communication? What’s  the actual bottleneck? I mean there’s always going to be a bottleneck,  what’s the current bottleneck?        

Bliss Chapman: 05:29:38: Yeah. A couple things. So kind of  hilariously, Bluetooth low- energy protocol has some restrictions on how fast you can communicate. So the protocol itself establishes a standard of the most frequent sort of updates you can send, are on the order of  7.5 milliseconds. And as we push latency down to the level of individual spikes impacting control, that level of resolution, that kind of  protocol is going to become a limiting factor at some scale.        

05:30:06: Another sort of important nuance to  this, is that it’s not just the Neuralink itself that’s part of this  equation. If you start pushing latency below the level of how fast  you’re going to refresh, then you have another problem. You need your  whole system to be able to be as reactive as the limits of what the  technology can offer.        

Lex Fridman: 05:30:24: Yes.        

Bliss Chapman: 05:30:26: 120 hertz just doesn’t work anymore,  if you’re trying to have something respond at something that’s at the  level of one millisecond.        

Lex Fridman: 05:30:32: That’s a really cool challenge. I also like that for a T-shirt, the best mouse in the world. Tell me on the  receiving end, so the decoding step? Now we figured out what the spikes  are, we’ve got them all together, now we’re sending that over to the  app. What’s the decoding step look like?        

Bliss Chapman: 05:30:49: Yeah. So maybe first, what is  decoding? I think there’s probably a lot of folks listening that just  have no clue what it means to decode brain activity.        

## Neuralink app

Lex Fridman: 05:30:56: Actually, even if we zoom out beyond  that, what is the app? So there’s an implant that’s wirelessly  communicating with any digital device that has an app installed.        

Bliss Chapman: 05:31:08: Yep.        

Lex Fridman: 05:31:08: So maybe can you tell me at high-level what the app is, what the software is outside of the brain?        

Bliss Chapman: 05:31:15: So maybe working backwards from the  goal. The goal is to help someone with paralysis. In this case, Noland.  Be able to navigate his computer independently. And we think the best  way to do that, is to offer them the same tools that we have to navigate our software. Because we don’t want to have to rebuild an entire  software ecosystem for the brain, at least not yet. Maybe someday you  can imagine there’s UXs that are built natively for BCI, but in terms of what’s useful for people today, I think most people would prefer to be  able to just control mouse and keyboard inputs, to all the applications  that they want to use for their daily jobs, for communicating with their friends, et cetera.        

05:31:47: And so the job of the application is  really to translate this wireless stream of brain data, coming off the  implant, into control of the computer. And we do that by essentially  building a mapping from brain activity to sort of the HID inputs, to the actual hardware. So HID is just the protocol for communicating like  input device events, so for example, move mouse to this position or  press this key down. And so that mapping is fundamentally what the app  is responsible for. But there’s a lot of nuance of how that mapping  works, and we spent a lot of time to try to get it right, and we’re  still in the early stages of a long journey to figure out how to do that optimally.        

05:32:21: So one part of that process is  decoding. So decoding is this process of taking the statistical patterns of brain data, that’s being channeled across this Bluetooth connection  to the application. And turning it into, for example, a mouse movement.  And that decoding step, you can think of it in a couple of different  parts. So similar to any machine learning problem, there’s a training  step, and there’s an [inaudible 05:32:39] step. The training step in our case is a very intricate behavioral process where the user has to  imagine doing different actions. So for example, they’ll be presented a  screen with a cursor on it, and they’ll be asked to push that cursor to  the right. Then imagine pushing that cursor to the left, push it up,  push it down. And we can basically build up a pattern or using any sort  of modern ML method of mapping of given this brain data, and then  imagine behavior, map one to the other.        

05:33:07: And then at test time you take that  same pattern matching system. In our case it’s a deep neural network,  and you run it and you take the live stream of brain data coming off  their implant, you decode it by pattern matching to what you saw at  calibration time, and you use that for a control of the computer. Now a  couple sort of rabbit holes that I think are quite interesting. One of  them has to do with how you build that best template matching system.  Because there’s a variety of behavioral challenges and also debugging  challenges when you’re working with someone who’s paralyzed.        

05:33:35: Because again, fundamentally you don’t observe what they’re trying to do, you can’t see them attempt to move  their hand. And so you have to figure out a way to instruct the user to  do something, and validate that they’re doing it correctly, such that  then you can downstream, build with confidence, the mapping between the  neural spikes and the intended action.        

05:33:53: And by doing the action correctly,  what I really mean is, at this level of resolution of what neurons are  doing. So if, in ideal world, you could get a signal of behavioral  intent that is ground truth accurate at the scale of one millisecond  resolution, then with high confidence, I could build a mapping from my  neural spikes, to that behavioral intention. But the challenge is again, that you don’t observe what they’re actually doing. And so there’s a  lot of nuance to how you build user experiences, that give you more than just a course on average correct representation of what the user’s  intending to do.        

05:34:24: If you want to build the world’s best  mouse, you really want it to be as responsive as possible. You want it  to be able to do exactly what the user’s intending, at every step along  the way, not just on average be correct, when you’re trying to move it  from left to right. And building a behavioral calibration game, or our  software experience, that gives you that level of resolution, is what we spend a lot of time working on.        

Lex Fridman: 05:34:44: So the calibration process, the  interface, has to encourage precision. Meaning whatever it does, it  should be super intuitive that the next thing the human is going to  likely do, is exactly that intention that you need, and only that  intention?        

Bliss Chapman: 05:34:45: Yeah.        

Lex Fridman: 05:35:03: And you don’t have any feedback except that may be speaking to you afterwards, what they actually did, you can’t… Oh, yeah.        

Bliss Chapman: 05:35:11: Right.        

Lex Fridman: 05:35:11: So that’s fundamentally, that is a  really exciting UX challenge. Because that’s all on the UX, it’s not  just about being friendly or nice or usable.        

Bliss Chapman: 05:35:23: Yep.        

Lex Fridman: 05:35:23: It’s like-        

Bliss Chapman: 05:35:24: User experience is how it works.        

Lex Fridman: 05:35:24: … it’s how it works, for the  calibration. And calibration, at least at this stage of Neuralink is  fundamental to the operation of the thing? And not just calibration, but continued calibration essentially?        

Bliss Chapman: 05:35:39: Yeah.        

## Intention vs action

Lex Fridman: 05:35:40: Wow, yeah.        

Bliss Chapman: 05:35:40: You said something that I think is  worth exploring there a little bit. You said it’s primarily a UX  challenge, and I think a large component of it is, but there is also a  very interesting machine learning challenge here. Which is given some  dataset, including some on average correct behavior, of asking the user  to move up, or move down, move right, move left, and given a dataset of  neural spikes. Is there a way to infer, in some kind of semi-supervised, or entirely unsupervised way, what that high resolution version of  their intention is?        

05:36:10: And if you think about it, there  probably is, because there are enough data points in the dataset, enough constraints on your model. That there should be a way with the right  sort of formulation, to let the model figure out itself, for example… At this millisecond, this is exactly how hard they’re pushing upwards, and at this millisecond, this is how hard they’re trying to push upwards.        

Lex Fridman: 05:36:27: It’s really important to have very  clean labels, yes? So the problem becomes much harder from the machine  learning perspective if the labels are noisy?        

Bliss Chapman: 05:36:35: That’s correct.        

Lex Fridman: 05:36:36: And then to get the clean labels, that’s a UX challenge?        

Bliss Chapman: 05:36:40: Correct. Although clean labels, I  think maybe it’s worth exploring what that exactly means. I think any  given labeling strategy will have some number of assumption to make,  about what the user is attempting to do. Those assumptions can be  formulated in a loss function, or they can be formulated in terms of  heuristics that you might use, to just try to estimate or guesstimate  what the user’s trying to do. And what really matters is, how accurate  are those assumptions? For example, you might say, “Hey, user, push  upwards and follow the speed of this cursor.” And your heuristic might  be that they’re trying to do exactly what that cursor is trying to do.        

05:37:10: Another competing heuristic might be,  they’re actually trying to go slightly faster at the beginning of the  movement and slightly slower at the end. And those competing heuristics  may or may not be accurate reflections of what the user is trying to do. Another version of the task might be, “Hey, user, imagine moving this  cursor a fixed offset.” So rather than follow the cursor, just try to  move it exactly 200 pixels to the right. So here’s the cursor, here’s  the target, okay, cursor disappears, try to move that now invisible  cursor, 200 pixels to the right. And the assumption in that case would  be that the user can’t actually modulate correctly that position offset.        

05:37:41: But that position offset assumption  might be a weaker assumption, and therefore potentially, you can make it more accurate, than these heuristics that are trying to guesstimate at  each millisecond what the user’s trying to do. So you can imagine  different tasks that make different assumptions about the nature of the  user intention. And those assumptions being correct is what I would  think of as a clean label.        

Lex Fridman: 05:37:59: For that step, what are we supposed to be visualizing? There’s a cursor, and you want to move that cursor to  the right, or the left, or up and down, or maybe move them by a certain  offset. So that’s one way. Is that the best way to do calibration?        

05:38:13: So for example, an alternative crazy  way that probably is playing a role here, is a game like WEG Grid. Where you’re just getting a very large amount of data, the person playing a  game. Where if they’re in a state of flow, maybe you can get clean  signal as a side effect?        

Bliss Chapman: 05:38:33: Yep.        

Lex Fridman: 05:38:34: Or is that not an effective way for initial calibration?        

Bliss Chapman: 05:38:38: Yeah. Great question. There’s a lot to unpack there. So the first thing I would draw a distinction between is, open loop versus closed loop. So open loop, what I mean by that is, the user is sort of going from zero to one. They have no model at all, and  they’re trying to get to the place where they have some level of  control, at all. In that setup, you really need to have some task that  gives the user a hint of what you want them to do, such that you can  build its mapping again, from brain data to output. Then once they have a model, you could imagine them using that model and actually adapting to it, and figuring out the right way to use it themself. And then  retraining on that data to give you sort of a boost in performance.        

05:39:14: There’s a lot of challenges associated with both of these techniques, and we can rabbit hole into both of them if you’re interested. But the sort of challenge with the open loop task is that the user themself doesn’t get proprioceptive feedback about  what they’re doing. They don’t necessarily perceive themself or feel the mouse under their hand, when they’re trying to do an open loop  calibration. They’re being asked to perform something… Imagine if you  sort of had your whole right arm numbed, and you stuck it in a box and  you couldn’t see it, so you had no visual feedback and you had no  proprioceptive feedback, about what the position or activity of your arm was.        

05:39:47: And now you’re asked, “Okay, given  this thing on the screen, that’s moving from left to right, match that  speed?” And you basically can try your best to invoke whatever that  imagined action is in your brain, that’s moving the cursor from left to  right. But in any situation, you’re going to be inaccurate and maybe  inconsistent in how you do that task. And so that’s sort of the  fundamental challenge of open loop. The challenge with closed loop is  that once the user’s given a model, and they’re able to start moving the mouse on their own, they’re going to very naturally adapt to that  model. And that coadaptation between the model learning what they’re  doing, and the user learning how to use the model, may not find you the  best sort of global minima.        

05:40:25: And maybe that your first model was  noisy in some ways, or maybe just had some quirk. There’s some part of  the data distribution, it didn’t cover super well, and the user now  figures out, because they’re a brilliant user like Noland, they figure  out the right sequence of imagined motions, or the right angle they have to hold their hand at to get it to work. And they’ll get it to work  great, but then the next day they come back to their device, and maybe  they don’t remember exactly all the tricks that they used the previous  day. And so there’s a complicated sort of feedback cycle here that can  emerge, and can make it a very, very difficulty debugging process.        

Lex Fridman: 05:40:56: Okay. There’s a lot of really  fascinating things there. Actually, just to stay on the closed loop…  I’ve seen situations, this actually happened watching psychology grad  students. They used a piece of software and they don’t know how to  program themselves. They used a piece of software that somebody else  wrote, and it has a bunch of bugs, and they’ve been using it for years.  They figure out ways to walk around, “Oh, that just happens.” Nobody  considers, “Maybe we should fix this.” They just adapt. And that’s a  really interesting notion, that we’re really good at it adapting, but  that might not be the optimal?        

Bliss Chapman: 05:41:39: Yeah.        

Lex Fridman: 05:41:39: Okay. So how do you solve that problem? Do you have to restart from scratch every once in a while, kind of thing?        

Bliss Chapman: 05:41:44: Yeah. It’s a good question. First and  foremost, I would say this is not a solve problem. And for anyone who’s  listening in academia who works on BCIs, I would also say this is not a  problem that’s solved by simply scaling channel count. So maybe that can help, and you can get sort of richer covariant structures that you can  use to exploit, when trying to come up with good labeling strategies.  But if you’re interested in problems that aren’t going to be solved  inherently by scaling channel count, this is one of them.        

05:42:08: Yeah. So how do you solve it? It’s not a solve problem. That’s the first thing I want to make sure it gets  across. The second thing is, any solution that involves closed loop is  going to become a very difficult debugging problem. And one of my  general heuristics for choosing what prompts to tackle is, that you want to choose the one that’s going to be the easiest to debug. Because if  you can do that, even if the ceiling is lower, you’re going to be able  to move faster, because you have a tighter iteration loop debugging the  problem.        

05:42:34: In the open loop setting, there’s not a feedback cycle to debug with the user in the loop. And so there’s some  reason to think that, that should be an easier debugging problem. The  other thing that’s worth understanding is that even in the closed loop  setting, there’s no special software magic of how to infer what the user is truly attempting to do. In the closed loop setting, although they’re moving the cursor on the screen, they may be attempting something  different than what your model is outputting. So what the model is  outputting is not a signal that you can use to retrain if you want to be able to improve the model further. You still have this very complicated guestimation, or unsupervised problem of figuring out what is the true  user intention underlying that signal?        

05:43:09: And so the open loop problem has the  nice property of being easy to debug, and the second nice property of,  it has all the same information and content as the closed loop scenario. Another thing I want to mention and call out, is that this problem  doesn’t need to be solved in order to give useful control to people.  Even today with the solutions we have now, and that academia has built  up over decades, the level of control that can be given to a user today, is quite useful. It doesn’t need to be solved to get to that level of  control.        

05:43:38: But again, I want to build the world’s best mouse. I want to make it so good that it’s not even a question  that you want it. And to build the world’s best mouse, the superhuman  version, you really need to nail that problem. And a couple maybe  details of previous studies that we’ve done internally, that I think are very interesting to understand, when thinking about how to solve this  problem. The first is that even when you have ground-truth data of what  the user’s trying to do, and you can get this with an able-bodied  monkey, a monkey that has a Neuralink device implanted, and moving a  mouse to control a computer. Even with that ground-truth dataset, it  turns out that the optimal thing to predict to produce high performance  BCI, is not just the direct control of the mouse.        

05:44:18: You can imagine building a dataset of  what’s going on in the brain, and what is the mouse exactly doing on the table? And it turns out that if you build the mapping from neurospikes  to predict exactly what the mouse is doing, that model will perform  worse, than a model that is trained to predict higher level assumptions  about what the user might be trying to do. For example, assuming that  the monkey is trying to go in a straight line to the target, it turns  out that making those assumptions is actually more effective in  producing a model, than actually predicting the underlying hand  movement.        

Lex Fridman: 05:44:45: So the intention, not the physical movement, or whatever?        

Bliss Chapman: 05:44:48: Yeah.        

Lex Fridman: 05:44:48: There’s obviously a really strong correlation between the two, but the intention is a more powerful thing to be chasing?        

Bliss Chapman: 05:44:54: Right.        

Lex Fridman: 05:44:55: Well, that’s also super interesting. I mean, the intention itself is fascinating because yes, with the BCI  here in this case with the digital telepathy, you’re acting on the  intention, not the action. Which is why there’s an experience of feeling like it’s happening before you meant for it to happen? That is so cool. And that is why you could achieve superhuman performance problem, in  terms of the control of the mouse? So for open loop, just to clarify, so whenever the person is tasked to move the mouse to the right, you said  there’s not feedback, so they don’t get to get that satisfaction of  actually getting it to move? Right?        

Bliss Chapman: 05:45:38: So you could imagine giving the user  feedback on a screen, but it’s difficult, because at this point you  don’t know what they’re attempting to do. So what can you show them that would basically give them a signal of, “I’m doing this correctly or not correctly?” So let’s take a very specific example. Maybe your  calibration task looks like you’re trying to move the cursor, a certain  position offset. So your instructions to the user are, “Hey, the  cursor’s here. Now when the cursor disappears, imagine you’re moving it  200 pixels from where it was, to the right to be over this target.”        

05:46:05: In that kind of scenario, you could  imagine coming up with some sort of consistency metric that you could  display to the user of, “Okay, I know what the spike trend looks like on average when you do this action to the right. Maybe I can produce some  sort of probabilistic estimate of how likely is that to be the action  you took, given the latest trial or trajectory that you imagined?” And  that could give the user some sort of feedback of how consistent are  they, across different trials.        

05:46:27: You could also imagine that if the  user is prompted with that kind of consistency metric, that maybe they  just become more behaviorally engaged to begin with, because the task is kind of boring when you don’t have any feedback at all. And so there  may be benefits to the user experience of showing something on the  screen, even if it’s not accurate. Just because it keeps the user  motivated to try to increase that number, or push it upwards.        

Lex Fridman: 05:46:48: So there’s this psychology element here?        

Bliss Chapman: 05:46:50: Yeah. Absolutely.        

## Calibration

Lex Fridman: 05:46:52: And again, all of that is UX  challenge? How much signal drift is there hour-to-hour, day-to-day,  week-to-week, month-to-month? How often do you have to recalibrate  because of the signal drift?        

Bliss Chapman: 05:47:06: Yeah. So this is a problem we’ve  worked on both with NHP, non-human primates, before our clinical trial,  and then also with Noland during the clinical trial. Maybe the first  thing that’s worth stating is what the goal is here. So the goal is  really to enable the user to have a plug and play experience… Well, I  guess they don’t have to plug anything in, but a play experience where  they can use the device whenever they wanted, however they want to. And  that’s really what we’re aiming for. And so there can be a set of  solutions that get to that state without considering this non-stationary problem.        

05:47:38: So maybe the first solution here  that’s important, is that they can recalibrate whenever they want. This  is something that Noland has the ability to do today, so he can  recalibrate the system at 2:00 AM, in the middle of the night without  his caretaker, or parents or friends around, to help push a button for  him. The other important part of the solution is that when you have a  good model calibrated, that you can continue using that without needing  to recalibrate it. So how often he has to do this recalibration to-date, depends really on his appetite for performance.        

05:48:06: We observe sort of a degradation  through time, of how well any individual model works, but this can be  mitigated behaviorally by the user adapting their control strategy. It  can also be mitigated through a combination of software features that we provide to the user. For example, we let the user adjust exactly how  fast the cursor is moving. We call that the gain, for example, the gain  of how fast the cursor reacts to any given input intention.        

05:48:27: They can also adjust the smoothing,  how smooth the output of that cursor intention actually is. That can  also adjust the friction, which is how easy is it to stop and hold  still? And all these software tools allow the user a great deal of  flexibility and troubleshooting mechanisms to be able to solve this  problem for themselves.        

Lex Fridman: 05:48:42: By the way, all of this is done by looking to the right side of the screen, selecting the mixer. And the mixer you have, it’s-        

Bliss Chapman: 05:48:48: Like DJ mode. DJ mode for your BCI.        

Lex Fridman: 05:48:52: I mean, it’s a really well done  interface. It’s really, really well done. And so there’s that bias that  there’s a cursor drift that Noland talked about in a stream. Although he said that you guys were just playing around with it with him, and then  constantly improving. So that could have been just a snapshot of that  particular moment, a particular day, where he said that there was this  cursor drift and this bias that could be removed by him. I guess,  looking to the right side of the screen, or left side of the screen, to  adjust the bias?        

Bliss Chapman: 05:49:25: Yeah, yeah.        

Lex Fridman: 05:49:25: That’s one interface action, I guess, to adjust the bias?        

Bliss Chapman: 05:49:28: Yeah. So this is actually an idea that comes out of academia. There is some prior work with BrainGate clinical trial participants where they pioneered this idea of bias correction.  The way we’ve done it, I think is, it’s very prioritized, very beautiful user experience. Where the user can essentially flash the cursor over  to the side of the screen, and it opens up a window, where they can  actually adjust or tune exactly the bias of the cursor. So bias, maybe  for people who aren’t familiar, is just sort of what is the default  motion of the cursor, if you’re imagining nothing? And it turns out  that, that’s one of the first sort-        

Bliss Chapman: 05:50:00: … and it turns out that that’s one of  the first qualia of the cursor control experience that’s impacted by  neuron [inaudible 05:50:07]        

Lex Fridman: 05:50:07: Qualia of the cursor experience.        

Bliss Chapman: 05:50:08: I mean, I don’t know how else to describe it. I’m not the guy moving thing.        

Lex Fridman: 05:50:14: It’s very poetic. I love it. The  qualia of the cursor experience. Yeah, I mean it sounds poetic, but it  is deeply true. There is an experience. When it works well, it is a  joyful… A really pleasant experience. And when it doesn’t work well,  it’s a very frustrating experience. That’s actually the art of UX, you  have the possibility to frustrate people, or the possibility to give  them joy.        

Bliss Chapman: 05:50:40: And at the end of the day, it really  is truly the case that UX is how the thing works. And so it’s not just  what’s showing on the screen, it’s also, what control surfaces does a  decoder provide the user? We want them to feel like they’re in the F1  car, not like some minivan. And that really truly is how we think about  it. Noland himself is an F1 fan. We refer to ourself as a pit crew, he  really is truly the F1 driver. And there’s different control surfaces  that different kinds of cars and airplanes provide the user, and we take a lot of inspiration from that when designing how the cursor should  behave.        

05:51:11: And maybe one nuance of this is, even  details like when you move a mouse on a MacBook trackpad, the sort of  response curve of how that input that you give the trackpad translates  to cursor movement is different than how it works with a mouse. When you move on the trackpad, there’s a different response function, a  different curve to how much a movement translates to input to the  computer than when you do it physically with a mouse. And that’s because somebody sat down a long time ago, when they’re designing the initial  input systems to any computer, and they thought through exactly how it  feels to use these different systems. And now we’re designing the next  generation of this, input system to a computer, which is entirely done  via the brain, and there’s no proprioceptive feedback, again, you don’t  feel the mouse in your hand, you don’t feel the keys under your  fingertips, and you want a control surface that still makes it easy and  intuitive for the user to understand the state of the system, and how to achieve what they want to achieve. And ultimately the end goal is that  that UX is completely… It fades in the background, it becomes something  that’s so natural and intuitive that it’s subconscious to the user, and  they just should feel like they have basically direct control over the  cursor, just does what they want it to do. They’re not thinking about  the implementation of how to make it do what they want it to do, it’s  just doing what they want it to do.        

Lex Fridman: 05:52:17: Is there some kind of things along the lines of like Fitt’s Law, where you should move the mouse in a certain  kind of way that maximizes your chance to hit the target? I don’t even  know what I’m asking, but I’m hoping the intention of my question will  land on a profound answer. No. Is there some kind of understanding of  the laws of UX when it comes to the context of somebody using their  brain to control it that’s different than with a mouse?        

Bliss Chapman: 05:52:55: I think we’re in the early stages of  discovering those laws, so I wouldn’t claim to have solved that problem  yet, but there’s definitely some things we’ve learned that make it  easier for the user to get stuff done. And it’s pretty straightforward  when you verbalize it, but it takes a while to actually get to that  point, when you’re in the process of debugging the stuff in the  trenches.        

05:53:14: One of those things is that any  machine learning system that you build has some number of errors, and it matters how those errors translate to the downstream user experience.  For example, if you’re developing a search algorithm in your photos, if  you search for your friend, Joe, and it pulls up a photo of your friend, Josephine, maybe that’s not a big deal, because the cost of an error is not that high. In a different scenario, where you’re trying to detect  insurance fraud or something like this, and you’re directly sending  someone to court because of some machine learning model output, then the errors make a lot more sense to be careful about, you want to be very  thoughtful about how those errors translate to downstream effects.        

05:53:53: The same is true in BCI. So for  example, if you’re building a model that’s decoding a velocity output  from the brain, versus an output where you’re trying to modulate the  left click for example, these have sort of different trade-offs of how  precise you need to be before it becomes useful to the end user. For  velocity, it’s okay to be on average correct, because the output of the  model is integrated through time. So if the user’s trying to click at  position A, and they’re currently position B, they’re trying to navigate over time to get between those two points. And as long as the output of the model is on average correct, they can sort of steer it through  time, with the user control loop in the mix, they can get to the point  they want to get to.        

05:54:29: The same is not true of a click. For a click, you’re performing it almost instantly, at the scale of neurons  firing. And so you want to be very sure that that click is correct,  because a false click can be very destructive to the user. They might  accidentally close the tab that they’re trying to do something in, and  lose all their progress. They might accidentally hit some send button on some text that there’s only half composed and reads funny after. So  there’s different sort of cost functions associated with errors in this  space, and part of the UX design is understanding how to build a  solution that is, when it’s wrong, still useful to the end user.        

Lex Fridman: 05:55:02: It’s so fascinating, assigning cost to every action when an error occurs. So every action, if an error occurs, has a certain cost, and incorporating that into how you interpret the  intention, mapping it to the action is really important. I didn’t quite, until you said it, realize there’s a cost to sending the text early.  It’s a very expensive cost.        

Bliss Chapman: 05:55:32: Yeah, it’s super annoying if you  accidentally… Imagine if your cursor misclicked every once in a while.  That’s super obnoxious. And the worst part of it is, usually when the  user’s trying to click, they’re also holding still, because they’re over the target they want to hit, and they’re getting ready to click, which  means that in the datasets that we build, on average is the case that  sort of low speeds, or desire to hold still, is correlated with when the user’s attempting to click.        

Lex Fridman: 05:55:54: Wow, that is really fascinating.        

Bliss Chapman: 05:55:58: People think that, “Oh, a click is a  binary signal, this must be super easy to decode.” Well, yes, it is, but the bar is so much higher for it to become a useful thing for the user. And there’s ways to solve this. I mean, you can sort of take the  compound approach of, “Well, let’s take five seconds to click. Let’s  take a huge window of time, so we can be very confident about the  answer.” But again, world’s best mouse. The world’s best mouse doesn’t  take a second to click, or 500 milliseconds to click, it takes five  milliseconds to click or less. And so if you’re aiming for that kind of  high bar, then you really want to solve the underlying problem.        

## Webgrid

Lex Fridman: 05:56:26: So maybe this is a good place to ask  about how to measure performance, this whole bits per second. Can you  explain what you mean by that? Maybe a good place to start is to talk  about Webgrid as a game, as a good illustration of the measurement of  performance.        

Bliss Chapman: 05:56:43: Yeah. Maybe I’ll take one zoom out  step there, which is just explaining why we care to measure this at all. So again, our goal is to provide the user the ability to control the  computer as well as I can, and hopefully better. And that means that  they can do it at the same speed as what I can do, it means that they  have access to all the same functionality that I have, including all  those little details like command tab, command space, all this stuff,  they need to be able to do it with their brain, and with the same level  of reliability as what I can do with my muscles. And that’s a high bar,  and so we intend to measure and quantify every aspect of that to  understand how we’re progressing towards that goal.        

05:57:13: There’s many ways to measure BPS by  the way, this isn’t the only way, but we present the user a grid of  targets, and basically we compute a score which is dependent on how fast and accurate they can select, and then how small are the targets. And  the more targets that are on the screen, the smaller they are, the more  information you present per click. And so if you think about it from  information theory point of view, you can communicate across different  information theoretic channels, and one such channel is a typing  interface, you can imagine, that’s built out of a grid, just like a  software keyboard on the screen.        

05:57:41: And bits per second is a measure  that’s computed by taking the log of the number of targets on the  screen. You can subtract one if you care to model a keyboard, because  you have to subtract one for the delete key on the keyboard. But log of  the number of targets on the screen, times the number of correct  selections, minus incorrect, divided by some time window, for example,  60 seconds. And that’s sort of the standard way to measure a cursor  control task in academia. And all credit in the world goes to this great professor, Dr. Shenoy of Stanford who came up with that task, and he’s  also one of my inspirations for being in the field. So all the credit in the world to him for coming up with a standardized metric to facilitate this kind of bragging rights that we have now to say that Noland is the best in the world at this task with this BCI. It’s very important for  progress that you have standardized metrics that people can compare  across. Different techniques and approaches, how well does this do? So  big kudos to him and to all the team at Stanford.        

05:58:29: Yeah, so for Noland, and for me  playing this task, there’s also different modes that you can configure  this task. So the Webgrid task can be presented as just sort of a left  click on the screen, or you could have targets that you just dwell over, or you could have targets that you left, right click on, you could have targets that are left, right click, middle click, scrolling, clicking  and dragging. You can do all sorts of things within this general  framework, but the simplest, purest form is just blue targets show up on the screen, blue means left click. That’s the simplest form of the  game.        

05:58:56: And the sort of prior records here in  academic work and at Neuralink internally with NHPs have all been  matched or beaten by Noland with his Neuralink device. So prior to  Neuralink, the world record for a human using device is somewhere  between 4.2 to 4.6 BPS, depending on exactly what paper you read and how you interpret it. Noland’s current record is 8.5 BPS. and again, this  sort of median Neuralinker performance is 10 BPS. So you can think of it roughly as, he’s 85% the level of control of a median Neuralinker using their cursor to select blue targets on the screen.        

05:59:35: I think there’s a very interesting  journey ahead to get us to that same level of 10 BPS performance. It’s  not the case that the tricks that got us from 4 to 6 BPS, and then 6 to 8 BPS are going to be the ones that get us from 8 to 10. And in my view,  the core challenge here is really the labeling problem. It’s how do you  understand, at a very, very fine resolution, what the user’s attempting  to do? And I highly encourage folks in academia to work on this problem.        

Lex Fridman: 06:00:01: What’s the journey with Noland on that quest of increasing the BPS on Webgrid? In March, you said that he  selected 89,285 targets in Webgrid. So he loves this game, he’s really  serious about improving his performance in this game. So what is that  journey of trying to figure out how to improve that performance? How  much can that be done on the decoding side? How much can that be done on the calibration side? How much can that be done on the Noland side of  figuring out how to convey his intention more cleanly?        

Bliss Chapman: 06:00:36: Yeah. No, this is a great question. So in my view, one of the primary reasons why Noland’s performance is so  good is because of Noland. Noland is extremely focused and very  energetic. He’ll play Webgrid sometimes for four hours in the middle of  the night. From 2:00 A.M. To 6:00 A.M. he’ll be playing Webgrid, just  because he wants to push it to the limits of what he can do. This is not us asking him to do that, I want to be clear. We’re not saying, ” Hey,  you should play Webgrid tonight.” We just gave him the game as part of  our research, and he is able to play it independently, and practice  whenever he wants, and he really pushes hard to push it, the  technology’s absolute limit. And he views that as his job, really, to  make us be the bottleneck. And boy, has he done that well.        

06:01:16: And so the first thing to acknowledge  is that he’s extremely motivated to make this work. I’ve also had the  privilege to meet other clinical trial participants from BrainGate and  other trials, and they very much shared the same attitude of, they  viewed this as their life’s work to advance the technology as much as  they can. And if that means selecting targets on the screen for four  hours from 2:00 A.M. to 6:00 A.M., then so be it. And there’s something  extremely admirable about that that’s worth calling out.        

06:01:42: Okay, so then how do you get from  where he started, which is no cursor control to eight BPS? I mean, when  he started, there’s a huge amount of learning to do on his side and our  side to figure out what’s the most intuitive control for him. And the  most intuitive control for him is, you have to find the set intersection of, “Do we have the signal to decode?” So we don’t pick up every single neuron in the motor cortex, which means we don’t have representation  for every part of the body. So there may be some signals that we have  better decode performance on than others. For example, on his left hand, we have a lot of difficulty distinguishing his left ring finger from  his left middle finger, but on his right hand, we have a good control  and good modulation detected from the neurons that were able to record  for his pinky, and his thumb, and his index finger. So you can imagine  how these different subspaces of modulated activity intersect with  what’s the most intuitive for him.        

06:02:32: And this has evolved over time, so  once we gave him the ability to calibrate models on his own, he was able to go and explore various different ways to imagine controlling the  cursor. For example, he can imagine controlling the cursor by wiggling  his wrist side to side, or by moving his entire arm, by… I think at one  point he did his feet. He tried a whole bunch of stuff to explore the  space of what is the most natural way for him to control the cursor,  that at the same time, it’s easy for us to decode-        

Lex Fridman: 06:02:54: Just to clarify, it’s through the body mapping procedure there, you’re able to figure out which finger he can move?        

Bliss Chapman: 06:03:02: Yes. Yeah, that’s one way to do it.  Maybe one nuance of the… When he’s doing it, he can imagine many more  things than we represent in that visual on the screen. So we show him,  sort of abstractly, “Here’s a cursor. You figure out what works the best for you.” And we obviously have hints about what will work best from  that body mapping procedure, of, “We know that this particular action we can represent well.” But it’s really up to him to go and explore and  figure out what works the best.        

Lex Fridman: 06:03:27: But at which point does he no longer visualize the movement of his body, and is just visualizing the movement of the cursor?        

Bliss Chapman: 06:03:33: Yeah.        

Lex Fridman: 06:03:34: How quickly does he get there?        

Bliss Chapman: 06:03:37: So this happened on a Tuesday. I  remember this day very clearly, because at some point during the day, it looked like he wasn’t doing super well, it looked like the model wasn’t performing super well, and he was getting distracted, but actually, it  wasn’t the case. What actually happened was, he was trying something  new, where he was just controlling the cursor, so he wasn’t imagining  moving his hand anymore, he was just imagining… I don’t know what it is, some abstract intention to move the cursor on the screen, and I cannot  tell you what the difference between those two things are, I truly  cannot. He’s tried to explain it to me before, I cannot give a  first-person account of what that’s like. But the expletives that he  uttered in that moment were enough to suggest that it was a very  qualitatively different experience for him to just have direct neural  control over a cursor.        

Lex Fridman: 06:04:23: I wonder if there’s a way through UX  to encourage a human being to discover that, because he discovered it…  Like you said to me, that he’s a pioneer. So he discovered that on his  own through all of this, the process of trying to move the cursor with  different kinds of intentions. But that is clearly a really powerful  thing to arrive at, which is to let go of trying to control the fingers  and the hand, and control the actual digital device with your mind.        

Bliss Chapman: 06:04:56: That’s right. UX is how it works. And  the ideal UX is one that the user doesn’t have to think about what they  need to do in order to get it done, it just does it.        

Lex Fridman: 06:05:05: That is so fascinating. But I wonder,  on the biological side, how long it takes for the brain to adapt. So is  it just simply learning high level software, or is there a  neuroplasticity component where the brain is adjusting slowly?        

Bliss Chapman: 06:05:25: Yeah. The truth is, I don’t know. I’m  very excited to see with sort of the second participant that I implant,  what the journey is like for them, because we’ll have learned a lot  more, potentially, we can help them understand and explore that  direction more quickly. This wasn’t me prompting Noland to go try this,  he was just exploring how to use his device and figured it out himself.  But now that we know that that’s a possibility, that maybe there’s a way to, for example, hint the user, “Don’t try super hard during  calibration, just do something that feels natural.” Or, “Just directly  control the cursor. Don’t imagine explicit action.” And from there, we  should be able to hopefully understand how this is for somebody who has  not experienced that before. Maybe that’s the default mode of operation  for them, you don’t have to go through this intermediate phase of  explicit motions.        

Lex Fridman: 06:06:07: Or maybe if that naturally happens for people, you can just occasionally encourage them to allow themselves to move the cursor.        

Bliss Chapman: 06:06:14: Right.        

Lex Fridman: 06:06:14: Actually, sometimes, just like with a four-minute mile, just the knowledge that that’s possible-        

Bliss Chapman: 06:06:19: Yes, pushes you to do it.        

Lex Fridman: 06:06:19: Yeah.        

Bliss Chapman: 06:06:20: Yeah.        

Lex Fridman: 06:06:21: Enables you to do it, and then it  becomes trivial. And then it also makes you wonder, this is the cool  thing about humans, once there’s a lot more human participants, they  will discover things that are possible.        

Bliss Chapman: 06:06:32: Yes. And share their experiences probably with each other.        

Lex Fridman: 06:06:34: Yeah, and share. And that because of  them sharing it, they’ll be able to do it. All of a sudden that’s  unlocked for everybody, because just the knowledge sometimes is the  thing that enables you to do it.        

Bliss Chapman: 06:06:46: Yeah. Just to comment on that too,  we’ve probably tried 1,000 different ways to do various aspects of  decoding, and now we know what the right subspace is to continue  exploring further. Again, thanks to Noland and the many hours he’s put  into this. And so even just that, help constraints, or the beam search  of different approaches that we could explore really helps accelerate  for the next person the set of things that we’ll get to try on day one,  how fast we hopefully get them to use for control, how fast we can  enable them to use it independently, and to get value out of the system. So massive hats off to Noland and all the participants that came before to make this technology a reality.        

Lex Fridman: 06:07:20: So how often are the updates to the  decoder? ‘Cause Noland mentioned, “Okay, there’s a new update that we’re working on.” In the stream he said he plays the snake game, because  it’s super hard, it’s a good way for him to test how good the update is. And he says sometimes the update is a step backwards, it’s a constant  iteration. What does the update entail? Is it mostly on the decoder  side?        

Bliss Chapman: 06:07:48: Yeah. Couple of comments. So, one,  it’s probably worth drawing distinction between research sessions where  we’re actively trying different things to understand what the best  approach is, versus independent use, where we wanted to have ability to  just go use the device how anybody would want to use their MacBook. So  what he’s referring to is, I think, usually in the context of a research session, where we’re trying many, many different approaches to… Even  unsupervised approaches, like we talked about earlier, to try to come up with better ways to estimate his true intention, and more accurately  decoded.        

06:08:15: And in those scenarios, we try, in any given session… He’ll sometimes work for eight hours a day, and so that  can be hundreds of different models that we would try in that day. A lot of different things. Now, it’s also worth noting that we update the  application he uses quite frequently, I think sometimes up to 4 or 5  times a day, we’ll update his application with different features, or  bug fixes, or feedback that he’s given us.        

06:08:39: He’s a very articulate person who is  part of the solution, he’s not a complaining person, he says, “Hey,  here’s this thing that I’ve discovered is not optimal in my flow. Here’s some ideas how to fix it. Let me know what your thoughts are, let’s  figure out how to solve it.” And it often happens that those things are  addressed within a couple of hours of him giving us his feedback, that’s the kind of iteration cycle we’ll have. And so sometimes at the  beginning of the session, he’ll give us feedback, and at the end of the  session he’s giving us feedback on the next iteration of that process or that setup.        

Lex Fridman: 06:09:06: That’s fascinating, ’cause one of the  things you mentioned that there was 271 pages of notes taken from the  BCI sessions, and this was just in March. So one of the amazing things  about human beings that they can provide… Especially ones who are smart, and excited, and all positive and good vibes like Noland, that they can provide feedback, continuous feedback.        

Bliss Chapman: 06:09:27: Yeah. Just to brag on the team a  little bit, I work with a lot of exceptional people, and it requires the team being absolutely laser-focused on the user, and what will be the  best for them. And it requires a level of commitment of, “Okay, this is  what the user feedback was. I have all these meetings, we’re going to  skip that today, and we’re going to do this.” That level of focus and  commitment is, I would say, underappreciated in the world. And also, you obviously have to have the talent to be able to execute on these things effectively, and we have that in loads.        

Lex Fridman: 06:10:00: Yeah, and this is such an interesting  space of UX design, because there’s so many unknowns here. And I can  tell UX is difficult because of how many people do it poorly. It’s just  not a trivial thing.        

Bliss Chapman: 06:10:19: Yeah. UX is not something that you can always solve by just constant iterating on different things. Sometimes  you really need to step back and think globally, “Am I even in the right sort of minima to be chasing down for a solution?” There’s a lot of  problems in which sort of fast iteration cycle is the predictor of how  successful you’ll be. As a good example, like in an RL simulation for  example, the more frequently you get reward, the faster you can  progress. It’s just an easier learning problem the more frequently you  get feedback. But UX is not that way, I mean, users are actually quite  often wrong about what the right solution is, and it requires a deep  understanding of the technical system, and what’s possible, combined  with what the problem is you’re trying to solve. Not just how the user  expressed it, but what the true underlying problem is to actually get to the right place.        

Lex Fridman: 06:11:04: Yeah, that’s the old stories of Steve  Jobs rolling in there, like, “Yeah, the user is a useful signal, but  it’s not a perfect signal, and sometimes you have to remove the floppy  disc drive.” Or whatever the… I forgot all the crazy stories of Steve  Jobs making wild design decisions. But there, some of it is aesthetic,  that some of it is about the love you put into the design, which is very much a Steve Jobs, Johnny Ive type thing, but when you have a human  being using their brain to interact with it, it also is deeply about  function, it’s not just aesthetic. And that, you have to empathize with a human being before you, while not always listening to them directly.  You have to deeply empathize. It’s fascinating. It’s really, really  fascinating. And at the same time, iterate, but not iterate in small  ways, sometimes a complete… Like rebuilding the design. Noland said in  the early days the UX sucked, but you improved quickly. What was that  journey like?        

Bliss Chapman: 06:12:16: Yeah, I mean, I’ll give you one  concrete example. So he really wanted to be able to read manga. This is  something that he… I mean, it sounds like a simple thing, but it’s  actually a really big deal for him, and he couldn’t do it with his mouse stick. It wasn’t accessible, you can’t scroll with the mouse stick on  his iPad on the website that he wanted to be able to use to read the  newest manga, and so-        

Lex Fridman: 06:12:36: Might be a good quick pause to say the mouth stick is the thing he’s using. Holding a stick in his mouth to scroll on a tablet.        

Bliss Chapman: 06:12:44: Right. Yeah. You can imagine it’s a stylus that you hold between your teeth. Yeah, it’s basically a very long stylus.        

Lex Fridman: 06:12:49: It’s exhausting, it hurts, and it’s inefficient.        

Bliss Chapman: 06:12:54: Yeah. And maybe it’s also worth  calling out, there are other alternative assisted technologies, but the  particular situation Noland’s in, and this is not uncommon, and I think  it’s also not well-understood by folks, is that he’s relatively spastic, so he’ll have muscle spasms from time to time. And so any assistive  technology that requires him to be positioned directly in front of a  camera, for example, an eye tracker, or anything that requires him to  put something in his mouth just is a no-go, ’cause he’ll either be  shifted out of frame when he has a spasm, or if he has something in his  mouth, it’ll stab him in the face if he spasms too hard. So these kinds  of considerations are important when thinking about what advantages a  BCI has in someone’s life. If it fits ergonomically into your life in a  way that you can use it independently when your caretakers not there,  wherever you want to, either in the bed or in the chair, depending on  your comfort level and your desire to have pressure source, all these  factors matter a lot in how good the solution is in that user’s life.        

06:13:45: So one of these very fun examples is  scroll. So, again, manga is something he wanted to be able to read, and  there’s many ways to do scroll with a BCI. You can imagine different  gestures, for example, the user could do that would move the page. But  scroll is a very fascinating control surface, because it’s a huge thing  on the screen in front of you. So any sort of jitter in the model  output, any sort of air in the model output causes an earthquake on the  screen. You really don’t want to have your mango page that you’re trying to read be shifted up and down a few pixels just because your scroll  decoder is not completely accurate.        

06:14:19: And so this was an example where we  had to figure out how to formulate the problem in a way that the errors  of the system, whenever they do occur, and we’ll do our best to minimize them, but whenever those errors do occur, that it doesn’t interrupt the qualia, again, of the experience that the user is having. It doesn’t  interrupt their flow of reading their book. And so what we ended up  building is this really brilliant feature. This is a teammate named  Bruce who worked on this really brilliant work called Quick Scroll. And  Quick Scroll basically looks at the screen, and it identifies where on  the screen are scroll bars. And it does this by deeply integrated with  macOS to understand where are the scroll bars actively present on the  screen, using the sort of accessibility tree that’s available to macOS  apps. And we identified where those scroll bars are, and we provided a  BCI scroll bar, and the BCI scroll bar looks similar to a normal scroll  bar, but it behaves very differently, in that once you move over to it,  your cursor sort of morphs onto it, it sort of attaches or latches onto  it. And then once you push up or down, in the same way that you’d use a  push to control the normal cursor, it actually moves the screen for you. So it’s basically like remapping the velocity to a scroll action.        

06:15:26: And the reason that feels so natural  and intuitive is that when you move over to attach to it feels like  magnetic, so you’re sort of stuck onto it, and then it’s one continuous  action, you don’t have to switch your imagined movement, you sort of  snap onto it, and then you’re good to go. You just immediately can start pulling the page down or pushing it up. And even once you get that  right, there’s so many little nuances of how the scroll behavior works  to make it natural and intuitive. So one example is momentum. When you  scroll a page with your fingers on the screen, you actually have some  flow, it doesn’t just stop right when you lift your finger up. The same  is true with BCI scroll, so we had to spend some time to figure out,  “What are the right nuances when you don’t feel the screen under your  fingertip anymore? What is the right sort of dynamic, or what’s the  right amount of page give, if you will, when you push it to make it flow the right amount for the user to have a natural experience reading  their book?”        

06:16:15: I could tell you there’s so many  little minutia of how exactly that scroll works, that we spent probably a month getting right, to make that feel extremely natural and easy for  the user to navigate.        

Lex Fridman: 06:16:25: I mean, even the scroll on a  smartphone with your finger feels extremely natural and pleasant, and it probably takes an extremely long time to get that right. And actually,  the same kind of visionary UX design that we were talking about, don’t  always listen to the users, but also listen to them, and also have  visionary, big, like throw everything out, think from first principles,  but also not. Yeah, yeah. By the way, it just makes me think that scroll bars on the desktop probably have stagnated, and never taken that…  ‘Cause the snap, same as snap to grid, snap to scroll bar action you’re  talking about is something that could potentially be extremely useful in the desktop setting, even just for users to just improve the  experience. ‘Cause the current scroll bar experience in the desktop is  horrible.        

Bliss Chapman: 06:17:19: Yep. Agreed.        

Lex Fridman: 06:17:20: It’s hard to find, hard to control,  there’s not a momentum, there’s… And the intention should be clear, when I start moving towards a scroll bar, there should be a snapping to the  scroll bar action, but of course… Maybe I’m okay paying that cost, but  there’s hundreds of millions of people paying that cost non-stop, but  anyway. But in this case, this is necessary, because there’s an extra  cost paid by Noland for the jitteriness, so you have to switch between  the scrolling and the reading. There has to be a face shift between the  two, like when you’re scrolling, you’re scrolling.        

Bliss Chapman: 06:17:58: Right, right. So that is one drawback  of the current approach. Maybe one other just sort of case study here.  So, again, UX is how it works, and we think about that holistically,  from the… Even the feature detection level of what we detect in the  brain, to how we design the decoder, what we choose to decode, to then  how it works once it’s being used by the user. So another good example  in that sort of how it works once they’re actually using the decoder,  the output that’s displayed on the screen is not just what the decoder  says, it’s also a function of what’s going on on the screen.        

06:18:25: So we can understand, for example,  that when you’re trying to close a tab, that very small, stupid little X that’s extremely tiny, which is hard to get precisely hit, if you’re  dealing with a noisy output of the decoder, we can understand that that  is a small little X you might be trying to hit, and actually make it a  bigger target for you. Similar to how when you’re typing on your phone,  if you are used to the iOS keyboard for example, it actually adapts to  target size of individual keys based on an underlying language model. So it’ll actually understand if I’m typing, “Hey, I’m going to see L.”  It’ll make the E key bigger because it knows Lex is the person I’m going to go see. And so that kind of predictiveness can make the experience  much more smooth, even without improvements to the underlying decoder or feature detection part of the stack.        

06:19:07: So we do that with a feature called  magnetic targets, we actually index the screen, and we understand,  “Okay, these are the places that are very small targets that might be  difficult to hit. Here’s the kind of cursor dynamics around that  location that might be indicative of the user trying to select it. Let’s make it easier. Let’s blow up the size of it in a way that makes it  easier for the user to sort of snap onto that target.” So all these  little details, they matter a lot in helping the user be independent in  their day-to-day living.        

## Neural decoder

Lex Fridman: 06:19:29: So how much of the work on the decoder is generalizable to P2, P3, P4, P5 PM? How do you improve the decoder  in a way that’s generalizable?        

Bliss Chapman: 06:19:40: Yeah, great question. So the  underlying signal we’re trying to decode is going to look very different in P2 than in P1. For example, channel number 345 is going to mean  something different in user one than it will in user two, just because  that electrode that corresponds with channel 345 is going to be next to a different neuron in user one to person user two. But the approach is  the methods, the user experience of how do you get the right behavioral  pattern from the user to associate with that neural signal. We hope that will translate over multiple generations of users.        

06:20:08: And beyond that, it’s very, very  possible, in fact, quite likely that we’ve overfit to Noland’s user  experience, desires and preferences. And so what I hope to see is that  when we get a second, third, fourth participant, that we find what the  right wide minimums are that cover all the cases that make it more  intuitive for everyone. And hopefully, there’s a crosspollination of  things, where, “Oh, we didn’t think about that with this user because  they can speak. But with this user who just can fundamentally not speak  at all, this user experience is not optimal.” Those improvements that we make there should hopefully translate then to even people who can speak but don’t feel comfortable doing so because we’re in a public setting,  like their doctor’s office.        

Lex Fridman: 06:20:42: So the actual mechanism of open-loop  labeling, and then closed-loop labeling would be the same, and hopefully can generalize across the different users-        

Bliss Chapman: 06:20:52: Correct.        

Lex Fridman: 06:20:52: … as they’re doing the calibration  step? And the calibration step is pretty cool. I mean, that in itself.  The interesting thing about Webgrid, which is closed-loop, it’s fun. I  love it when there’s… They used to be kind of idea of human computation, which is using actions a human would want to do anyway to get a lot of  signal from. And Webgrid is that, a nice video game that also serves as  great calibration.        

Bliss Chapman: 06:21:20: It’s so funny, I’ve heard this  reaction so many times. Before the first user was implanted, we had an  internal perception that the first user would not find this fun. And so  we thought really quite a bit actually about, “Should we build other  games that are more interesting for the user, so we can get this kind of data and help facilitate research that’s for long duration and stuff  like this?” Turns out that people love this game. I always loved it, but I didn’t know that that was a shared perception.        

Lex Fridman: 06:21:45: Yeah. And just in case it’s not clear, Webgrid is… There’s a grid of let’s say 35 by 35 cells and one of them  lights up blue and you have to move your mouse over that and click on  it. And if you miss it, it’s red, and…        

Bliss Chapman: 06:22:01: I’ve played this game for so many hours, so many hours.        

Lex Fridman: 06:22:04: And what’s your record you said?        

Bliss Chapman: 06:22:06: I think I have the highest at Neuralink right now. My record’s 17 BPS.        

Lex Fridman: 06:22:09: 17 BPS?        

Bliss Chapman: 06:22:11: If you imagine that 35 by 35 grid,  you’re hitting about 100 trials per minute. So 100 correct selections in that one minute window. So you’re averaging about between 500, 600  milliseconds per selection.        

Lex Fridman: 06:22:22: So one of the reasons I think I  struggle with that game is I’m such a keyboard person, so everything is  done with via keyboard. If I can avoid touching the mouse, it’s great.  So how can you explain your high performance?        

Bliss Chapman: 06:22:36: I have a whole ritual I go through  when I play Webgrid. There’s actually like a diet plan associated with  this. It’s a whole thing.        

Lex Fridman: 06:22:42: That’s great.        

Bliss Chapman: 06:22:43: The first thing is-        

Lex Fridman: 06:22:43: “I have to fast for five days, I have to go up to the mountains.”        

Bliss Chapman: 06:22:47: I mean, the fasting thing is important. So this is like-        

Lex Fridman: 06:22:49: Focuses the mind, yeah. It’s true, it’s true.        

Bliss Chapman: 06:22:51: So what I do is, I… Actually, I don’t  eat for a little bit beforehand, and then I’ll actually eat a ton of  peanut butter right before I play, and I get-        

Lex Fridman: 06:22:58: This is a real thing?        

Bliss Chapman: 06:22:59: This is a real thing, yeah. And then  it has to be really late at night, this is, again, a night owl thing I  think we share, but it has to be midnight, 2:00 A.M. kind of time  window. And I have a very specific physical position I’ll sit in, which  is… I was homeschooled growing up, and so I did most of my work on the  floor, just in my bedroom or whatever. And so I have a very specific  situation-        

Lex Fridman: 06:23:18: On the floor?        

Bliss Chapman: 06:23:19: … on the floor, that I sit and play.  And then you have to make sure there’s not a lot of weight on your elbow when you’re playing so you can move quickly. And then I turn the gain  of the cursor, so the speed of the cursor way, way up, so it’s small  motions that actually move the cursor.        

Lex Fridman: 06:23:29: Are you moving with your wrist, or you’re… You’re never-        

Bliss Chapman: 06:23:33: I move with my fingers. So my wrist is almost completely still, I’m just moving my fingers.        

Lex Fridman: 06:23:37: You know those… Just on a small tangent-        

Bliss Chapman: 06:23:39: Yeah.        

Lex Fridman: 06:23:40: … the… which I’ve been meaning to go  down this rabbit hole of people that set the world record in Tetris.  Those folks, they’re playing… There’s a way to… Did you see this?        

Bliss Chapman: 06:23:50: I’ve seen it. All the fingers are moving?        

Lex Fridman: 06:23:52: Yeah, you could find a way to do it  where it’s using a loophole, like a bug that you can do some incredibly  fast stuff. So it’s along that line, but not quite. But you do realize  there’ll be a few programmers right now listening to this who’ll fast  and eat peanut butter, and be like-        

Bliss Chapman: 06:24:09: Yeah, please track my record. I mean,  the reason I did this literally was just because I wanted the bar to be  high for the team. The number that we aim for should not be the median  performance, it should be able to beat all of us at least, that should  be the minimum bar.        

Lex Fridman: 06:24:21: What do you think is possible, like 20?        

Bliss Chapman: 06:24:23: Yeah, I don’t know what the limits… I  mean, the limits, you can calculate just in terms of screen refresh rate and cursor immediately jumping to the next target. I mean, I’m sure  there’s limits before that with just sort of reaction time, and visual  perception, and things like this. I would guess it’s below 40, but above 20, somewhere in there is probably the right… That I’d never to be  thinking about. It also matters how difficult the task is. You can  imagine some people might be able to do 10,000 targets on the screen,  and maybe they can do better that way. So there’s some task  optimizations you could do to try to boost your performance as well.        

Lex Fridman: 06:24:55: What do you think it takes for Noland  to be able to do above 8.5, to keep increasing that number? You said  every increase in the number…        

Lex Fridman: 06:25:00: … to keep increasing that number. You said every increase in the number might require different improvements in the system.        

Bliss Chapman: 06:25:08: Yeah. The first answer that’s  important to say is, I don’t know. This is edge of the research so,  again, nobody’s gotten to that number before, so what’s next is going to be a heuristic guess from my part. What we’ve seen historically is that different parts of the stack can compile next to different time points. So when I first joined Neuralink, three years ago or so, one of the  major problems was just the latency of the Bluetooth connection. The  radio in the device wasn’t super good, it was an early revision of the  implant. And it just, no matter how good your decoder was, if your thing is updating every 30 milliseconds or 50 milliseconds, it’s just going  to be choppy. And no matter how good you are, that’s going to be  frustrating and lead to challenges. So at that point, it was very clear  that the main challenge is just get the data off the device in a very  reliable way such that you can enable the next challenge to be tackled.        

06:25:59: And then at some point it was actually the modeling challenge of how do you just build a good mapping, like  the supervised learning problem of, you have a bunch of data and you  have a label you’re trying to predict, just what is the right neural  decoder architecture and hyperparameters to optimize that? And that was  the problem for a bit, and once you solve that, it became a different  bottleneck. I think the next bottleneck after that was actually just  software stability and reliability. If you have widely varying inference latency in your system or your app just lags out every once in a while, it decreases your ability to maintain and get in a state of flow, and  it basically just disrupts your control experience. And so there’s a  variety of different software bugs and improvements we made that  basically increased the performance of the system, made it much more  reliable, much more stable and led to a state where we could reliably  collect data to build better models with.        

06:26:49: So that was a bottleneck for a while,  it was just the software stack itself. If I were to guess right now,  there’s two major directions you could think about for improving VPS  further. The first major direction is labeling. So labeling is, again,  this fundamental challenge of given a window of time where the user is  expressing some behavioral intent, what are they really trying to do at  the granularity of every millisecond? And that again, is a task design  problem, it’s a UX problem, it’s a machine learning problem, it’s a  software problem. It touches all those different domains. The second  thing you can think about to improve BPS further is either completely  changing the thing you’re decoding or just extending the number of  things that you’re decoding. So this is serving the direction of  functionality, basically, you can imagine giving more clicks.        

06:27:33: For example, a left click, a right  click, a middle click, different actions like click-and-drag for  example, and that can improve the effective bit rate of your  communication processes. If you’re trying to allow the user to express  themselves through any given communication channel, you can measure that with bits per second. But what actually is measured at the end of the  day is how effective are they at navigating their computer? So from the  perspective of the downstream tasks that you care about, functionality  and extending functionality is something we’re very interested in,  because not only can it improve the number of BPS, but it can also  improve the downstream independence that the user has and the skill and  efficiency with which they can operate their computer.        

Lex Fridman: 06:28:05: Would the number of threads increasing also potentially help?        

Bliss Chapman: 06:28:10: Yes. Short answer is yes. It’s a bit  nuanced how that manifests in the numbers. So what you’ll see is that if you plot a curve of number of channels that you’re using for decode  versus either the offline metric of how good you are at decoding or the  online metric of in practice how good is the user at using this device,  you see roughly a log curve. So as you move further out in number of  channels, you get a corresponding logarithmic improvement in control  quality and offline validation metrics. The important nuance here is  that each channel corresponds with a specific represented intention in  the brain. So for example, if you have a channel 254, it might  correspond with moving to the right. Channel 256, might mean move to the left. If you want to expand the number of functions you want to  control, you really want to have a broader set of channels that covers a broader set of imagined movements. You can think of it like Mr. Potato  Man actually, if you had a bunch of different imagined movements you  could do, how would you map those imagined movements to input to a  computer? You could imagine handwriting to output characters on the  screen. You could imagine just typing with your fingers and have that  output text on the screen. You could imagine different finger  modulations for different clicks. You can imagine wiggling your big nose for opening some menu or wiggling your big toe to have command tab  occur or something like this. So it’s really the amount of different  actions you can take in the world depends on how many channels you have  on the information content that they carry.        

Lex Fridman: 06:29:42: Right, so that’s more about the number of actions. So actually as you increase the number of threads, that’s  more about increasing the number of actions you’re able to perform.        

Bliss Chapman: 06:29:51: But one other nuance there that is  worth mentioning. So again, our goal is really to enable a user with  paralyzes to control the computer as fast as I can, so that’s BPS, with  all the same functionality I have, which is what we just talked about,  but then also as reliably as I can. And that last point is very related  to channel account discussion. So as you scale out number of channels,  the relative importance of any particular feature of your model input to the output control of the user diminishes, which means that if the  neural non-stationarity effect is per channel, or if the noise is  independent such that more channels means on average less output effect, then your reliability of your system will improve. So one core thesis  that at least I have is that scaling channel account should improve the  reliability system without any work on the decoder itself.        

Lex Fridman: 06:30:37: Can you linger on the reliability  here? So first of all, when you say non-stationarity of the signal,  which aspect are you referring to?        

Bliss Chapman: 06:30:46: Yeah, so maybe let’s talk briefly what the actual underlying signal looks like. So again, I spoke very briefly at the beginning about how when you imagine moving to the right or  imagine moving to the left, neurons might fire more or less, and the  frequency content that signal, at least in the motor cortex, it’s very  correlated with the output intention, the behavioral task that the user  is doing. You can imagine actually this is not obvious that rate coding, which is the name of that phenomenon, is the only way the brain could  represent information. You can imagine many different ways in which the  brain could encode intention, and there’s actually evidence in bats for  example, that there’s temporal codes. So timing codes of exactly when  particular neurons fire is the mechanism of information representation.  But at least in the motor cortex, there’s substantial evidence that it’s rate coding or at least first order of effect is that it’s rate coding.        

06:31:31: So then if the brain is representing  information by changing the frequency of a neuron firing, what really  matters is the delta between the baseline state of the neuron and what  it looks like when it’s modulated. And what we’ve observed and what has  also been observed in academic work is that that baseline rate, if  you’re to target the scale, if you imagine that analogy for measuring  flour or something when you’re baking, that baseline state of how much  the pot weighs is actually different day to day. So if what you’re  trying to measure is how much rice is in the pot, you’re going to get a  different measurement different days because you’re measuring with  different pots. So that baseline rate shifting is really the thing that  at least from a first order description of the problem is what’s causing this downstream bias. There can be other effects, not linear effects on top of that, but at least at a very first order description of the  problem. That’s what we observed day to day is that the baseline firing  rate of any particular neuron or observed on a particular channel is  changing.        

Lex Fridman: 06:32:23: So can you just adjust to the baseline to make it relative to the baseline nonstop?        

Bliss Chapman: 06:32:29: Yeah, this is a great question. So  with monkeys, we have found various ways to do this. One example way to  do this is you ask them to do some behavioral tasks like play the game  with a joystick, you measure what’s going on in the brain. You compute  some mean of what’s going on across all the input features, and you  subtract that on the input when you’re doing your BCI session, works  super well. For whatever reason, that doesn’t work super well with  Noland. I actually don’t know the full reason why, but I can imagine  several explanations.        

06:32:59: One such explanation could be that the context effect difference between some open-loop task and some  closed-loop task is much more significant with Noland than it is with  the monkey. Maybe in this open-loop task, he’s watching the Lex Fridman  Podcast while he’s doing the task or he’s whistling and listening to  music and talking with his friend and ask his mom what’s for dinner  while he’s doing this task. So the exact difference in context between  those two states may be much larger and thus lead to a bigger  generalization gap between the features that you’re normalizing at  open-loop time and what you’re trying to use at closed-loop time.        

Lex Fridman: 06:33:29: That’s interesting. Just on that  point, it’s incredible to watch Noland be able to multitask, to do  multiple tasks at the same time, to be able to move the mouse cursor  effectively while talking and while being nervous because he’s talking  in front of [inaudible 06:33:45]        

Bliss Chapman: 06:33:44: Kicking my ass and chest too, yeah.        

Lex Fridman: 06:33:46: Kicking your ass and talk trash while doing it-        

Bliss Chapman: 06:33:46: Yes.        

Lex Fridman: 06:33:50: … so all at the same time. And yes, if you are trying to normalize to the baseline, that might throw  everything off. Boy, is that interesting?        

Bliss Chapman: 06:33:59: Maybe one comment on that too. For  folks that aren’t familiar with assistive technology, I think there’s a  common belief that, well, why can’t you just use an eye tracker or  something like this for helping somebody move a mouse on the screen?  It’s really a fair question and one that I actually was not confident  before Sir Noland that this was going to be a profoundly transformative  technology for people like him. And I’m very confident now that it will  be, but the reasons are subtle. It really has to do with ergonomically  how it fits into their life, even if you can just offer the same level  of control as what they would have with an eye tracker or with a mouse  stick, but you don’t need to have that thing in your face. You don’t  need to be positioned a certain way.        

06:34:34: You don’t need your caretaker to be  around to set it up for you. You can activate it when you want, how you  want, wherever you want. That level of independence is so game-changing  for people. It means that they can text a friend at night privately  without their mom needing to be in the loop. It means that they can open up and browse the internet at 2:00 AM when nobody’s around to set their iPad up for them. This is a profoundly game-changing thing for folks in that situation, and this is even before we start talking about folks  that may not be able to communicate at all or ask for help when they  want to. This can be potentially the only link that they have to the  outside world. And yeah, that one doesn’t, I think, need explanation of  why that’s so impactful.        

Lex Fridman: 06:35:11: You mentioned NeuroDecodeR. How much  machine learning is in the decoder, how much magic, how much science,  how much art? How difficult is it to come up with a decoder that figures out what these sequence of spikes mean?        

Bliss Chapman: 06:35:28: Yeah, good question. There’s a couple  of different ways to answer this, so maybe I’ll zoom out briefly first  and then I’ll go down one of the rabbit holes. So the zoomed out view is that building the decoder is really the process of building the dataset plus compiling it into the weights, and each of those steps is  important. The direction I think of further improvement is primarily  going to be in the dataset side of how do you construct the optimal  labels for the model. But there’s an entirely separate challenge of then how do you compile the best model? And so I’ll go briefly down the  second rabbit hole. One of the main challenges with designing the  optimal model for BCI is that offline metrics don’t necessarily  correspond to online metrics. It’s fundamentally a control problem. The  user is trying to control something on the screen and the exact user  experience of how you output the intention impacts their ability to  control. So for example, if you just look at validation loss as  predicted by your model, there can be multiple ways to achieve the same  validation loss.        

06:36:26: Not all of them are equally  controllable by the end user. And so it might be as simple as saying,  oh, you could just add auxiliary loss terms that help you capture the  thing that actually matters. But this is a very complex nuanced process. So how you turn the labels into the model is more of a nuanced process  than just a standard supervised learning problem. One very fascinating  anecdote here, we’ve tried many different neural network architectures  that translate brain data to velocity outputs, for example. And one  example that’s stuck in my brain from a couple of years ago now is at  one point, we were using just fully-connected networks to decode the  brain activity. We tried A-B test where we were measuring the relative  performance in online control sessions of one deconvolution over the  input signal. So if you imagine per channel you have a sliding window  that’s producing some convolved feature, for each of those input  sequences for every single channel simultaneously, you can actually get  better validation metrics, meaning you’re fitting the data better and  it’s generalizing better in offline data if you use this convolutional  architecture. You’re reducing parameters. It’s a standard procedure when you’re dealing with time series data. Now it turns out that when using  that model online, the controllability was worse, was far worse, even  though the offline metrics were better, and there can be many ways to  interpret that. But what that taught me at least was that, hey, it’s at  least the case right now that if you were to just throw a bunch of  compute at this problem and you were trying to hyperparameter optimize  or let some GPT model hard code or come up with or invent many different solutions, if you were just optimizing for loss, it would not be  sufficient, which means that there’s still some inherent modeling gap  here. There’s still some artistry left to be uncovered here of how to  get your model to scale with more compute, and that may be fundamentally a labeling problem, but there may be other components to this as well.        

Lex Fridman: 06:38:11: Is it data constraint at this time, which is what it sounds like? How do you get a lot of good labels?        

Bliss Chapman: 06:38:22: Yeah, I think it’s data quality constrained, not necessarily data quantity constrained.        

Lex Fridman: 06:38:27: But even just the quantity ’cause it has to be trained on the interactions. I guess there’s not that many interactions.        

Bliss Chapman: 06:38:37: Yeah, so it depends what version of  this you’re talking about. So if you’re talking about, let’s say, the  simplest example of just 2D velocity, then I think, yeah, data quality  is the main thing. If you’re talking about how to build a multi-function output that lets you do all the inputs the computer that you and I can  do, then it’s actually a much more sophisticated nuanced modeling  challenge because now you need to think about not just when the users  are left clicking, but when you’re building the left click model, you  also need to be thinking about how to make sure it doesn’t fire when  they’re trying to right click or when they’re trying to move the mouse.        

06:39:03: So one example of an interesting bug  from week one of BCI with Noland was when he moved the mouse, the click  signal dropped off a cliff and when he stopped, the click signal went  up. So again, there’s a contamination between the two inputs. Another  good example was at one point he was trying to do a left click and drag, and the minute he started moving, the left click signal dropped off a  cliff. So again, ’cause some contamination between the two signals, you  need to come up with some way to either in the dataset or in the model  build robustness against this kind of, you think of it like overfitting, but really it’s just that the model has not seen this kind of  variability before. So you need to find some way to help the model with  that.        

Lex Fridman: 06:39:42: This is super cool ’cause it feels like all of this is very solvable, but it’s hard.        

Bliss Chapman: 06:39:46: Yes, it is fundamentally an  engineering challenge. This is important to emphasize, and it’s also  important to emphasize that it may need fundamentally new techniques,  which means that people who work on let’s say unsupervised speech  classification using CTC loss for example, with internal to Siri, they  could potentially have very applicable skills to this.        

## Future improvements

Lex Fridman: 06:40:03: So what things are you excited about  in the future development of the software stack on Neuralink? So  everything we’ve been talking about, the decoding, the UX?        

Bliss Chapman: 06:40:14: I think there’s something I’m excited  about from the technology side and some I’m excited about for  understanding how this technology is going to be best situated for  entering the world, so I’ll work backwards. On the technology entering  the world side of things, I’m really excited to understand how this  device works for folks that cannot speak at all, that have no ability to bootstrap themselves into useful control by voice command, for example, and are extremely limited in their current capabilities. I think that  will be an incredibly useful signal for us to understand really, what is an existential threat for all startups, which is product market fit.  Does this device have the capacity and potential to transform people’s  lives in the current state? And if not, what are the gaps? And if there  are gaps, how do we solve them most efficiently?        

06:40:56: So that’s what I’m very excited about  for the next year or so of clinical trial operations. On the technology  side, I’m quite excited about basically everything we’re doing. I think  it’s going to be awesome. The most prominent one I would say is scaling  channel account. So right now we have a 1,000-channel device. The next  version we’ll have between 3 and 6,000 channels, and I would expect that curve to continue in the future. And it’s unclear what set of problems  will just disappear completely at that scale and what set of problems  will remain and require for their focus. And so I’m excited about the  clarity of gradient that gives us in terms of the user experiences we  choose to focus our time and resources on. And then also in terms of  even things as simple as non-stationarity, does that problem just  completely go away at that scale? Or do we need to come up with new  creative UXes still even at that point?        

06:41:40: And also when we get to that time  point, when we start expanding out dramatically the set of functions  that you can output from one brain how to deal with all the nuances of  both the user experience of not being able to feel the different keys  under your fingertips, but still needing to be able to modulate all of  them in synchrony to achieve the thing you want. And again, you don’t  have that appropriate set of feedback loop, so how can you make that  intuitive for a user to control a high dimensional control surface  without feeling the thing physically? I think that’s going to be a super interesting problem. I’m also quite excited to understand do these  scaling laws continue? As you scale channel count, how much further out  do you go before that saturation point is truly hit?        

06:42:17: And it’s not obvious today. I think we only know what’s in the interpolation space. We only know what’s  between 0 and 1,024, but we don’t know what’s beyond that. And then  there’s a whole range of interesting neuroscience and brain questions,  which is, when you stick more stuff in the brain in more places, you get to learn much more quickly about what those brain regions represent.  And so I’m excited about that fundamental neuroscience learning, which  is also important for figuring out how to most efficiently insert  electrodes in the future. So yeah, I think all those dimensions I’m  really, really excited about. And that doesn’t even get close to  touching the software stack that we work on every single day and what  we’re working on right now.        

Lex Fridman: 06:42:49: Yeah, it seems virtually impossible to me that 1,000 electrodes is where it saturates. It feels like this  would be one of those silly notions in the future where obviously you  should have millions of electrodes and this is where the true  breakthroughs happen. You tweeted, “Some thoughts are most precisely  described in poetry.” Why do you think that is?        

Bliss Chapman: 06:43:20: I think it’s because the information  bottleneck of language is pretty steep, and yet you’re able to  reconstruct on the other person’s brain more effectively without being  literal. If you can express a sentiment such that in their brain they  can reconstruct the actual true underlying meaning and beauty of the  thing that you’re trying to get across, the generator function in their  brain is more powerful than what language can express. And so the  mechanism of poetry is really just to feed or seed that generator  function.        

Lex Fridman: 06:43:56: So being literal sometimes is a suboptimal compression for the thing you’re trying to convey.        

Bliss Chapman: 06:44:03: That right. And it’s actually in the  process of the user going through that generation that they understand  what you mean. That’s the beautiful part. It’s also like when you look  at a beautiful painting, it’s not the pixels of the painting that are  beautiful, it’s the thought process that occurs when you see that, the  experience of that, that actually is the thing that matters.        

Lex Fridman: 06:44:19: Yeah, it’s resonating with some deep  thing within you that the artist also experienced and was able to convey that through the pixels.        

Bliss Chapman: 06:44:28: Right. Right.        

Lex Fridman: 06:44:29: And that’s actually going to be  relevant for full-on telepathy. It’s like if you just read the poetry  literally, that doesn’t say much of anything interesting. It requires a  human to interpret it. So it’s the combination of the human mind and all the experiences that a human being has within the context of the  collective intelligence of the human species that makes that poem make  sense and they load that in. So in that same way, the signal that  carries from human to human meaning may seem trivial, but may actually  carry a lot of power because of the complexity of the human mind and the receiving end. Yeah, that’s interesting. Who was it? I think Joscha  Bach [inaudible 06:45:24] said something about all the people that think we’ve achieved AGI explain why humans like music.        

Bliss Chapman: 06:45:37: Oh, yeah.        

Lex Fridman: 06:45:38: And until the AGI likes music, you haven’t achieved AGI or something like this.        

Bliss Chapman: 06:45:45: Do you not think that’s some next token entropy surprise kind of thing going on there?        

Lex Fridman: 06:45:49: I don’t know.        

Bliss Chapman: 06:45:50: I don’t know either. I listen to a lot of classical music and also read a lot of poetry and yeah, I do wonder  if there is some element of the next token surprise factor going on  there.        

Lex Fridman: 06:45:59: Yeah, maybe.        

Bliss Chapman: 06:46:00: Cause a lot of the tricks in both  poetry and music are basically you have some repeated structure and then you do a twist. It’s like, okay, clause 1, 2, 3 is one thing and then  clause four is like, “Okay, now we’re onto the next theme,” and they  play with exactly when the surprise happens and the expectation of the  user. And that’s even true through history as musicians evolve in music, they take some known structure that people are familiar with and they  just tweak it a little bit. They tweak it and add a surprising element.  This is especially true in classical music heritage, but that’s what I’m wondering. Is it all just entropy?        

Lex Fridman: 06:46:32: So breaking structure or breaking symmetry is something that humans seem to like. Maybe it’s as simple as that.        

Bliss Chapman: 06:46:37: Yeah, and great artists copy and  knowing which rules to break is the important part, and fundamentally,  it must be about the listener of the piece. Which rule is the right one  to break? It’s about the audience member perceiving that as interesting.        

Lex Fridman: 06:46:54: What do you think is the meaning of human existence?        

Bliss Chapman: 06:47:00: There’s a TV show I really like called The West Wing, and in The West Wing there’s a character, he’s the  President of the United States who’s having a discussion about the Bible with one of their colleagues. And the colleague says something about  the Bible says X, Y, and Z, and the President says, “Yeah, but it also  says A, B, C.” The person says, “Well, do you believe the Bible to be  literally true?” And the President says, “Yes, but I also think that  neither of us are smart enough to understand it.” I think the analogy  here for the meaning of life is that largely we don’t know the right  question to ask.        

06:47:38: So I think I’m very aligned with the  Hitchhiker’s Guide to the Galaxy version of this question, which is  basically, if we can ask the right questions, it’s much more likely we  find the meaning of human existence. So in the short term as a heuristic in the search policy space, we should try to increase the diversity of  people asking such questions or generally of consciousness and conscious beings asking such questions. So again, I think I will take the I don’t know card here, but say I do think there are meaningful things we can  do that improve the likelihood of answering that question.        

Lex Fridman: 06:48:13: It’s interesting how much value you  assign to the task of asking the right questions. That’s the main thing, it’s not the answers, it’s the questions.        

Bliss Chapman: 06:48:24: This point, by the way, is driven home in a very painful way when you try to communicate with someone who  cannot speak, because a lot of the time, the last thing to go is they  have the ability to somehow wiggle a lip or move something that allows  them to say yes or no. And in that situation, it’s very obvious that  what matters is, are you asking them the right question to be able to  say yes or no to?        

Lex Fridman: 06:48:45: Wow, that’s powerful. Well, Bliss,  thank you for everything you do, and thank you for being you, and thank  you for talking today.        

Bliss Chapman: 06:48:54: Thank you.        

## Noland Arbaugh

Lex Fridman: 06:48:56: Thanks for listening to this  conversation with Bliss Chapman. And now, dear friends, here’s Noland  Arbaugh, the first human being to have a Neuralink device implanted in  his brain. You had a diving accident in 2016 that left you paralyzed  with no feeling from the shoulders down. How did that accident change  your life?        

## Becoming paralyzed

Noland Arbaugh: 06:49:18: It was a freak thing that happened.  Imagine you’re running into the ocean, although this is a lake, but  you’re running into the ocean and you get to about waist high, and then  you dive in, take the rest of the plunge under the wave or something.  That’s what I did, and then I just never came back up. Not sure what  happened. I did it running into the water with a couple of guys, and so  my idea of what happened is really just that I took a stray fist, elbow, knee, foot, something to the side of my head. The left side of my head  was sore for about a month afterwards, so I must’ve taken a pretty big  knock, and then they both came up and I didn’t. And so I was face down  in the water for a while. I was conscious, and then eventually just  realized I couldn’t hold my breath any longer and I keep saying took a  big drink.        

06:50:20: People, I don’t know if they like that I say that. It seems like I’m making light of it all, but it’s just how I am, and I don’t know. I am a very relaxed stress-free person. I  rolled with the punches for a lot of this. I took it in stride. It’s  like, “All right, well, what can I do next? How can I improve my life  even a little bit on a day-to-day basis?” At first, just trying to find  some way to heal as much of my body as possible to try to get healed, to try to get off a ventilator, learn as much as I could so I could  somehow survive once I left the hospital. And then thank God I had my  family around me. If I didn’t have my parents, my siblings, then I  would’ve never made it this far.        

06:51:24: They’ve done so much for me, more than I can ever thank them for, honestly, and a lot of people don’t have  that. A lot of people in my situation, their families either aren’t  capable of providing for them or honestly just don’t want to, and so  they get placed somewhere in some sort of home. So thankfully, I had my  family. I have a great group of friends, a great group of buddies from  college who have all rallied around me, and we’re all still incredibly  close. People always say if you’re lucky, you’ll end up with one or two  friends from high school that you keep throughout your life. I have  about 10 or 12 from high school that have all stuck around, and we still get together, all of us twice a year. We call it the spring series and  the fall series. This last one we all did, we dressed up X-Men, so I did a-        

Lex Fridman: 06:52:21: Nice.        

Noland Arbaugh: 06:52:21: … Professor Xavier, and it was  freaking awesome. It was so good. So yeah, I have such a great support  system around me, and so being a quadriplegic isn’t that bad. I get  waited on all the time. People bring me food and drinks, and I get to  sit around and watch as much TV and movies and anime as I want. I get to read as much as I want. It’s great.        

Lex Fridman: 06:52:51: It’s beautiful to see that you see the silver lining in all of this. Just going back, do you remember the  moment when you first realized you were paralyzed from the neck down?        

Noland Arbaugh: 06:53:03: Yep. I was face down in the water when I… whatever, something hit my head. I tried to get up and I realized I  couldn’t move, and it just clicked. I’m like, “All right, I’m paralyzed, can’t move. What do I do? If I can’t get up? I can’t flip over, can’t  do anything, then I’m going to drown eventually.” And I knew I couldn’t  hold my breath forever, so I just held my breath and thought about it  for maybe 10, 15 seconds. I’ve heard from other people that on lookers, I guess the two girls that pulled me out of the water were two of my best friends. They were lifeguards, and one of them said that it looked like my body was shaking in the water like I was trying to flip over and  stuff, but I knew. I knew immediately, and I realized that that’s what  my situation was from here on out.        

06:54:08: Maybe if I got to the hospital, they’d be able to do something.When I was in the hospital right before  surgery, I was trying to calm one of my friends down. I had brought her  with me from college to camp, and she was just bawling over me, and I  was like, “Hey, it’s going to be fine. Don’t worry.” I was cracking some jokes to try to lighten the mood. The nurse had called my mom, and I  was like, “Don’t tell my mom. She’s just going to be stressed out. Call  her after I’m out of surgery ’cause at least she’ll have some answers  then, whether I live or not, really.” And I didn’t want her to be  stressed through the whole thing, but I knew.        

06:54:44: And then when I first woke up after  surgery, I was super drugged up. They had me on fentanyl three ways,  which was awesome. I don’t recommend it, but I saw some crazy stuff on  that fentanyl, and it was still the best I’ve ever felt on drugs,  medication, sorry, on medication. I remember the first time I saw my mom in the hospital, I was just bawling. I had ventilator in. I couldn’t  talk or anything, and I just started crying because it was more like  seeing her… The whole situation obviously was pretty rough, but it was  just seeing her face for the first time was pretty hard. But yeah, I  never had a moment of, “Man, I’m paralyzed. This sucks. I don’t want to  be around anymore.” It was always just, “I hate that I have to do this,  but sitting here and wallowing isn’t going to help.”        

Lex Fridman: 06:55:57: So immediate acceptance.        

Noland Arbaugh: 06:55:58: Yeah. Yeah.        

Lex Fridman: 06:56:01: Has there been low points along the way?        

Noland Arbaugh: 06:56:03: Yeah, yeah, sure. There are days when I don’t really feel like doing anything. Not so much anymore. Not for the last couple of years I don’t really feel that way. I’ve more so just  wanted to try to do anything possible to make my life better at this  point. But at the beginning, there were some ups and downs. There were  some really hard things to adjust to. First off, just the first couple  months, the amount of pain I was in was really, really hard. I remember  screaming at the top of my lungs in the hospital because I thought my  legs were on fire, and obviously I can’t feel anything, but it’s all  nerve pain. And so that was a really hard night. I asked them to give me as much pain meds as possible, but they’re like, “You’ve had as much as you can have, so just deal with it. Go to a happy place,” sort of  thing. So that was a pretty low point.        

06:56:59: And then every now and again, it’s  hard realizing things that I wanted to do in my life that I won’t be  able to do anymore. I always wanted to be a husband and father, and I  just don’t think that I could do it now as a quadriplegic. Maybe it’s  possible, but I’m not sure I would ever put someone I love through that, having to take care of me and stuff. Not being able to go out and play  sports, I was a huge athlete growing up, so that was pretty hard. Little things too, when I realized I can’t do them anymore. There’s something  really special about being able to hold a book and smell a book, the  feel, the texture, the smell as you turn the pages, I just love it and I can’t do it anymore, and it’s little things like that.        

06:57:53: The two-year mark was pretty rough.  Two years is when they say you will get back basically as much as you’re ever going to get back as far as movement and sensation goes. And so  for the first two years, that was the only thing on my mind was try as  much as I can to move my fingers, my hands, my feet, everything possible to try to get sensation and movement back. And then when the two-year  mark hit, so June 30, 2018, I was really sad that that’s where I was,  and then just randomly here and there, but I was never depressed for  long periods of time. Just it never seemed worthwhile to me.        

Lex Fridman: 06:58:45: What gave you strength?        

Noland Arbaugh: 06:58:47: My faith. My faith in God was a big  one. My understanding that it was all for purpose, and even if that  purpose wasn’t anything involving Neuralink, even if that purpose was…  There’s a story in the Bible about Job, and I think it’s a really,  really popular story about how Job has all of these terrible things  happen to him, and he praises God throughout the whole situation. I  thought, and I think a lot of people think for most of their lives that  they are Job, that they’re the ones going through something terrible,  and they just need to praise God through the whole thing and everything  will work out.        

06:59:28: At some point after my accident, I  realized that I might not be Job, that I might be one of his children  that gets killed or kidnapped or taken from him. And so it’s about  terrible things that happen to those around you who you love. So maybe  in this case, my mom would be Job and she has to get through something  extraordinarily hard, and I just need to try and make it as best as  possible for her because she’s the one that’s really going through this  massive trial.        

Noland Arbaugh: 07:00:01: … she’s the one that’s really going  through this massive trial and that gave me a lot of strength, and  obviously my family. My family and my friends, they give me all the  strength that I need on a day-to-day basis. So it makes things a lot  easier having that great support system around me.        

Lex Fridman: 07:00:20: From everything I’ve seen of you  online, your streams and the way you are today, I really admire, let’s  say your unwavering positive outlook on life. Has that always been this  way?        

Noland Arbaugh: 07:00:32: Yeah, yeah. I mean, I’ve just always  thought I could do anything I ever wanted to do. There was never  anything too big. Whatever I set my mind to, I felt like I could do it. I didn’t want to do a lot. I wanted to travel around and be sort of like a gypsy and go work odd jobs. I had this dream of traveling around Europe and being like, I don’t know, a shepherd in Wales or Ireland, and then  going and being a fisherman in Italy, doing all of these things for a  year. It’s such cliche things, but I just thought it would be so much  fun to go and travel and do different things.        

07:01:17: And so I’ve always just seen the best  in people around me too, and I’ve always tried to be good to people. And growing up with my mom too, she’s like the most positive energetic  person in the world, and we’re all just people people. I just get along  great with people. I really enjoy meeting new people, and so I just  wanted to do everything. This is kind of just how I’ve been.        

Lex Fridman: 07:01:50: It’s just great to see that cynicism didn’t take over given everything you’ve been through.        

Noland Arbaugh: 07:01:55: Yeah.        

Lex Fridman: 07:01:56: Was that a deliberate choice you made, that you’re not going to let this keep you down?        

Noland Arbaugh: 07:02:01: Yeah, a bit. Also, it’s just kind of  how I am. I just, like I said, I roll with the punches with everything. I always used to tell people I don’t stress about things much, and  whenever I’d see people getting stressed, I would just say, “It’s not  hard just don’t stress about it and that’s all you need to do. And  they’re like, “That’s not how that works.” I’m like, “It works for me.  Just don’t stress and everything will be fine. Everything will work  out.” Obviously not everything always goes well, and it’s not like it  all works out for the best all the time, but I just don’t think stress  has had any place in my life since I was a kid.        

## First Neuralink human participant

Lex Fridman: 07:02:44: What was the experience like of you  being selected to be the first human being to have a Neuralink device  implanted in your brain? Were you scared? Excited?        

Noland Arbaugh: 07:02:54: No, no. It was cool. I was never  afraid of it. I had to think through a lot. Should I do this? Be the  first person? I could wait until number two or three and get a better  version of the Neuralink. The first one might not work. Maybe it’s  actually going to kind of suck. It’s going to be the worst version ever  in a person, so why would I do the first one? I’ve already kind of been  selected? I could just tell them, “Okay, find someone else, and then  I’ll do number two or three.” I’m sure they would let me, they’re  looking for a few people anyways, but ultimately I was like, I don’t  know? There’s something about being the first one to do something. It’s  pretty cool. I always thought that if I had the chance that I would like to do something for the first time, this seemed like a pretty good  opportunity. And I was never scared.        

07:03:51: I think my faith had a huge part in  that. I always felt like God was preparing me for something. I almost  wish it wasn’t this, because I had many conversations with God about not wanting to do any of this as a quadriplegic. I told Him, “I’ll go out  and talk to people. I’ll go out and travel the world and talk to  stadiums, thousands of people, give my testimony. I’ll do all of it, but heal me first. Don’t make me do all of this in a chair. That sucks.”  And I guess He won that argument. I didn’t really have much of a choice. I always felt like there was something going on. And to see how, I  guess easily I made it through the interview process and how quickly  everything happened, how the stars sort of aligned with all of this. It  just told me as the surgery was getting closer, it just told me that it  was all meant to happen.        

07:05:02: It was all meant to be, and so I  shouldn’t be afraid of anything that’s to come. And so I wasn’t. I kept  telling myself like, “You say that now, but as soon as the surgery  comes, you’re probably going to be freaking out. You’re about to have  brain surgery.” And brain surgery is a big deal for a lot of people, but it’s an even bigger deal for me. It’s all I have left. The amount of  times I’ve been like, “Thank You, God, that you didn’t take my brain and my personality and my ability to think, my love of learning, my  character, everything. Thank You so much. As long as You left me that,  then I think I can get by.” And I was about to let people go root around in there like, “Hey, we’re going to go put some stuff in your brain.  Hopefully it works out.” And so it was something that gave me pause, but like I said, how smoothly everything went.        

07:05:54: I never expected for a second that  anything would go wrong. Plus the more people I met on the Barrow side  and on the Neuralink side, they’re just the most impressive people in  the world. I can’t speak enough to how much I trust these people with my life and how impressed I am with all of them. And to see the excitement on their faces, to walk into a room and, roll into a room and see all  of these people looking at me like, “We’re so excited. We’ve been  working so hard on this and it’s finally happening.” It’s super  infectious and it just makes me want to do it even more. And to help  them achieve their dreams, I don’t know, it’s so rewarding and I’m so  happy for all of them, honestly.        

## Day of surgery

Lex Fridman: 07:06:45: What was the day of surgery like? When did you wake up? What’d you feel? Minute-by-minute. Were you freaking out?        

Noland Arbaugh: 07:06:54: No, no. I thought I was going to, but  as surgery approached the night before, the morning of, I was just  excited. I was like, “Let’s make this happen.” I think I said that,  something like that to Elon on the phone. Beforehand we were FaceTiming, and I was like, “Let’s rock and roll.” And he’s like, “Let’s do it.” I  don’t know. I wasn’t scared. So we woke up. I think we had to be at the  hospital at 5:30 AM. I think surgery was at 7:00 AM So we woke up pretty early. I’m not sure much of us slept that night. Got to the hospital  5:30, went through all the pre-op stuff. Everyone was super nice. Elon  was supposed to be there in the morning, but something went wrong with  his plane, so we ended up FaceTiming. That was cool. I had one of the  greatest one-liners of my life after that phone call. Hung up with him.  There were 20 people around me and I was like, “I just hope he wasn’t  too starstruck talking to me.”        

Lex Fridman: 07:07:54: Nice.        

Noland Arbaugh: 07:07:55: And yeah, it was good.        

Lex Fridman: 07:07:56: Well done. Well done. Did you write that ahead of time it just came to you?        

Noland Arbaugh: 07:08:02: No. No, it just came to me. I was  like, “This seems right.” Went into surgery. I asked if I could pray  right beforehand, so I prayed over the room. I asked God if He would be  with my mom in case anything happened to me and just to calm her nerves  out there. Woke up, played a bit of a prank on my mom. I don’t know if  you’ve heard about it?        

Lex Fridman: 07:08:24: Yeah, I read about it.        

Noland Arbaugh: 07:08:25: Yeah, she was not happy.        

Lex Fridman: 07:08:28: Can you take me through the prank?        

Noland Arbaugh: 07:08:29: Yeah. This is something-        

Lex Fridman: 07:08:31: Do you regret doing that now?        

Noland Arbaugh: 07:08:31: … No, no, not one bit. It was  something I had talked about ahead of time with my buddy Bane. I was  like, “I would really like to play a prank on my mom.” Very  specifically, my mom. She’s very gullible. I think she had knee surgery  once even, and after she came out of knee surgery, she was super groggy. She’s like, “I can’t feel my legs.” And my dad looked at her. He was  like, “You don’t have any legs. They had to amputate both your legs.”  And we just do very mean things to her all the time. I’m so surprised  that she still loves us.        

07:09:15: But right after surgery, I was really  worried that I was going to be too groggy, not all there. I had had  anesthesia once before and it messed me up. I could not function for a  while afterwards. And I said a lot of things that… I was really worried  that I was going to start, I don’t know, dropping some bombs and I  wouldn’t even know. I wouldn’t remember. So I was like, “Please God,  don’t let that happen, and please let me be there enough to do this to  my mom.”        

07:09:54: And so she walked in after surgery. It was the first time they had been able to see me after surgery, and she  just looked at me. She said, “Hi, how are you? How are you doing? How do you feel?” And I looked at her and this very, I think the anesthesia  helped, very groggy, sort of confused look on my face. It’s like, “Who  are you?” And she just started looking around the room at the surgeons,  at the doctors like, “What did you do to my son? You need to fix this  right now.” Tears started streaming. I saw how much she was freaking  out. I was like, “I can’t let this go on.” And so I was like, “Mom, mom, I’m fine. It’s all right.” And still, she was not happy about it. She  still says she’s going to get me back someday, but I mean, I don’t know. I don’t know what that’s going to look like.        

Lex Fridman: 07:10:44: It’s a lifelong battle, man.        

Noland Arbaugh: 07:10:46: Yeah, but it was good.        

Lex Fridman: 07:10:47: In some sense it was a demonstration that you still got… Still had a sense of humor.        

Noland Arbaugh: 07:10:52: That’s all I wanted it to be. That’s  all I wanted it to be. And I knew that doing something super mean to her like that would show her.        

Lex Fridman: 07:11:00: To show that you’re still there, that you love her.        

Noland Arbaugh: 07:11:01: Yeah, exactly. Exactly.        

Lex Fridman: 07:11:03: It’s a dark way to do it, but I love it.        

Noland Arbaugh: 07:11:05: Yeah.        

Lex Fridman: 07:11:06: What was the first time you were able to feel that you can use the Neuralink device to affect the world around you?        

Noland Arbaugh: 07:11:17: The first little taste I got of it was actually not too long after surgery. Some of the Neuralink team had  brought in a little iPad, a little tablet screen, and they had put up  eight different channels that were recording some of my neuron spikes  and they put it in front of me. They’re like, “This is real time your  brain firing.” I was like, “That’s super cool.” My first thought was, “I mean, if they’re firing now, let’s see if I can affect them in some  way.”        

07:11:51: So I started trying to wiggle my  fingers and I just started scanning through the channels, and one of the things I was doing was moving my index finger up and down, and I just  saw this yellow spike on top row, third box over or something. I saw  this yellow spike every time I did it, and I was like, “Oh, that’s  cool.” And everyone around me was just like, “What are you seeing?” I  was like, “Look at this one. Look at this top row, third box over this  yellow spike. That’s me right there, there, there.” And everyone was  freaking out. They started clapping. I was like, “That’s super  unnecessary.” This is what’s supposed to happen, right?        

Lex Fridman: 07:12:29: So you’re imagining yourself moving  each individual finger one at a time, and then seeing that you can  notice something. And then when you did the index finger, you’re like,  “Oh, cool.”        

Noland Arbaugh: 07:12:39: Yeah, I was wiggling all of my fingers to see if anything would happen. There was a lot of other things going  on, but that big yellow spike was the one that stood out to me. I’m sure that if I would’ve stared at it long enough, I could have mapped out  maybe a hundred different things. But the big yellow spike was the one  that I noticed.        

Lex Fridman: 07:13:00: Maybe you could speak to what it’s  like to wiggle your fingers, to imagine the cognitive effort required to wiggle your index finger, for example. How easy is that to do?        

Noland Arbaugh: 07:13:13: Pretty easy for me. It’s something  that at the very beginning, after my accident, they told me to try and  move my body as much as possible. Even if you can’t, just keep trying  because that’s going to create new neural pathways or pathways in my  spinal cord to reconnect these things to hopefully regain some movement  someday.        

Lex Fridman: 07:13:39: That’s fascinating.        

Noland Arbaugh: 07:13:40: Yeah, I know. It’s bizarre.        

Lex Fridman: 07:13:43: That’s part of the recovery process is to keep trying to move your body.        

Noland Arbaugh: 07:13:46: Yep. Every day as much as you can.        

Lex Fridman: 07:13:49: And the nervous system does its thing. It starts reconnecting.        

Noland Arbaugh: 07:13:52: It’ll start reconnecting for some  people, some people it never works. Some people they’ll do it. For me, I got some bicep control back, and that’s about it. If I try enough, I  can wiggle some of my fingers, not on command. It’s more like if I try  to move, say my right pinky, and I just keep trying to move it, after a  few seconds it’ll wiggle. So I know there’s stuff there. I know, and  that happens with a few different of my fingers and stuff. But yeah,  that’s what they tell you to do. One of the people at the time when I  was in the hospital came in and told me for one guy who had recovered  most of his control, what he thought about every day was actually  walking, like the act of walking just over and over again. So I tried  that for years. I tried just imagining walking, which is, it’s hard.  It’s hard to imagine all of the steps that go into, well, taking a step. All of the things that have to move, all of the activations that have  to happen along your leg in order for one step to occur.        

Lex Fridman: 07:15:09: But you’re not just imagining, you’re doing it, right?        

Noland Arbaugh: 07:15:12: I’m trying. Yeah. So it’s imagining  over again what I had to do to take a step, because it’s not something  any of us think about. We just, you want to walk and you take a step.  You don’t think about all of the different things that are going on in  your body. So I had to recreate that in my head as much as I could, and  then I practice it over, and over, and over again.        

Lex Fridman: 07:15:37: So it’s not like a third person  perspective, it’s a first person perspective. It’s not like you’re  imagining yourself walking. You’re literally doing everything, all the  same stuff as if you’re walking.        

Noland Arbaugh: 07:15:49: Yeah, which was hard. It was hard at the beginning.        

Lex Fridman: 07:15:53: Frustrating hard, or actually cognitively hard, which way?        

Noland Arbaugh: 07:15:57: It was both. There’s a scene in one of the Kill Bill movies, actually, oddly enough, where she is paralyzed, I don’t know, from a drug that was in her system. And then she finds some way to get into the back of a truck or something, and she stares at her toe and she says, “Move,” like move your big toe. And after a few  seconds on screen, she does it. And she did that with every one of her  body parts until she can move again. I did that for years, just stared  at my body and said, “Move your index finger, move your big toe.”  Sometimes vocalizing it out loud, sometimes just thinking it. I tried  every different way to do this to try to get some movement back. And  it’s hard because it actually is taxing, physically taxing on my body,  which is something I would’ve never expected.        

07:16:58: It’s not like I’m moving, but it feels like there’s a buildup of, the only way I can describe it is there are  signals that aren’t getting through from my brain down, because there’s  that gap in my spinal cord, so brain down, and then from my hand back up to the brain. And so it feels like those signals get stuck in whatever  body part that I’m trying to move, and they just build up, and build up, and build up until they burst. And then once they burst, I get this  really weird sensation of everything dissipating back out to level, and  then I do it again.        

07:17:42: It’s also just a fatigue thing, like a muscle fatigue, but without actually moving your muscles. It’s very,  very bizarre. And then if you try to stare at a body part or think about a body part and move for two, three, four, sometimes eight hours, it’s  very taxing on your mind. It takes a lot of focus. It was a lot easier  at the beginning because I wasn’t able to control a TV in my room or  anything. I wasn’t able to control any of my environment. So for the  first few years, a lot of what I was doing was staring at walls. And so, obviously I did a lot of thinking and I tried to move a lot just over,  and over, and over again.        

Lex Fridman: 07:18:33: So you never gave up hope there?        

Noland Arbaugh: 07:18:35: No.        

Lex Fridman: 07:18:35: Just training hard [inaudible 07:18:38].        

Noland Arbaugh: 07:18:37: Yeah. And I still do it. I do it  subconsciously, and I think that that helped a lot with things with  Neuralink, honestly. It’s something that I talked about the other day at the All Hands that I did at Neuralink’s Austin facility.        

Lex Fridman: 07:18:53: Welcome to Austin, by the way.        

Noland Arbaugh: 07:18:54: Yeah. Hey, thanks man. I went to school-        

Lex Fridman: 07:18:55: Nice hat.        

Noland Arbaugh: 07:18:57: … Hey, thanks. Thanks, man. The  Gigafactory was super cool. I went to school at [inaudible 07:19:01], so I’ve been around before.        

Lex Fridman: 07:19:02: So you should be saying welcome to me. Welcome to Texas, Lex.        

Noland Arbaugh: 07:19:06: Yeah.        

Lex Fridman: 07:19:07: I get you.        

Noland Arbaugh: 07:19:08: But yeah, I was talking about how a  lot of what they’ve had me do, especially at the beginning, well, I  still do it now, is body mapping. So there will be a visualization of a  hand or an arm on the screen, and I have to do that motion, and that’s  how they train the algorithm to understand what I’m trying to do. And so it made things very seamless for me I think.        

Lex Fridman: 07:19:38: That’s really, really cool. So it’s  amazing to know. I’ve learned a lot about the body mapping procedure  with the interface and everything like that. It’s cool to know that  you’ve been essentially training to be world-class at that task.        

Noland Arbaugh: 07:19:52: Yeah. Yeah. I don’t know if other  quadriplegics, other paralyzed people give up. I hope they don’t. I hope they keep trying, because I’ve heard other paralyzed people say, “Don’t ever stop.” They tell you two years, but you just never know. The human body’s capable of amazing things. So I’ve heard other people say,  “Don’t give up.” I think one girl had spoken to me through some family  members and said that she had been paralyzed for 18 years, and she’d  been trying to wiggle her index finger for all that time, and she  finally got it back 18 years later. So I know that it’s possible, and  I’ll never give up doing it. I do it when I’m lying down watching TV.  I’ll find myself doing it just almost on its own. It’s just something  I’ve gotten so used to doing that I don’t know. I don’t think I’ll ever  stop.        

Lex Fridman: 07:20:54: That’s really awesome to hear. I think it’s one of those things that can really pay off in the long term. It  is training. You’re not visibly seeing the results of that training at  the moment, but there’s that Olympic level nervous system getting ready  for something.        

Noland Arbaugh: 07:21:08: Which honestly was something that I  think Neuralink gave me that I can’t thank them enough for. I can’t show my appreciation for it enough, was being able to visually see that what I’m doing is actually having some effect. It’s a huge part of the  reason why I know now that I’m going to keep doing it forever. Because  before Neuralink, I was doing it every day and I was just assuming that  things were happening. It’s not like I knew. I wasn’t getting back any  mobility or sensation or anything. So I could have been running up  against a brick wall for all I knew. And with Neuralink, I get to see  all the signals happening real time, and I get to see that what I’m  doing can actually be mapped. When we started doing click calibrations  and stuff, when I go to click my index finger for a left click, that it  actually recognizes that. It changed how I think about what’s possible  with retraining my body to move. And so yeah, I’ll never give up now.        

Lex Fridman: 07:22:28: And also just the signal that there’s  still a powerhouse of a brain there that’s like, and as the technology  develops, that brain is, I mean, that’s the most important thing about  the human body is the brain, and it can do a lot of the control. So what did it feel like when you first could wiggle the index finger and saw  the environment respond? That little thing, whatever [inaudible  07:22:49] just being way too dramatic according to you?        

Noland Arbaugh: 07:22:51: Yeah, it was very cool. I mean, it was cool, but I keep telling this to people. It made sense to me. It made  sense that there are signals still happening in my brain, and that as  long as you had something near it that could measure those, that could  record those, then you should be able to visualize it in some way. See  it happen. And so that was not very surprising to me. I was just like,  “Oh, cool. We found one, we found something that works.”        

07:23:23: It was cool to see that their  technology worked and that everything that they had worked so hard for  was going to pay off. But I hadn’t moved a cursor or anything at that  point. I hadn’t interacted with a computer or anything at that point. So it just made sense. It was cool. I didn’t really know much about BCI at that point either, so I didn’t know what sort of step this was actually making. I didn’t know if this was a huge deal, or if this was just  like, “Okay, this is, it’s cool that we got this far, but we’re actually hoping for something much better down the road.” It’s like, “Okay.” I  just thought that they knew that it turned on. So I was like, “Cool,  this is cool.”        

Lex Fridman: 07:24:08: Well, did you read up on the specs of the hardware you get installed, the number of threads, all this kind of stuff.        

Noland Arbaugh: 07:24:16: Yeah, I knew all of that, but it’s all Greek to me. I was like, “Okay, 64 threads, 16 electrodes, 1,024  channels. Okay, that math checks out.”        

Lex Fridman: 07:24:30: Sounds right.        

## Moving mouse with brain

Noland Arbaugh: 07:24:31: Yeah.        

Lex Fridman: 07:24:32: When was the first time you were able to move a mouse cursor?        

Noland Arbaugh: 07:24:34: I know it must have been within the  first maybe week, a week or two weeks that I was able to first move the  cursor. And again, it kind of made sense to me. It didn’t seem like that big of a deal. It was like, okay, well, how do I explain this? When  everyone around you starts clapping for something that you’ve done, it’s easy to say, “Okay, I did something cool.”        

07:25:04: That was impressive in some way. What  exactly that meant, what it was hadn’t really set in for me. So again, I knew that me trying to move a body part and then that being mapped in  some sort of machine learning algorithm to be able to identify my brain  signals and then take that and give me cursor control, that all kind of  made sense to me. I don’t know all the ins and outs of it, but I was  like, “There are still signals in my brain firing. They just can’t get  through because there’s a gap in my spinal cord, and so they can’t get  all the way down and back up, but they’re still there.” So when I moved  the cursor for the first time, I was like, “That’s cool, but I expected  that that should happen.” It made sense to me. When I moved the cursor  for the first time with just my mind, without physically trying to move. So I guess I can get into that just a little bit. The difference  between attempted movement, and imagine movement.        

Lex Fridman: 07:26:16: Yeah, that’s a fascinating difference [inaudible 07:26:18] from one to the other.        

Noland Arbaugh: 07:26:19: Yeah, yeah, yeah. So attempted  movement is me physically trying to attempt to move, say my hand. I try  to attempt to move my hand to the right, to the left, forward and back.  And that’s all attempted. Attempt to lift my finger up and down, attempt to kick or something. I’m physically trying to do all of those things,  even if you can’t see it. This would be me attempting to shrug my  shoulders or something. That’s all attempted movement. That’s what I was doing for the first couple of weeks when they were going to give me  cursor control. When I was doing body mapping, it was attempt to do  this, attempt to do that. When Nir was telling me to imagine doing it,  it kind of made sense to me, but it’s not something that people  practice. If you started school as a child and they said, “Okay, write  your name with this pencil,” and so you do that. Like, “Okay, now  imagine writing your name with that pencil.”        

07:27:33: Kids would think, “Uh, I guess that  kind of makes sense,” and they would do it. But that’s not something  we’re taught, it’s all how to do things physically. We think about  thought experiments and things, but that’s not a physical action of  doing things. It’s more what you would do in certain situations. So  imagine movement, it never really connected with me. I guess you could  maybe describe it as a professional athlete swinging a baseball bat or  swinging a golf club. Imagine what you’re supposed to do. But then you  go right to that and physically do it. Then you get a bat in your hand,  and then you do what you’ve been imagining.        

07:28:15: And so I don’t have that connection.  So telling me to imagine something versus attempting it, there wasn’t a  lot that I could do there mentally. I just kind of had to accept what  was going on and try. But the attempted moving thing, it all made sense  to me. If I try to move, then there’s a signal being sent in my brain,  and as long as they can pick that up, then they should be able to map it to what I’m trying to do. And so when I first moved the cursor like  that, it was just like, “Yes, this should happen. I’m not surprised by  that.”        

Lex Fridman: 07:28:50: But can you clarify, is there supposed to be a difference between imagine movement and attempted movement?        

Noland Arbaugh: 07:28:55: Yeah, just that in imagine movement, you’re not attempting to move at all. So it’s-        

Lex Fridman: 07:29:00: You’re visualizing what you’re doing.        

Noland Arbaugh: 07:29:01: … Visualizing.        

Lex Fridman: 07:29:03: … And then theoretically, is that supposed to be a different part of the brain that lights up in those two different situations?        

Bliss Chapman: 07:29:09: Yeah, not necessarily. I think all  these signals can still be represented in motor cortex, but the  difference I think, has to do with the naturalness of imagining  something versus-        

Lex Fridman: 07:29:09: Got it.        

Bliss Chapman: 07:29:18: … attempting it. The fatigue of that over time.        

Lex Fridman: 07:29:20: And by the way, on the mic is Bliss.  So this is just different ways to prompt you to kind of get to the thing that you arrived at.        

Noland Arbaugh: 07:29:31: Yeah, yeah.        

Lex Fridman: 07:29:31: Attempted movement does sound like the right thing. Try.        

Noland Arbaugh: 07:29:35: Yeah. I mean, it makes sense to me.        

Lex Fridman: 07:29:37: Because imagine, for me, I would start visualizing, in my mind, visualizing. Attempted I would actually start  trying to… I did combat sports my whole life, like wrestling. When I’m  imagining a move, see, I’m moving my muscle.        

Noland Arbaugh: 07:29:54: Exactly.        

Lex Fridman: 07:29:55: There is a bit of an activation almost versus visualizing yourself, like a picture doing it.        

Noland Arbaugh: 07:30:01: Yeah. It’s something that I feel like  naturally anyone would do. If you try to tell someone to imagine doing  something, they might close their eyes and then start physically doing  it, but it just-        

Lex Fridman: 07:30:13: Just didn’t click.        

Noland Arbaugh: 07:30:14: … Yeah, it’s hard. It was very hard at the beginning.        

Lex Fridman: 07:30:18: But attempted worked.        

Noland Arbaugh: 07:30:20: Attempted worked. It worked just like it should. Worked like a charm.        

Bliss Chapman: 07:30:26: Remember there was one Tuesday we were messing around and I think, I forget what swear word you used, but  there’s a swear word that came out of your mouth when you figured out  you could just do the direct cursor control.        

Noland Arbaugh: 07:30:35: Yeah, it blew my mind, no pun  intended. Blew my mind when I first moved the cursor just with my  thoughts and not attempting to move. It’s something that I found over  the couple of weeks building up to that, that as I get better cursor  controls, the model gets better, then it gets easier for me to… I don’t  have to attempt as much to move it. And part of that is something that  I’d even talked with them about when I was watching the signals of my  brain one day. I was watching when I attempted to move to the right and I watched the screen as I saw the spikes. I was seeing the spike, the  signal was being sent before I was actually attempting to move. I  imagine just because when you go to say, move your hand or any body  part, that signal gets sent before you’re actually moving, has to make  it all the way down and back up before you actually do any sort of  movement.        

07:31:51: So there’s a delay there. And I  noticed that there was something going on in my brain before I was  actually attempting to move that my brain was anticipating what I wanted to do, and that all started sort of, I don’t know, percolating in my  brain. It was just there always in the back like, “That’s so weird that  it could do that. It kind of makes sense, but I wonder what that means  as far as using the Neuralink.”        

07:32:29: And then as I was playing around with  the attempted movement and playing around with the cursor, and I saw  that as the cursor control got better, that it was anticipating my  movements and what I wanted it to do, like cursor movements, what I  wanted it to do a bit better and a bit better. And then one day I just  randomly, as I was playing Webgrid, I looked at a target before I had  started attempting to move, I was just trying to get over, train my eyes to start looking ahead, like, “Okay, this is the target I’m on, but if I look over here to this target, I know I can maybe be a bit quicker  getting there.”        

07:33:12: And I looked over and the cursor just  shot over. It was wild. I had to take a step back. I was like, “This  should not be happening.” All day I was just smiling. I was so giddy. I  was like, “Guys, do you know that this works? I can just think it and it happens.” Which they’d all been saying this entire time like, “I can’t  believe you’re doing all this with your mind.” I’m like, “Yeah, but is  it really with my mind. I’m attempting to move and it’s just picking  that up so it doesn’t feel like it’s with my mind.” But when I moved it  for the first time like that, it was, oh man. It made me think that this technology, that what I’m doing is actually way, way more impressive  than I ever thought. It was way cooler than I ever thought, and it just  opened up a whole new world of possibilities of what could possibly  happen with this technology and what I might be able to be capable of  with it.        

Lex Fridman: 07:34:08: Because you had felt for the first time like this was digital telepathy. You’re controlling a digital device with your mind.        

Noland Arbaugh: 07:34:15: Yep.        

Lex Fridman: 07:34:16: I mean, that’s a real moment of  discovery. That’s really cool. You’ve discovered something. I’ve seen  scientists talk about a big aha moment, like Nobel Prize winning.  They’ll have this like, “Holy crap.” Like, “Whoa.”        

Noland Arbaugh: 07:34:31: That’s what it felt like. I felt like I had discovered something, but for me, maybe not necessarily for the  world-at-large or this field-at-large, it just felt like an aha moment  for me. Like, “Oh, this works.” Obviously it works. And so that’s what I do all the time now. I kind of intermix the attempted movement and  imagine movement. I do it all together because I’ve found that…        

Noland Arbaugh: 07:35:00: I do it all together because I’ve  found that there is some interplay with it that maximizes efficiency  with the cursor. So it’s not all one or the other. It’s not all just, I  only use attempted or I only use imagined movements. It’s more I use  them in parallel and I can do one or the other. I can just completely  think about whatever I’m doing, but I don’t know, I like to play around  with it. I also like to just experiment with these things. Every now and again, I’ll get this idea in my head, I wonder if this works and I’ll  just start doing it, and then afterwards I’ll tell them, “By the way, I  wasn’t doing that like you guys wanted me to. I thought of something and I wanted to try it and so I did. It seems like it works, so maybe we  should explore that a little bit.”        

Lex Fridman: 07:35:51: So I think that discovery’s not just  for you, at least from my perspective. That’s a discovery for everyone  else who ever uses a Neuralink that this is possible. I don’t think  that’s an obvious thing that this is even possible. It’s like I was  saying to Bliss earlier, it’s like the four-minute mile. People thought  it was impossible to run a mile in four minutes and once the first  person did it, then everyone just started doing it. So just to show that it’s possible, that paves the way to anyone can now do it. That’s the  thing that’s actually possible. You don’t need to do the attempted  movement, you can just go direct.        

Noland Arbaugh: 07:36:25: Yeah. Yeah.        

Lex Fridman: 07:36:26: That’s crazy.        

Noland Arbaugh: 07:36:27: It is crazy. It is crazy, yeah.        

Lex Fridman: 07:36:30: For people who don’t know, can you  explain how the Link app works? You have an amazing stream on the topic. Your first stream, I think, on X describing, the app. Can you just  describe how it works?        

Noland Arbaugh: 07:36:43: Yeah, so it’s just an app that  Neuralink created to help me interact with the computer. So on the Link  app there are a few different settings, and different modes, and things I can do on it. So there’s the body mapping, which we kind of touched on. There’s a calibration. Calibration is how I actually get cursor  control, so calibrating what’s going on in my brain to translate that  into cursor control. So it will pop out models. What they use, I think,  is time. So it would be five minutes and calibration will give me so  good of a model, and then if I’m in it for 10 minutes and 15 minutes,  the models will progressively get better. And so the longer I’m in it,  generally, the better the models will get.        

Lex Fridman: 07:37:43: That’s really cool because you often  refer to the models. So the model’s the thing that’s constructed once  you go through the calibration step.        

Noland Arbaugh: 07:37:43: Yeah.        

Lex Fridman: 07:37:49: And then you also talked about sometimes you’ll play a really difficult game like Snake just to see how good the model is.        

Noland Arbaugh: 07:37:56: Yeah. Yeah, so Snake is kind of like  my litmus test for models. If I can control a snake decently well then I know I have a pretty good model. So yeah, the Link app has all of  those. It has Webgrid in it now. It’s also how I connect to the computer just in general. So they’ve given me a lot of voice controls with it at this point. So I can say, “Connect,” or, “Implant disconnect,” and as  long as I have that charger handy, then I can connect to it. So the  charger is also how I connect to the Link app to connect to the  computer. I have to have the implant charger over my head when I want to connect, to have it wake up, because the implant’s in hibernation mode  always when I’m not using it. I think there’s a setting to wake it up  every so long, so we could set it to half an hour, or five hours, or  something, if I just want it to wake up periodically.        

07:38:56: So yeah, I’ll connect to the Link app  and then go through all sorts of things, calibration for the day, maybe  body mapping. I made them give me a little homework tab because I am  very forgetful and I forget to do things a lot. So I have a lot of data  collection things that they want me to do.        

Lex Fridman: 07:39:18: Is the body mapping part of the data collection or is that also part of the calibration?        

Noland Arbaugh: 07:39:21: Yeah, it is. It’s something that they  want me to do daily, which I’ve been slacking on because I’ve been doing so much media and traveling so much. So I’ve been [inaudible 07:39:30]-        

Lex Fridman: 07:39:30: You’ve gotten super famous.        

Noland Arbaugh: 07:39:31: Yeah, I’ve been a terrible first  candidate for how much I’ve been slacking on my homework. But yeah, it’s just something that they want me to do every day to track how well the  Neuralink is performing over time and to have something to give, I  imagine, to give to the FDA to create all sorts of fancy charts and  stuff, and show like, hey, this is what the Neuralink… This is how it’s  performing day one, versus day 90, versus day 180, and things like that.        

Lex Fridman: 07:40:02: What’s the calibration step like? Is it move left, move right?        

Noland Arbaugh: 07:40:06: It’s a bubble game. So there will be  yellow bubbles that pop up on the screen. At first, it is open loop. So  open loop, this is something that I still don’t fully understand, the  open loop and closed loop thing.        

Lex Fridman: 07:40:21: The me and Bliss talked for a long time about the difference between the two on the technical side.        

Noland Arbaugh: 07:40:21: Okay, yeah.        

Lex Fridman: 07:40:25: So it’d be great to hear your-        

Noland Arbaugh: 07:40:25: Okay, so open-        

Lex Fridman: 07:40:27: … your side of the story.        

Noland Arbaugh: 07:40:29: Open loop is basically I have no  control over the cursor. The cursor will be moving on its own across the screen and I am following, by intention, the cursor to different  bubbles. And then the algorithm is training off of what the signals it’s getting are as I’m doing this. There are a couple of different ways  that they’ve done it. They call it center-out targets. So there will be a bubble in the middle and then eight bubbles around that, and the cursor will go from the middle to one side. So say, middle to left, back to  middle, to up, to middle, up, right, and they’ll do that all the way  around the circle. And I will follow that cursor the whole time, and  then it will train off of my intentions, what it is expecting my  intentions to be throughout the whole process.        

Lex Fridman: 07:41:22: Can you actually speak to, when you say follow-        

Noland Arbaugh: 07:41:25: Yes.        

Lex Fridman: 07:41:25: … you don’t mean with your eyes, you mean with your intentions?        

Noland Arbaugh: 07:41:28: Yeah, so generally for calibration,  I’m doing attempted movements because I think it works better. I think  the better models, as I progress through calibration, make it easier to  use imagined movements.        

Lex Fridman: 07:41:45: Wait. Wait, wait, wait. So calibrated  on attempted movement will create a model that makes it really effective for you to then use the force.        

Noland Arbaugh: 07:41:55: Yes. I’ve tried doing calibration with imagined movement and it just doesn’t work as well for some reason. So  that was the center-out targets. There’s also one where a random target  will pop up on the screen and it’s the same. I just move, I follow along wherever the cursor is, to that target all across the screen. I’ve  tried those with imagined movement and for some reason the models just  don’t, they don’t give as high level as quality when we get into closed  loop. I haven’t played around with it a ton, so maybe the different ways that we’re doing calibration now might make it a bit better. But what  I’ve found is there will be a point in calibration where I can use  imagined movement. Before that point, it doesn’t really work.        

07:42:53: So if I do calibration for 45 minutes, the first 15 minutes, I can’t use imagined movement. It just doesn’t  work for some reason. And after a certain point, I can just feel it, I  can tell. It moves different. That’s the best way I can describe it.  It’s almost as if it is anticipating what I am going to do again, before I go to do it. And so using attempted movement for 15 minutes, at some  point, I can tell when I move my eyes to the next target that the cursor is starting to pick up. It’s starting to understand, it’s learning what I’m going to do.        

Lex Fridman: 07:43:41: So first of all, it’s really cool  that, you are a true pioneer in all of this. You’re exploring how to do  every aspect of this most effectively and there’s just, I imagine, so  many lessons learned from this. So thank you for being a pioneer in all  these kinds of different super technical ways. And it’s also cool to  hear that there’s a different feeling to the experience when it’s  calibrated in different ways because I imagine your brain is doing  something different and that’s why there’s a different feeling to it.  And then trying to find the words and the measurements to those feelings would be also interesting. But at the end of the day, you can also  measure your actual performance, on whether it’s Snake or Webgrid, you  could see what actually works well. And you’re saying, for the open loop calibration, the attempted movement works best for now.        

Noland Arbaugh: 07:44:35: Yep. Yep.        

Lex Fridman: 07:44:36: So the open loop, you don’t get the feedback that you did something.        

Noland Arbaugh: 07:44:41: Yeah. I just-        

Lex Fridman: 07:44:42: Is that frustrating? [inaudible 07:44:43]-        

Noland Arbaugh: 07:44:43: No, no, it makes sense to me. We’ve  done it with a cursor and without a cursor in open loop. So sometimes  it’s just, say for the center out, you’ll start calibration with a  bubble lighting up and I push towards that bubble, and then when it’s  pushed towards that bubble for, say, three seconds, a bubble will pop  and then I come back to the middle. So I’m doing it all just by my  intentions. That’s what it’s learning anyway. So it makes sense that as  long as I follow what they want me to do, follow the yellow brick road,  that it’ll all work out.        

Lex Fridman: 07:45:22: You’re full of great references. Is the bubble game fun?        

Noland Arbaugh: 07:45:26: Yeah, they always feel so bad making  me do calibration like, oh, we’re about to do a 40-minute calibration.  I’m like, “All right, do you guys want to do two of them?” I’m always  asking to… Whatever they need, I’m more than happy to do. And it’s not  bad. I get to lie there or sit in my chair and do these things with some great people. I get to have great conversations. I can give them  feedback. I can talk about all sorts of things. I could throw something  on, on my TV in the background, and split my attention between them.  It’s not bad at all. I don’t mind it.        

Lex Fridman: 07:46:06: Is there a score that you get?        

Noland Arbaugh: 07:46:06: No.        

Lex Fridman: 07:46:07: Can you do better on a bubble game?        

Noland Arbaugh: 07:46:08: No, I would love that.        

Lex Fridman: 07:46:09: Yeah.        

Noland Arbaugh: 07:46:12: Yeah, I would love a-        

Lex Fridman: 07:46:13: Writing down suggestions from Noland.        

Noland Arbaugh: 07:46:17: That-        

Lex Fridman: 07:46:18: Make it more fun, gamified.        

Noland Arbaugh: 07:46:20: Yeah, that’s one thing that I really,  really enjoy about Webgrid is because I’m so competitive. The higher the BPS, the higher the score, I know the better I’m doing, and so if I… I  think I’ve asked at one point, one of the guys, if he could give me some sort of numerical feedback for calibration. I would like to know what  they’re looking at. Like, oh, we see this number while you’re doing  calibration, and that means, at least on our end, that we think  calibration is going well. And I would love that because I would like to know if what I’m doing is going well or not. But then they’ve also told me, yeah, not necessarily one to one. It doesn’t actually mean that  calibration is going well in some ways. So it’s not like a hundred  percent and they don’t want to skew what I’m experiencing or want me to  change things based on that, if that number isn’t always accurate to how the model will turn out or the end result,. That’s at least what I got  from it.        

07:47:19: One thing I have asked them, and  something that I really enjoy striving for, is towards the end of  calibration, there is a time between targets. And so I like to keep, at  the end, that number as low as possible. So at the beginning it can be  four or five, six seconds between me popping bubbles, but towards the  end I like to keep it below 1.5 or if I could get it to one second  between bubbles. Because in my mind, that translates really nicely to  something like Webgrid, where I know if I can hit a target, one every  second, that I’m doing real, real well.        

Lex Fridman: 07:47:58: There you go. That’s a way to get a score on the calibrations, like the speed. How quickly can you get from bubble to bubble?        

Noland Arbaugh: 07:48:03: Yeah.        

Lex Fridman: 07:48:05: So there’s the open loop and then it goes to the closed loop.        

Noland Arbaugh: 07:48:05: Closed loop.        

Lex Fridman: 07:48:08: And the closed loop can already start giving you a sense because you’re getting feedback of how good the model is.        

Noland Arbaugh: 07:48:13: Yeah. Yeah. So closed loop is when I  first get cursor control, and how they’ve described it to me, someone  who does not understand this stuff, I am the dumbest person in the room  every time I’m with any of those guys.        

Lex Fridman: 07:48:13: I love the humility. I appreciate it.        

Noland Arbaugh: 07:48:27: Yeah, is that I am closing the loop.  So I am actually now the one that is finishing the loop of whatever this loop is. I don’t even know what the loop is. They’ve never told me.  They just say there is a loop and at one point it’s open and I can’t  control, and then I get control and it’s closed. So I’m finishing the  loop.        

Lex Fridman: 07:48:48: So how long the calibration usually take? You said 10, 15 minutes, [inaudible 07:48:52]-        

Noland Arbaugh: 07:48:52: Well, yeah, they’re trying to get that number down pretty low. That’s what we’ve been working on a lot  recently, is getting that down is low as possible. So that way, if this  is something that people need to do on a daily basis or if some people  need to do on a every-other-day basis or once a week, they don’t want  people to be sitting in calibration for long periods of time. I think  they’ve wanted to get it down seven minutes or below, at least where  we’re at right now. It’d be nice if you never had to do calibration. So  we’ll get there at some point, I’m sure, the more we learn about the  brain, and I think that’s the dream. I think right now, for me to get  really, really good models, I’m in calibration 40 or 45 minutes. And I  don’t mind, like I said, they always feel really bad, but if it’s going  to get me a model that can break these records on Webgrid, I’ll stay in  it for flipping two hours.        

## Webgrid

Lex Fridman: 07:49:50: Let’s talk business. So Webgrid, I saw a presentation where Bliss said by March you selected 89,000 targets in Webgrid. Can you explain this game? What is Webgrid and what does it  take to be a world-class performer in Webgrid, as you continue to break  world records?        

Noland Arbaugh: 07:50:09: Yeah.        

Lex Fridman: 07:50:10: It’s like a gold medalist talk. Well, where do I begin?        

Noland Arbaugh: 07:50:15: Yeah, I’d like thank-        

Lex Fridman: 07:50:18: Yeah, exactly.        

Noland Arbaugh: 07:50:18: … everyone who’s helped me get here,  my coaches, my parents, for driving me to practice every day at 5:00 in  the morning. I like to thank God and just overall my dedication to my  craft. [inaudible 07:50:29].        

Lex Fridman: 07:50:29: Yeah, the interviews with athletes, they’re always like that exact-        

Noland Arbaugh: 07:50:29: Yeah.        

Lex Fridman: 07:50:29: It’s that template.        

Noland Arbaugh: 07:50:34: Yeah, so-        

Lex Fridman: 07:50:37: So Webgrid, is a-        

Noland Arbaugh: 07:50:37: Webgrid is a-        

Lex Fridman: 07:50:37: … grid of cells.        

Noland Arbaugh: 07:50:41: Yeah, it’s literally just a grid. They can make it as big or small as you can make a grid. A single box on  that grid will light up and you go and click it. And it is a way for  them to benchmark how good a BCI is. So it’s pretty straightforward. You just click targets.        

Lex Fridman: 07:51:01: Only one blue cell appears and you’re supposed to move the mouse to there and click on it.        

Noland Arbaugh: 07:51:06: Yep. So I like playing on bigger grids because the bigger the grid, the more BPS, it’s bits per second, that  you get every time you click one. So I’ll say I’ll play on a 35 by 35  grid, and then one of those little squares, a cell, you can call it,  target, whatever, will light up. And you move the cursor there, and you  click it, and then you do that forever.        

Lex Fridman: 07:51:34: And you’ve been able to achieve, at first, eight bits per second, then you’ve recently broke that.        

Noland Arbaugh: 07:51:40: Yeah. Yeah, I’m at 8.5 right now. I  would’ve beaten that literally the day before I came to Austin. But I  had a, I don’t know, a five-second lag right at the end, and I just had  to wait until the latency calmed down, and then I kept clicking. But I  was at 8.01, and then five seconds of lag, and then the next three  targets I clicked all stayed at 8.01. So if I would’ve been able to  click during that time of lag, I probably would’ve hit, I don’t know, I  might’ve hit nine. So I’m there. I’m really close, and then this whole  Austin trip has really gotten in the way of my Webgrid playing ability.        

Lex Fridman: 07:52:25: It’s frustrating.        

Noland Arbaugh: 07:52:25: Yeah, it’s-        

Lex Fridman: 07:52:25: So that’s all-        

Noland Arbaugh: 07:52:26: I’ve been itching.        

Lex Fridman: 07:52:26: … you’ve thinking about right now?        

Noland Arbaugh: 07:52:26: Yeah, I know. I just want to do better.        

Lex Fridman: 07:52:28: At nine.        

Noland Arbaugh: 07:52:28: I want to do better. I want to hit  nine, I think, well, I know nine is very, very achievable. I’m right  there. I think 10 I could hit, maybe in the next month. I could do it  probably in the next few weeks if I really push.        

Lex Fridman: 07:52:41: I think you and Elon are basically the same person because last time I did a podcast with him, he came in  extremely frustrated that he can’t beat Uber Lilith as a Druid.        

Noland Arbaugh: 07:52:51: [inaudible 07:52:51].        

Lex Fridman: 07:52:50: That was a year ago, I think, I  forget, solo. And I could just tell there’s some percentage of his  brain, the entire time was thinking, “I wish I was right now  attempting.” [inaudible 07:53:01]-        

Noland Arbaugh: 07:53:01: Yeah. I think he did it that night.        

Lex Fridman: 07:53:06: He did it that night. He stayed up and did it that night, which is crazy to me. In a fundamental way, it’s  really inspiring and what you’re doing is inspiring in that way because  it’s not just about the game. Everything you’re doing there has impact.  By striving to do well on Webgrid, you’re helping everybody figure out  how to create the system all along the decoding, the software, the  hardware, the calibration, all of it. How to make all of that work so  you can do everything else really well.        

Noland Arbaugh: 07:53:36: Yeah, it’s just really fun.        

Lex Fridman: 07:53:38: Well, that’s also, that’s part of the thing, is that making it fun.        

Noland Arbaugh: 07:53:42: Yeah, it’s a addicting. I’ve joked  about what they actually did when they went in and put this thing in my  brain. They must’ve flipped a switch to make me more susceptible to  these kinds of games, to make me addicted to Webgrid or something.        

Lex Fridman: 07:53:58: Yeah.        

Noland Arbaugh: 07:53:59: Do you know Bliss’s high score?        

Lex Fridman: 07:54:00: Yeah, he said like 14 or something.        

Noland Arbaugh: 07:54:02: 17.        

Lex Fridman: 07:54:03: Oh, boy.        

Noland Arbaugh: 07:54:04: 17.1 or something. 17.01?        

Bliss Chapman: 07:54:04: 17 on the dot.        

Noland Arbaugh: 07:54:04: 17-        

Bliss Chapman: 07:54:04: 17.01.        

Noland Arbaugh: 07:54:04: Yeah.        

Lex Fridman: 07:54:09: He told me he does it on the floor  with peanut butter and he fasts. It’s weird. That sounds like cheating.  Sounds like performance enhancing-        

Bliss Chapman: 07:54:17: Noland, the first time Noland played  this game, he asked how good are we at this game? And I think you told  me right then, you’re going to try to beat me [inaudible 07:54:24]-        

Noland Arbaugh: 07:54:24: I’m going to get there someday.        

Bliss Chapman: 07:54:24: Yeah, I fully believe you.        

Noland Arbaugh: 07:54:26: I think I can. I think I can. I think-        

Bliss Chapman: 07:54:27: I’m excited for that.        

Noland Arbaugh: 07:54:28: Yeah. So I’ve been playing, first off, with the dwell cursor, which really hampers my Webgrid playing ability. Basically I have to wait 0.3 seconds for every click.        

Lex Fridman: 07:54:40: Oh, so you can’t do the click. So you click by dwelling, you said 0.3.        

Noland Arbaugh: 07:54:45: 0.3 seconds, which sucks. It really  slows down how high I’m able to get. I still hit 50, I think I hit  50-something net trials per minute in that, which was pretty good  because I’m able to… One of the settings is also how slow you need to be moving in order to initiate a click, to start a click. So I can tell,  sort of, when I’m on that threshold, to start initiating a click just a  bit early. So I’m not fully stopped over the target when I go to click,  I’m doing it on my way to the targets a little, to try to time it just  right.        

Lex Fridman: 07:55:29: Oh, wow.        

Noland Arbaugh: 07:55:30: Yeah.        

Lex Fridman: 07:55:30: So you’re slowing down.        

Noland Arbaugh: 07:55:31: Yeah, just a hair, right before the targets.        

Lex Fridman: 07:55:34: This is like elite performance. Okay, but that’s still, it sucks that there’s a ceiling of the 0.3.        

Noland Arbaugh: 07:55:41: Well, I can get down to 0.2 and 0.1. 0.1’s what I’ve-        

Lex Fridman: 07:55:45: [inaudible 07:55:45].        

Noland Arbaugh: 07:55:45: Yeah, and I’ve played with that a  little bit too. I have to adjust a ton of different parameters in order  to play with 0.1, and I don’t have control over all of that on my end  yet. It also changes how the models are trained. If I train a model,  like in Webgrid, I bootstrap on a model, which basically is them  training models as I’m playing Webgrid based off of the Webgrid data  that I’m… So if I play Webgrid for 10 minutes, they can train off that  data specifically in order to get me a better model. If I do that with  0.3 versus 0.1, the models come out different. The way that they  interact, it’s just much, much different. So I have to be really  careful. I found that doing it with 0.3 is actually better in some ways. Unless I can do it with 0.1 and change all of the different parameters, then that’s more ideal, because obviously 0.3 is faster than 0.1. So I  could get there. I can get there.        

Lex Fridman: 07:56:43: Can you click using your brain?        

Noland Arbaugh: 07:56:45: For right now, it’s the hover clicking with the dwell cursor. Before all the thread retraction stuff happened, we were calibrating clicks, left click, right click. That was my  previous ceiling, before I broke the record again with the dwell cursor, was I think on a 35 by 35 grid with left and right click. And you get  more BPS, more bits per second, using multiple clicks because it’s more  difficult.        

Lex Fridman: 07:57:12: Oh, because what is it, you’re supposed to do either a left click or a right click?        

Noland Arbaugh: 07:57:17: Yes.        

Lex Fridman: 07:57:18: Is a different colors, something like this?        

Noland Arbaugh: 07:57:18: Different colors.        

Lex Fridman: 07:57:18: Cool. Cool.        

Noland Arbaugh: 07:57:19: Yeah, blue targets for left click, orange targets for right click is what they had done.        

Lex Fridman: 07:57:23: Got it.        

Noland Arbaugh: 07:57:23: So my previous record of 7.5-        

Lex Fridman: 07:57:26: Was with the two clicks.        

Noland Arbaugh: 07:57:27: … was with the blue and the orange  targets, yeah, which I think if I went back to that now, doing the click calibration, I would be able to… And being able to initiate clicks on  my own, I think I would break that 10 ceiling in a couple days, max.        

Lex Fridman: 07:57:43: Yeah, you would start making Bliss nervous about his 17.        

Noland Arbaugh: 07:57:46: Yeah, he should be.        

Bliss Chapman: 07:57:47: Why do you think we haven’t given him the-        

Noland Arbaugh: 07:57:48: Yeah.        

## Retracted threads

Lex Fridman: 07:57:49: Exactly. Exactly. So what did it feel like with the retractions, that some of the threads are retracted?        

Noland Arbaugh: 07:57:57: It sucked. It was really, really hard. The day they told me was the day of my big Neuralink tour at their  Fremont facility. They told me right before we went over there. It was  really hard to hear. My initial reaction was, all right, go in, fix it.  Go in, take it out and fix it. The first surgery was so easy. I went to  sleep, a couple hours later I woke up and here we are. I didn’t feel any pain, didn’t take any pain pills or anything. So I just knew that if  they wanted to, they could go in and put in a new one next day if that’s what it took because I wanted it to be better and I wanted not to lose  the capability. I had so much fun playing with it for a few weeks, for a month. It had opened up so many doors for me. It had opened up so many  more possibilities that I didn’t want to lose it after a month.        

07:58:58: I thought it would’ve been a cruel  twist of fate if I had gotten to see the view from the top of this  mountain and then have it all come crashing down after a month. And I  knew, I say the top of the mountain, but how I saw it was I was just now starting to climb the mountain and there was so much more that I knew  was possible. And so to have all of that be taken away was really,  really hard. But then on the drive over to the facility, I don’t know,  five minute drive, whatever it is, I talked with my parents about it. I  prayed about it. I was just like, I’m not going to let this ruin my day. I’m not going to let this ruin this amazing tour that they have set up  for me. I want to go show everyone how much I appreciate all the work  they’re doing.        

07:59:54: I want to go meet all of the people  who have made this possible, and I want to go have one of the best days  of my life, and I did. And it was amazing, and it absolutely was one of  the best days I’ve ever been privileged to experience. And then for a  few days I was pretty down in the dumps, but for the first few days  afterwards, I didn’t know if it was ever going to work again. And then I made the decision that, even if I lost the ability to use the  Neuralink, even if I lost out on everything to come, if I could keep  giving them data in any way, then I would do that.        

08:00:41: If I needed to just do some of the  data collection every day or body mapping every day for a year, then I  would do it because I know that everything I’m doing helps everyone to  come after me, and that’s all I wanted. Just the whole reason that I did this was to help people, and I knew that anything I could do to help, I would continue to do, even if I never got to use the cursor again, then I was just happy to be a part of it. And everything that I had done was just a perk. It was something that I got to experience, and I know how  amazing it’s going to be for everyone to come after me. So might as well just keep trucking along.        

Lex Fridman: 08:01:22: Well, that said, you were able to get  to work your way up, to get the performance back. So this is like going  from Rocky I to Rocky II. So when did you first realize that this is  possible, and what gave you the strength, the motivation, the  determination to do it, to increase back up and beat your previous  record?        

Noland Arbaugh: 08:01:42: Yeah, it was within a couple weeks, [inaudible 08:01:44]-        

Lex Fridman: 08:01:44: Again, this feels like I’m interviewing an athlete. This is great. I’d like thank my parents.        

Noland Arbaugh: 08:01:50: The road back was long and hard-        

Lex Fridman: 08:01:53: [inaudible 08:01:53] like a movie.        

Noland Arbaugh: 08:01:53: … fraught with many difficulties.  There were dark days. It was a couple weeks, I think, and then there was just a turning point. I think they had switched how they were measuring the neuron spikes in my brain, the… Bliss help me out.        

Bliss Chapman: 08:02:15: Yeah, the way in which we were measuring the behavior of individual neurons.        

Noland Arbaugh: 08:02:18: Yeah.        

Bliss Chapman: 08:02:18: So we’re switching from individual  spike detection to something called spike band power, which if you watch the previous segments with either me or DJ, you probably have some  [inaudible 08:02:26]-        

Noland Arbaugh: 08:02:26: Yeah, okay.        

Lex Fridman: 08:02:26: Mm-hmm.        

Noland Arbaugh: 08:02:27: So when they did that, it was like a  light over the head, light bulb moment, like, oh, this works and this  seems like we can run with this. And I saw the uptick in performance  immediately. I could feel it when they switched over. I was like, “This  is better. This is good. Everything up until this point,” for the last  few weeks, last, whatever, three or four weeks because it was before  they even told me, “Everything before this sucked. Let’s keep doing what we’re doing now.” And at that point it was not like, oh, I know I’m  still only at, say in Webgrid terms, four or five BPS compared to my 7.5 before, but I know that if we keep doing this, then I can get back  there. And then they gave me the dwell cursor and the dwell cursor  sucked at first. It’s obviously not what I want, but it gave me a path  forward to be able to continue using it and hopefully to continue to  help out. And so I just ran with it, never looked back. Like I said, I’m just kind of person, I roll with the punches anyway. So-        

Lex Fridman: 08:03:37: What was the process? What was the  feedback loop on the figuring out how to do the spike detection in a way that would actually work well for Noland?        

Bliss Chapman: 08:03:45: Yeah, it’s a great question. So maybe  just to describe first how the actual update worked. It was basically an update to your implant. So we just did an over-the-air software update  to his implants, same way you’d update your Tesla or your iPhone. And  that firmware change enabled us to record averages of populations of  neurons nearby individual electrodes. So we have less resolution about  which individual neuron is doing what, but we have a broader picture of  what’s going on nearby an electrode overall. And that feedback loop,  basically as Noland described it, it was immediate when we flipped that  switch. I think the first day we did that, you had three or four BPS  right out of the box, and that was a light bulb moment for, okay, this  is the right path to go down. And from there, there’s a lot of feedback  around how to make this useful for independent use.        

08:04:27: So what we care about ultimately is  that you can use it independently to do whatever you want. And to get to that point, it required us to re-engineer the UX, as you talked about  with the dwell cursor, to make it something that you can use  independently without us needing to be involved all the time. And yeah,  this is obviously the start of this journey still. Hopefully we get back to the places where you’re doing multiple clicks and using that to  control, much more fluidly, everything, and much more naturally the  applications that you’re trying to interface with.        

Lex Fridman: 08:04:51: And most importantly, get that Webgrid number up.        

Noland Arbaugh: 08:04:55: Yep.        

Speaker 1: 08:04:55: Yes. [inaudible 08:04:57].        

Noland Arbaugh: 08:04:55: Yeah.        

Lex Fridman: 08:04:58: So how is, on the hover click, do you accidentally click stuff sometimes?        

Noland Arbaugh: 08:05:02: Yep.        

Lex Fridman: 08:05:03: How hard is it to avoid accidentally clicking?        

Noland Arbaugh: 08:05:05: I have to continuously keep it moving, basically. So like I said, there’s a threshold where it will initiate a click. So if I ever drop below that, it’ll start and I have 0.3 seconds to move it before it clicks anything.        

Lex Fridman: 08:05:21: [inaudible 08:05:21].        

Noland Arbaugh: 08:05:20: And if I don’t want it to ever get  there, I just keep it moving at a certain speed and just constantly  doing circles on screen, moving it back and forth, to keep it from  clicking stuff. I actually noticed, a couple weeks back, that when I was not using the implant, I was just moving my hand back and forth or in  circles. I was trying to keep the cursor from clicking and I was just  doing it while I was trying to go to sleep. And I was like, “Okay, this  is a problem.” [inaudible 08:05:52].        

Speaker 1: 08:05:51: [inaudible 08:05:51].        

Lex Fridman: 08:05:52: To avoid the clicking. I guess, does that create problems when you’re gaming, accidentally click a thing? Like-        

Noland Arbaugh: 08:05:58: Yeah. Yeah. It happens in chess.        

Lex Fridman: 08:06:01: Accidental, yeah.        

Noland Arbaugh: 08:06:02: I’ve lost a number of games because I’ll accidentally click something.        

Bliss Chapman: 08:06:06: I think the first time I ever beat you was because of an accidental click.        

Noland Arbaugh: 08:06:06: Yeah, a misclick. Yeah.        

Lex Fridman: 08:06:10: It’s a nice excuse, right? You can always-        

Noland Arbaugh: 08:06:12: Yeah, [inaudible 08:06:12] it’s great. It’s perfect.        

Lex Fridman: 08:06:12: … anytime you lose, you could just say, “That was accidental.”        

Noland Arbaugh: 08:06:15: Yeah. Yeah.        

## App improvements

Lex Fridman: 08:06:16: You said the app improved a lot from  version one when you first started using it. It was very different. So  can you just talk about the trial and error that you went through with  the team? 200 plus pages of notes. What’s that process like of going  back and forth and working together to improve the thing?        

Noland Arbaugh: 08:06:36: It’s a lot of me just using it day in  and day out and saying, “Hey, can you guys do this for me? Give me this. I want to be able to do that. I need this.” I think a lot of it just  doesn’t occur to them maybe, until someone is actually using the app,  using the implant. It’s just something that they just never would’ve  thought of or it’s very specific to even me, maybe what I want. It’s  something I’m a little worried about with the next people that come is  maybe they will want things much different than how I’ve set it up or  what the advice I’ve given the team, and they’re going to look at some  of the things they’ve added for me. [inaudible 08:07:26] like, “That’s a dumb idea. Why would he ask for that?” And so I’m really looking  forward to get the next people on because I guarantee that they’re going to think of things that I’ve never thought of.        

08:07:37: They’re going to think of improvements something like, wow, that’s a really good idea. I wish I would’ve  thought of that. And then they’re also going to give me some pushback  about, yeah, what you are asking them to do here, that’s a bad idea.  Let’s do it this way. And I’m more than happy to have that happen, but  it’s just a lot of different interactions with different games or  applications, the internet, just with the computer in general. There’s  tons of bugs that end up popping up, left, right, center.        

08:08:11: So it’s just me trying to use it as  much as possible and showing them what works and what doesn’t work, and  what I would like to be better. And then they take that feedback and  they usually create amazing things for me. They solve these problems in  ways I would’ve never imagined. They’re so good at everything they do,  and so I’m just really thankful that I’m able to give them feedback and  they can make something of it, because a lot of my feedback is really  dumb. It’s just like, “I want this, please do something about it,” and  it’ll come back, super well-thought-out, and it’s way better than  anything I could have ever thought of or implemented myself. So they’re  just great. They’re really, really cool.        

Lex Fridman: 08:08:53: As the BCI community grows, would you  like to hang out with the other folks with Neuralinks? What  relationship, if any, would you want to have with them? Because you said they might have a different set of ideas of how to use the thing.        

Noland Arbaugh: 08:09:10: Yeah.        

Lex Fridman: 08:09:10: Would you be intimidated by their Webgrid performance?        

Noland Arbaugh: 08:09:13: No. No. I hope-        

Lex Fridman: 08:09:14: Compete.        

Noland Arbaugh: 08:09:15: I hope, day one, they wipe the floor  with me. I hope they beat it and they crush it, double it if they can,  just because on one hand it’s only going to push me to be better because I’m super competitive. I want other people to push me. I think that is  important for anyone trying to achieve greatness is they need other  people around them who are going to push them to be better. And I even  made a joke about it on X once, once the next people get chosen, cue  buddy cop music. I’m just excited to have other people to do this with  and to share experiences with. I’m more than happy to interact with them as much as they want, more than happy to give them advice. I don’t know what kind of advice I could give them, but if they have-        

Noland Arbaugh: 08:10:00: … give them advice. I don’t know what advice I could give them, but if they have questions, I’m more than happy.        

Lex Fridman: 08:10:05: What advice would you have for the next participant in the clinical trial?        

Noland Arbaugh: 08:10:10: That they should have fun with this,  because it is a lot of fun, and that I hope they work really, really  hard because it’s not just for us, it’s for everyone that comes after  us. And come to me if they need anything. And to go to Neuralink if they need anything. Man, Neuralink moves mountains. They do absolutely  anything for me that they can, and it’s an amazing support system to  have. It puts my mind at ease for so many things that I have had  questions about or so many things I want to do, and they’re always  there, and that’s really, really nice. And so I would tell them not to  be afraid to go to Neuralink with any questions that they have, any  concerns, anything that they’re looking to do with this. And any help  that Neuralink is capable of providing, I know they will. And I don’t  know. I don’t know. Just work your ass off because it’s really important that we try to give our all to this.        

Lex Fridman: 08:11:20: So have fun and work hard.        

Noland Arbaugh: 08:11:21: Yeah. Yeah. There we go. Maybe that’s what I’ll just start saying to people. Have fun, work hard.        

Lex Fridman: 08:11:26: Now you’re a real pro athlete. Just  keep it short. Maybe it’s good to talk about what you’ve been able to do now that you have a Neurolink implant, the freedom you gain from this  way of interacting with the outside world. You play video games all  night and you do that by yourself, and that’s the freedom. Can you speak to that freedom that you gain?        

Noland Arbaugh: 08:11:53: Yeah. It’s what all… I don’t know,  people in my position want. They just want more independence. The more  load that I can take away from people around me, the better. If I’m able to interact with the world without using my family, without going  through any of my friends, needing them to help me with things, the  better. If I’m able to sit up on my computer all night and not need  someone to sit me up, say, on my iPad, in a position where I can use it, and then have to have them wait up for me all night until I’m ready to  be done using it, it takes a load off of all of us and it’s really all I can ask for. It’s something that I could never thank Neuralink enough  for, and I know my family feels the same way. Just being able to have  the freedom to do things on my own at any hour of the day or night, it  means the world to me and… I don’t know.        

## Gaming

Lex Fridman: 08:13:02: When you’re up at 2:00 AM playing  Webgrid by yourself, I just imagine it’s darkness and there’s just a  light glowing and you’re just focused. What’s going through your mind?  Or you were in a state of flow where it’s like the mind is empty like  those Zen masters.        

Noland Arbaugh: 08:13:22: Yeah. Generally, it is me playing  music of some sort. I have a massive playlist, and so I’m just rocking  out to music. And then it’s also just a race against time, because I’m  constantly looking at how much battery percentage I have left on my  implant, like, “All right. I have 30%, which equates to X amount of  time, which means I have to break this record in the next hour and a  half or else it’s not happening tonight.” And so it’s a little stressful when that happens. When it’s above 50%, I’m like, “Okay, I got time.”  It starts getting down to 30, and then 20 it’s like, “All right, 10%, a  little popup is going to pop up right here, and it’s going to really  screw my Webgrid flow. It’s going to tell me that… The low battery popup comes up and I’m like, “It’s really going to screw me over. So if I’m  going to break this record, I have to do it in the next 30 seconds,” or  else that popup is going to get in the way, cover my Webgrid.        

08:14:26: And then after that, I go click on it, go back into Webgrid, and I’m like, “All right, that means I have 10  minutes left before this thing’s dead.” That’s what’s going on in my  head, generally. That and whatever song’s playing. And I want to break  those records so bad. It’s all I want when I’m playing Webgrid. It has  become less of like, “Oh, this is just a leisurely activity. I just  enjoy doing this because it just feels so nice and it puts me at ease.”  It is, “No. Once I’m in Webgrid, you better break this record or you’re  going to waste five hours of your life right now.” And I don’t know.  It’s just fun. It’s fun, man.        

Lex Fridman: 08:15:05: Have you ever tried Webgrid with two targets and three targets? Can you get higher BPS with that?        

Noland Arbaugh: 08:15:05: Can you do that?        

Bliss Chapman: 08:15:12: You mean different colored targets or you mean-        

Lex Fridman: 08:15:14: Oh, multiple targets. Does that change the thing?        

Bliss Chapman: 08:15:16: Yeah. So BPS is a log of number of  targets times correct minus incorrect, divided by time. And so you can  think of different clicks as basically double the number of active  targets.        

Lex Fridman: 08:15:25: Got it.        

Bliss Chapman: 08:15:26: So basically higher BPS, the more  options there are, the more difficult the task. And there’s also Zen  mode you’ve played in before, which is infinite-        

Noland Arbaugh: 08:15:33: Yeah. Yeah. It covers the whole screen with a grid and… I don’t know-        

Lex Fridman: 08:15:41: And so you can go… That’s insane.        

Noland Arbaugh: 08:15:44: Yeah.        

Bliss Chapman: 08:15:45: He doesn’t like it because it didn’t show BPS, so-        

Noland Arbaugh: 08:15:49: I had them put in a giant BPS in the  background, so now it’s the opposite of Zen mode. It’s super hard mode,  just metal mode. If it’s just a giant number in the back [inaudible  08:16:01].        

Bliss Chapman: 08:16:01: We should renamed that. Metal mode is a much better [inaudible 08:16:03].        

Lex Fridman: 08:16:05: So you also play Civilization VI.        

Noland Arbaugh: 08:16:08: I love Civ VI. Yeah.        

Lex Fridman: 08:16:10: Usually go with Korea, you said?        

Noland Arbaugh: 08:16:11: I do. Yeah. So the great part about  Korea is they focus on science tech victories, which was not planned.  I’ve been playing Korea for years, and then all of the [inaudible  08:16:23] stuff happened, so it aligns. But what I’ve noticed with tech  victories is if you can just rush tech, rush science, then you can do  anything. At one point in the game, you’ll be so far ahead of everyone  technologically that you’ll have musket men, infantrymen, planes  sometimes, and people will still be fighting with bows and arrows. And  so if you want to win a domination victory, you just get to a certain  point with the science, and then go and wipe out the rest of the world.  Or you can just take science all the way and win that way, and you’re  going to be so far ahead of everyone because you’re producing so much  science that it’s not even close. I’ve accidentally won in different  ways just by focusing on science.        

Lex Fridman: 08:17:18: Accidentally won by focusing on science-        

Noland Arbaugh: 08:17:20: Yeah. I was playing only science,  obviously. Just science all the way, just tech. And I was trying to get  every tech in the tech tree and stuff, and then I accidentally won  through a diplomatic victory, and I was so mad. I was so mad because it  just ends the game one turn. It was like, “Oh, you won. You’re so  diplomatic.” I’m like, “I don’t want to do this. I should have declared  war on more people or something.” It was terrible. But you don’t need  giant civilizations with tech, especially with Korea. You can keep it  pretty small. So I generally just get to a certain military unit and put them all around my border to keep everyone out, and then I will just  build up. So very isolationist.        

Lex Fridman: 08:18:05: Nice.        

Noland Arbaugh: 08:18:06: Yeah.        

Lex Fridman: 08:18:06: Just work on the science and the tech.        

Noland Arbaugh: 08:18:07: Yep, that’s it.        

Lex Fridman: 08:18:08: You’re making it sound so fun.        

Noland Arbaugh: 08:18:10: It’s so much fun.        

Lex Fridman: 08:18:11: And I also saw a Civilization VII trailer.        

Noland Arbaugh: 08:18:13: Oh, man. I’m so pumped.        

Lex Fridman: 08:18:14: And that’s probably coming out-        

Noland Arbaugh: 08:18:16: Come on Civ VII, hit me up. All alpha, beta tests, whatever.        

Lex Fridman: 08:18:20: Wait, when is it coming out?        

Noland Arbaugh: 08:18:21: 2025.        

Lex Fridman: 08:18:22: Yeah, yeah, next year. Yeah. What  other stuff would you like to see improved about the Neuralink app and  just the entire experience?        

Noland Arbaugh: 08:18:29: I would like to, like I said, get back to the click on demand, the regular clicks. That would be great. I  would like to be able to connect to more devices. Right now, it’s just  the computer. I’d like to be able to use it on my phone or use it on  different consoles, different platforms. I’d like to be able to control  as much stuff as possible, honestly. An Optimus robot would be pretty  cool. That would be sick if I could control an Optimus robot. The Link  app itself, it seems like we are getting pretty dialed in to what it  might look like down the road. It seems like we’ve gotten through a lot  of what I want from it, at least. The only other thing I would say is  more control over all the parameters that I can tweak with my cursor and stuff. There’s a lot of things that go into how the cursor moves in  certain ways, and I have… I don’t know. Three or four of those  parameters, and there might-        

Lex Fridman: 08:19:42: Gain and friction and all that.        

Noland Arbaugh: 08:19:43: Gain and friction, yeah. And there’s  maybe double the amount of those with just velocity and then with the  actual [inaudible 08:19:51] cursor. So I would like all of it. I want as much control over my environment as possible, especially-        

Lex Fridman: 08:19:58: So you want advanced mode. There’s usually this basic mode, and you’re one of those folks, the power-user, advanced-        

Noland Arbaugh: 08:20:06: Yeah. Yeah.        

Lex Fridman: 08:20:07: Got it.        

Noland Arbaugh: 08:20:07: That’s what I want. I want as much  control over this as possible. So, yeah, that’s really all I can ask  for. Just give me everything.        

Lex Fridman: 08:20:18: Has speech been useful? Just being able to talk also in addition to everything else?        

Noland Arbaugh: 08:20:23: Yeah, you mean while I’m using it?        

Lex Fridman: 08:20:25: While you’re using it? Speech-to-text?        

Noland Arbaugh: 08:20:28: Oh, yeah.        

Lex Fridman: 08:20:28: Or do you type… Because there’s also a keyboard-        

Noland Arbaugh: 08:20:30: Yeah, yeah, yeah. So there’s a virtual keyboard. That’s another thing I would like to work more on is finding  some way to type or text in a different way. Right now, it is a  dictation basically and a virtual keyboard that I can use with the  cursor, but we’ve played around with finger spelling, sign language  finger spelling, and that seems really promising. So I have this thought in my head that it’s going to be a very similar learning curve that I  had with the cursor where I went from attempted movement to imagine  movement at one point. I have a feeling, this is just my intuition, that at some point, I’m going to be doing finger spelling and I won’t need  to actually attempt to finger spell anymore, that I’ll just be able to  think the letter that I want and it’ll pop up.        

Lex Fridman: 08:21:24: That would be epic. That’s challenging. That’s hard. That’s a lot of work for you to take that leap, but that would be awesome.        

Noland Arbaugh: 08:21:30: And then going from letters to words  is another step. Right now, it’s finger spelling of just the sign  language alphabet, but if it’s able to pick that up, then it should be  able to pick up the whole sign language language, and so then if I could do something along those lines, or just the sign language spelled word, if I can spell it at a reasonable speed and it can pick that up, then I would just be able to think that through and it would do the same  thing. After what I saw with the cursor control, I don’t see why it  wouldn’t work, but we’d have to play around with it more.        

Lex Fridman: 08:22:10: What was the process in terms of  training yourself to go from attempted movement to imagined movement?  How long did that take? So how long would this process take?        

Noland Arbaugh: 08:22:19: Well, it was a couple weeks before it  just happened upon me. But now that I know that that was possible, I  think I could make it happen with other things. I think it would be  much, much simpler.        

Lex Fridman: 08:22:32: Would you get an upgraded implant device?        

Noland Arbaugh: 08:22:34: Sure, absolutely. Whenever they’ll let me.        

Lex Fridman: 08:22:39: So you don’t have any concerns for you with the surgery experience? All of it was no regrets?        

Noland Arbaugh: 08:22:45: No.        

Lex Fridman: 08:22:46: So everything’s been good so far?        

Noland Arbaugh: 08:22:47: Yep.        

Lex Fridman: 08:22:49: You just keep getting upgrades.        

Noland Arbaugh: 08:22:50: Yeah. I mean, why not? I’ve seen how  much it’s impacted my life already, and I know that everything from here on out, it’s just going to get better and better. So I would love to  get the upgrade.        

Lex Fridman: 08:23:02: What future capabilities are you  excited about? So beyond this telepathy, is vision interesting? So for  folks, for example, who are blind, so Neuralink enabling people to see,  or for speech.        

Noland Arbaugh: 08:23:19: Yeah, there’s a lot that’s very, very  cool about this. I mean, we’re talking about the brain, so this is just  motor cortex stuff. There’s so much more that can be done. The vision  one is fascinating to me. I think that is going to be very, very cool.  To give someone the ability to see for the first time in their life  would just be… I mean, it might be more amazing than even helping  someone like me. That just sounds incredible. The speech thing is really interesting. Being able to have some real-time translation and cut away that language barrier would be really cool. Any actual impairments that it could solve with speech would be very, very cool.        

## Future Neuralink capabilities

08:24:00: And then also, there are a lot of  different disabilities that all originate in the brain, and you would be able to hopefully be able to solve a lot of those. I know there’s  already stuff to help people with seizures that can be implanted in the  brain. I imagine the same thing. And so you could do something like  that. I know that even someone like Joe Rogan has talked about the  possibilities with being able to stimulate the brain in different ways.  I’m not sure how ethical a lot of that would be. That’s beyond me,  honestly. But I know that there is a lot that can be done when we’re  talking about the brain and being able to go in and physically make  changes to help people or to improve their lives. So I’m really looking  forward to everything that comes from this. And I don’t think it’s all  that far off. I think a lot of this can be implemented within my  lifetime, assuming that I live a long life.        

Lex Fridman: 08:25:07: What you were referring to is things like people suffering from depression or things of that nature, potentially getting help.        

Noland Arbaugh: 08:25:14: Yeah, flip a switch like that, make  someone happy. I think Joe has talked about it more in terms of you want to experience what a drug trip feels like. You want to experience what  it’d be like to be on mushrooms or something like that, DMT. You can  just flip that switch in the brain. My buddy, Bain, has talked about  being able to wipe parts of your memory and re-experience things for the first time, like your favorite movie or your favorite book, just wipe  that out real quick, and then re-fall in love with Harry Potter or  something. I told him, I was like, “I don’t know how I feel about people being able to just wipe parts of your memory. That seems a little  sketchy to me.” He’s like, “They’re already doing it.”        

Lex Fridman: 08:25:59: Sounds legit. I would love memory replay. Just actually high resolution, replay of old memories.        

Noland Arbaugh: 08:26:07: Yeah. I saw an episode of Black Mirror about that once, so I don’t think I want it.        

Lex Fridman: 08:26:10: Yeah, so Black Mirror always considers the worst case, which is important. I think people don’t consider the  best case or the average case enough. I don’t know what it is about us  humans. We want to think about the worst possible thing. We love drama.  It’s like how is this new technology going to kill everybody? We just  love that. Again like, “Yes, let’s watch.”        

Noland Arbaugh: 08:26:32: Hopefully people don’t think about that too much with me. It’ll ruin a lot of my plans.        

Lex Fridman: 08:26:37: Yeah, I assume you’re going to have to take over the world. I mean, I love your Twitter. You tweeted, “I’d  like to make jokes about hearing voices in my head since getting the  Neuralink, but I feel like people would take it the wrong way. Plus the  voices in my head told me not to.”        

Noland Arbaugh: 08:26:37: Yeah.        

Lex Fridman: 08:26:37: Yeah.        

Noland Arbaugh: 08:26:52: Yeah.        

## Controlling Optimus robot

Lex Fridman: 08:26:53: Please never stop. So you were talking about Optimus. Is that something you would love to be able to do to  control the robotic arm or the entirety of Optimus?        

Noland Arbaugh: 08:27:05: Oh, yeah, for sure. For sure. Absolutely.        

Lex Fridman: 08:27:07: You think there’s something fundamentally different about just being able to physically interact with the world?        

Noland Arbaugh: 08:27:12: Yeah. Oh, 100%. I know another thing  with being able to give people the ability to feel sensation and stuff  too, by going in with the brain and having a Neuralink maybe do that,  that could be something that could be transferred through the Optimus as well. There’s all sorts of really cool interplay between that. And then also, like you said, just physically interacting. I mean, 99% of the  things that I can’t do myself, obviously, I need a caretaker for,  someone to physically do things for me. If an Optimus robot could do  that, I could live an incredibly independent life and not be such a  burden on those around me, and it would change the way people like me  live, at least until whatever this is gets cured.        

08:28:12: But being able to interact with the  world physically, that would just be amazing. And not just for having it be a caretaker or something, but something like I talked about. Just  being able to read a book. Imagine an Optimus robot just being able to  hold a book open in front of me. I get that smell again. I might not be  able to feel it at that point, or maybe I could, again, with the  sensation and stuff. But there’s something different about reading a  physical book than staring at a screen or listening to an audiobook. I  actually don’t like audiobooks. I’ve listened to a ton of them at this  point, but I don’t really like them. I would much rather read a physical copy.        

Lex Fridman: 08:28:52: So one of the things you would love to be able to experience is opening the book, bringing it up to you, and  to feel the touch of the paper.        

Noland Arbaugh: 08:29:01: Yeah. Oh, man. The touch, the smell. I mean, it’s just something about the words on the page. And they’ve  replicated that page color on the Kindle and stuff. Yeah, it’s just not  the same. Yeah. So just something as simple as that.        

Lex Fridman: 08:29:18: So one of the things you miss is touch?        

Noland Arbaugh: 08:29:20: I do. Yeah. A lot of things that I  interact with in the world, like clothes or literally any physical thing that I interact within the world, a lot of times what people around me  will do is they’ll just come rub it on my face. They’ll lay something on me so I can feel the weight. They will rub a shirt on me so I can feel  fabric. There’s something very profound about touch, and it’s something  that I miss a lot and something I would love to do again. We’ll see.        

Lex Fridman: 08:29:56: What would be the first thing you do with a hand that can touch? Give your mom a hug after that, right?        

Noland Arbaugh: 08:30:02: Yeah. I know. It’s one thing that I’ve asked God for basically every day since my accident was just being able to one day move, even if it was only my hand, so that way, I could  squeeze my mom’s hand or something just to show her how much I care and  how much I love her and everything. Something along those lines. Being  able to just interact with the people around me. Handshake, give someone a hug. I don’t know. Anything like that. Being able to help me eat. I’d probably get really fat, which would be a terrible, terrible thing.        

Lex Fridman: 08:30:44: Also, beat Bliss in chess on a physical board.        

Noland Arbaugh: 08:30:47: Yeah. Yeah. I mean, there were just so many upsides. And any way to find some way to feel like I’m bringing  Bliss down to my level because he’s just such an amazing guy, and  everything about him is just so above and beyond, that anything I can do to take him down a notch, I’m more than happy-        

Lex Fridman: 08:31:10: Yeah. Yeah, humble him a bit. He needs it.        

Noland Arbaugh: 08:31:12: Yeah.        

## God

Lex Fridman: 08:31:13: Okay. As he’s sitting next to me. Did you ever make sense of why God puts good people through such hardship?        

Noland Arbaugh: 08:31:23: Oh, man. I think it’s all about  understanding how much we need God. And I don’t think that there’s any  light without the dark. I think that if all of us were happy all the  time, there would be no reason to turn to God ever. I feel like there  would be no concept of good or bad, and I think that as much of the  darkness and the evil that’s in the world, it makes us all appreciate  the good and the things we have so much more. And I think when I had my  accident, one of the first things I said to one of my best friends was…  And this was within the first month or two after my accident, I said,  “Everything about this accident has just made me understand and believe  that God is real and that there really is a God, basically. And that my  interactions with him have all been real and worthwhile.”        

08:32:32: And he said, if anything, seeing me go through this accident, he believes that there isn’t a God. And it’s a  very different reaction, but I believe that it is a way for God to test  us, to build our character, to send us through trials and tribulations,  to make sure that we understand how precious He is and the things that  He’s given us and the time that He’s given us, and then to hopefully  grow from all of that. I think that’s a huge part of being here, is to  not just have an easy life and do everything that’s easy, but to step  out of our comfort zones and really challenge ourselves because I think  that’s how we grow.        

## Hope

Lex Fridman: 08:33:21: What gives you hope about this whole thing we have going on human civilization?        

Noland Arbaugh: 08:33:27: Oh, man. I think people are my biggest inspiration. Even just being at Neuralink for a few months, looking  people in the eyes and hearing their motivations for why they’re doing  this, it’s so inspiring. And I know that they could be other places, at  cushier jobs, working somewhere else, doing X, Y, or Z, that doesn’t  really mean that much. But instead, they’re here and they want to better humanity, and they want to better just the people around them. The  people that they’ve interacted with in their life, they want to make  better lives for their own family members who might have disabilities,  or they look at someone like me and they say, “I can do something about  that. So I’m going to.” And it’s always been what I’ve connected with  most in the world are people.        

08:34:22: I’ve always been a people person and I love learning about people, and I love learning how people developed  and where they came from, and to see how much people are willing to do  for someone like me when they don’t have to, and they’re going out of  their way to make my life better. It gives me a lot of hope for just  humanity in general, how much we care and how much we’re capable of when we all get together and try to make a difference. And I know there’s a  lot of bad out there in the world, but there always has been and there  always will be. And I think that that is… It shows human resiliency and  it shows what we’re able to endure and how much we just want to be there and help each other, and how much satisfaction we get from that,  because I think that’s one of the reasons that we’re here is just to  help each other, and… I don’t know. That always gives me hope, is just  realizing that there are people out there who still care and who want to help.        

Lex Fridman: 08:35:31: And thank you for being one such human being and continuing to be a great human being through everything  you’ve been through and being an inspiration to many people, to myself,  for many reasons, including your epic, unbelievably great performance on Webgrid. I’ll be training all night tonight to try to catch up.        

Noland Arbaugh: 08:35:52: Hey, man. You can do it. You can do it.        

Lex Fridman: 08:35:52: And I believe in you that once you  come back… So sorry to interrupt with the Austin trip, once you come  back, eventually beat Bliss.        

Noland Arbaugh: 08:36:00: Yeah, yeah, for sure. Absolutely.        

Lex Fridman: 08:36:02: I’m rooting for you, though. The whole world is rooting for you.        

Noland Arbaugh: 08:36:03: Thank you.        

Lex Fridman: 08:36:05: Thank you for everything you’ve done, man.        

Noland Arbaugh: 08:36:07: Thanks. Thanks, man.        

Lex Fridman: 08:36:09: Thanks for listening to this  conversation with Nolan Arbaugh, and before that, with Elon Musk, DJ  Seo, Matthew McDougall, and Bliss Chapman. To support this podcast,  please check out our sponsors in the description. And now, let me leave  you with some words from Aldous Huxley in The Doors of Perception. “We  live together. We act on and react to one another. But always, and in  all circumstances, we are by ourselves. The martyrs go hand in hand into the arena. They are crucified alone. Embrace the lovers desperately  tried to fuse their insulated ecstasies into a single self-transcendence in vain. But it’s very nature, every embodied spirit is doomed to  suffer and enjoy its solitude, sensations, feelings, insights, fancies,  all these are private, and except through symbols and a secondhand  incommunicable. We can pool information about experiences, but never the experiences themselves. From family to nation, every human group is a  society of island universes.” Thank you for listening and hope to see  you next time.