

### LLaVA

> https://llava-vl.github.io
> https://github.com/haotian-liu/LLaVA
> https://huggingface.co/liuhaotian

LLaVa connects pre-trained [CLIP ViT-L/14](https://openai.com/research/clip) visual encoder and large language model [Vicuna](https://github.com/lm-sys/FastChat), using a simple projection matrix. 

LLaVA-1.5 uses Llama 2.



### BakLLaVA-1

> https://github.com/SkunkworksAI/BakLLaVA
> https://huggingface.co/SkunkworksAI/BakLLaVA-1

BakLLaVA 1 is a Mistral 7B base augmented with the LLaVA 1.5 architecture.



